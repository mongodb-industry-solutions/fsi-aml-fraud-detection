{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building a MongoDB-Powered AML Solution\n",
        "The implementation of these three core featuresâ€”Intelligent Entity Resolution, Network Analysis & Visualization, and Real-Time Risk Scoring creates a powerful foundation for a modern AML system built on MongoDB. Together, they address the fundamental challenges facing financial institutions in the fight against money laundering:\n",
        "* Who are we dealing with? (Entity Resolution)\n",
        "* Who do they know and work with? (Network Analysis)\n",
        "* How risky are they and why? (Real-Time Risk Scoring)"
      ],
      "metadata": {
        "id": "MjUFnH3cCObp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo faker dnspython boto3 awscli numpy -q\n",
        "\n",
        "import pymongo\n",
        "from faker import Faker\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "from bson import ObjectId\n",
        "import uuid # For more unique IDs if needed\n",
        "import boto3\n",
        "from botocore.config import Config\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import numpy as np\n",
        "import time\n",
        "import json"
      ],
      "metadata": {
        "id": "5mZo9xqNE9kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "MONGODB_URI = \"ENTER URI\"\n",
        "DB_NAME = \"threatsight360\"\n",
        "\n",
        "# Add your AWS credentials and region\n",
        "aws_access_key = \"\"\n",
        "aws_secret_key = \"\"\n",
        "aws_region = \"us-east-1\"  # Change to your preferred region\n",
        "EMBEDDING_MODEL_ID = \"amazon.titan-embed-text-v1\"\n",
        "EMBEDDING_DIMENSIONS = 1536"
      ],
      "metadata": {
        "id": "-qZPq5H2E_lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fake = Faker() # Your original\n",
        "fake = Faker(['en_US', 'en_CA', 'en_GB', 'de_DE', 'fr_FR']) # New: Add multiple locales\n",
        "Faker.seed(0) # For reproducibility"
      ],
      "metadata": {
        "id": "hfmXPnDjFBFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure AWS Session\n",
        "boto3_config = Config(\n",
        "    region_name=aws_region,\n",
        "    signature_version='v4',\n",
        "    retries={\n",
        "        'max_attempts': 3,\n",
        "        'mode': 'standard'\n",
        "    }\n",
        ")\n",
        "\n",
        "# Initialize Bedrock Runtime client\n",
        "try:\n",
        "    bedrock_runtime = boto3.client(\n",
        "        service_name='bedrock-runtime',\n",
        "        aws_access_key_id=aws_access_key,\n",
        "        aws_secret_access_key=aws_secret_key,\n",
        "        config=boto3_config\n",
        "    )\n",
        "    print(\"AWS Bedrock client initialized successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: AWS Bedrock client initialization failed: {e}\")\n",
        "    print(\"Using fallback random embeddings - for demo purposes only\")\n",
        "    bedrock_runtime = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZVzDVt0FcxJ",
        "outputId": "49b3bcfa-b897-4f16-d4db-4ea702b64470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AWS Bedrock client initialized successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Embedding Generation Function ---\n",
        "def get_embedding_from_bedrock_or_fallback(text_to_embed, bedrock_client, model_id=EMBEDDING_MODEL_ID, dimensions=EMBEDDING_DIMENSIONS):\n",
        "    if not bedrock_client:\n",
        "        # print(f\"Debug: Bedrock client None. Fallback random embedding for: '{text_to_embed[:50]}...'\")\n",
        "        return np.random.rand(dimensions).tolist()\n",
        "    try:\n",
        "        payload = {\"inputText\": text_to_embed}\n",
        "        body = json.dumps(payload)\n",
        "        response = bedrock_client.invoke_model(\n",
        "            body=body, modelId=model_id, accept='application/json', contentType='application/json'\n",
        "        )\n",
        "        response_body = json.loads(response.get('body').read())\n",
        "        embedding = response_body.get('embedding')\n",
        "        if embedding and len(embedding) == dimensions:\n",
        "            return embedding\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating embedding with Bedrock for '{text_to_embed[:50]}...': {e}\")"
      ],
      "metadata": {
        "id": "FXDc4yF8HaG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MongoDB Connection ---\n",
        "try:\n",
        "    client = pymongo.MongoClient(MONGODB_URI)\n",
        "    db = client[DB_NAME]\n",
        "    db.command('ping')\n",
        "    print(f\"Successfully connected to MongoDB: {DB_NAME}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error connecting to MongoDB: {e}\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "_xhA-mEVFDcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 1. `entities` Collection\n",
        "\n",
        "*   **Schema:** (Your existing schema is very good. We'll highlight key parts for generation.)\n",
        "    *   `_id`: `ObjectId()`\n",
        "    *   `entityId`: String (e.g., \"E\" + random numbers/letters) - **Unique**\n",
        "    *   `entityType`: String (\"individual\", \"organization\")\n",
        "    *   `status`: String (\"active\", \"inactive\", \"under_review\")\n",
        "    *   `sourceSystem`: String (e.g., \"core_banking\", \"onboarding_portal\", \"crm\")\n",
        "    *   `createdAt`: `ISODate()`\n",
        "    *   `updatedAt`: `ISODate()`\n",
        "    *   `name`:\n",
        "        *   `full`: String\n",
        "        *   `structured`: { `first`, `middle`, `last` } (for individuals) or `legalName` (for orgs)\n",
        "        *   `aliases`: Array of Strings\n",
        "        *   `nameComponents`: Array of Strings (lowercase tokens)\n",
        "    *   `dateOfBirth`: String \"YYYY-MM-DD\" (for individuals) / `incorporationDate` for orgs\n",
        "    *   `placeOfBirth`: String (for individuals) / `jurisdictionOfIncorporation` for orgs\n",
        "    *   `gender`: String (for individuals)\n",
        "    *   `nationality`: Array of Strings (for individuals)\n",
        "    *   `residency`: String (country code)\n",
        "    *   `addresses`: Array of Objects (your address schema is great)\n",
        "        *   `type`: \"residential\", \"business\", \"mailing\"\n",
        "        *   `primary`: Boolean\n",
        "        *   `full`: String\n",
        "        *   `structured`: { `street`, `city`, `state`, `postalCode`, `country` }\n",
        "        *   `coordinates`: [lng, lat] (optional, but cool for geo-queries if you go there)\n",
        "        *   `validFrom`, `validTo`: `ISODate()`\n",
        "        *   `verified`, `verificationMethod`, `verificationDate`\n",
        "    *   `contactInfo`: Array of Objects (your contactInfo schema is good)\n",
        "        *   `type`: \"email\", \"phone\"\n",
        "        *   `value`: String\n",
        "        *   `primary`: Boolean\n",
        "        *   `verified`, `verificationDate`\n",
        "    *   `identifiers`: Array of Objects (your identifiers schema is good)\n",
        "        *   `type`: \"ssn\", \"passport\", \"drivers_license\", \"tin\" (for orgs)\n",
        "        *   `value`: String\n",
        "        *   `country`: String\n",
        "        *   `issueDate`, `expiryDate`: `ISODate()`\n",
        "        *   `verified`, `verificationMethod`, `verificationDate`\n",
        "    *   `resolution`: Object (Crucial for Feature 1)\n",
        "        *   `status`: \"unresolved\", \"resolved\", \"under_review\" (default to \"unresolved\" or \"resolved\" if it's a master)\n",
        "        *   `masterEntityId`: String (points to self if it's the master, or to the master entityId)\n",
        "        *   `confidence`: Number (0-1)\n",
        "        *   `linkedEntities`: Array of Objects\n",
        "            *   `entityId`: String (ID of the linked entity)\n",
        "            *   `linkType`: \"potential_duplicate\", \"confirmed_match\", \"shared_address_link\", etc.\n",
        "            *   `confidence`: Number\n",
        "            *   `matchedAttributes`: Array of Strings\n",
        "            *   `matchDate`: `ISODate()`\n",
        "            *   `decidedBy`: \"system\" or \"analyst_ID\"\n",
        "            *   `decision`: \"confirmed_match\", \"rejected_match\", \"under_review\"\n",
        "        *   `lastReviewDate`, `reviewedBy`\n",
        "    *   `riskAssessment`: Object (Crucial for Feature 3 & pKYC)\n",
        "        *   `overall`: { `score`, `level`, `trend`, `lastUpdated`, `nextScheduledReview` }\n",
        "        *   `components`: { `identity`, `activity`, `profile`, `external`, `network` } (each with `score`, `weight`, `factors` array)\n",
        "            *   `factors`: [{ `type`, `impact`, `description`, `mitigations` }]\n",
        "        *   `history`: Array of { `date`, `score`, `level`, `changeTrigger` }\n",
        "        *   `metadata`: { `model`, `lastFullAssessment`, `assessmentType`, `overrides` }\n",
        "    *   `watchlistMatches`: Array of Objects (Crucial for Feature 3/5)\n",
        "        *   `listId`: String (e.g., \"OFAC-SDN\", \"EU-PEP\")\n",
        "        *   `matchId`: String (ID from the watchlist source)\n",
        "        *   `matchScore`: Number\n",
        "        *   `matchDate`: `ISODate()`\n",
        "        *   `status`: \"under_review\", \"confirmed_hit\", \"false_positive\"\n",
        "    *   `customerInfo`: Object (Good for context and profile risk)\n",
        "        *   `customerSince`, `segments`, `products`, `employmentStatus`, `occupation`, `employer` / `industry`, `businessType` (for orgs)\n",
        "    *   **Data Tweaks for `entities`:**\n",
        "        1.  **Clear Duplicates:**\n",
        "            *   Entity A: \"Johnathan Smith\", DOB \"1980-01-15\", Address \"123 Main St, Anytown\".\n",
        "            *   Entity B: \"John Smith\", DOB \"1980-01-15\", Address \"123 Main St, Apt 2, Anytown\". (Slight name/address variation)\n",
        "            *   Entity C: \"Jon Smyth\", DOB \"1980-01-15\", Phone \"+1-555-123-4567\".\n",
        "            *   Entity D: \"Johnathan A. Smith\", same DOB, same phone as C.\n",
        "        2.  **Subtle/Complex Duplicates:**\n",
        "            *   Entity E: \"Sarah Miller\", Address \"456 Oak Ave\", Old Passport \"P123\".\n",
        "            *   Entity F: \"Sarah Davis\" (married name), Address \"789 Pine Ln\", New Passport \"P789\", Email \"sarah.davis@email.com\" (previously used by Sarah Miller). Link via historical data or shared non-obvious identifier.\n",
        "        3.  **Organization Links:**\n",
        "            *   Org G: \"Global Exports Inc.\", Director: \"Peter Jones\" (Entity H).\n",
        "            *   Org I: \"Import Solutions LLC\", Shareholder >25%: \"Peter Jones\" (Entity H).\n",
        "        4.  **Risk Profiles:**\n",
        "            *   **Low Risk Start:** Entity J - complete KYC, stable job, low-risk country.\n",
        "            *   **High Risk Start:** Entity K - PEP, operations in high-risk industry/jurisdiction.\n",
        "            *   **Evolving Risk:** Entity L (starts low) - later add transactions to high-risk country, or link to a high-risk entity, or partial watchlist match.\n",
        "        5.  **Watchlist Candidates:**\n",
        "            *   Entity M: \"Evil Villain\" - direct match for a watchlist entry.\n",
        "            *   Entity N: \"Eva Villian\" - fuzzy match for a watchlist entry.\n",
        "        6.  **For Network:** Entities that share addresses, phone numbers, or are linked via ER.\n",
        "        7.  **Temporal Data:** Some entities with multiple historical addresses/jobs to show the timeline.\n",
        "        8.  **Incomplete Data:** Some entities with missing `dateOfBirth` or unverified identifiers to show impact on identity risk.\n"
      ],
      "metadata": {
        "id": "wd6fIKsTCVXI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOzVlHEiA4XK",
        "outputId": "5750e096-4d83-495a-ab92-fb8a25a8c16b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating scenario-based entities with multiplication...\n",
            "Generating 15 sets of Clear Duplicates...\n",
            "Generating 20 PEP Individuals...\n",
            "Generating 10 Evolving Risk Individuals...\n",
            "Generating 8 Sanctioned Organizations...\n",
            "Generating 5 Complex Organization Structures...\n",
            "Generating 25 Incomplete Data Individuals...\n",
            "Generating 10 Household Sets...\n",
            "Generating 8 Subtle Duplicate Clusters...\n",
            "Generating 12 Shell Company Candidates...\n",
            "Generating 15 HNWIs...\n",
            "Generating 200 generic individuals...\n",
            "Generating 100 generic organizations...\n",
            "\n",
            "Total entities to insert: 504\n",
            "Attempting to insert entities into 'entities' collection...\n",
            "Successfully inserted 504 entities.\n",
            "\n",
            "--- Entity Seeding with Scenario Multiplication Complete ---\n"
          ]
        }
      ],
      "source": [
        "entities_collection = db[\"entities\"]\n",
        "potential_ubo_pool = [] # Reset for each run if needed\n",
        "\n",
        "# --- Global Storage for Generated IDs (to be used by other collection scripts) ---\\n\",\n",
        "# This dictionary will store lists of entity_docs for easy access later\\n\",\n",
        "generated_entity_store = {}\n",
        "\n",
        "# --- Enhanced Helper Functions ---\\n\",\n",
        "def generate_unique_id(prefix=\"E\"):\n",
        "    return f\"{prefix}-{uuid.uuid4().hex[:10].upper()}\"\n",
        "\n",
        "def create_name_data(entity_type=\"individual\", first_name=None, last_name=None, company_name_base=None, use_maiden_name=False):\n",
        "    name_info = {}\n",
        "    if entity_type == \"individual\":\n",
        "        fn = first_name or fake.first_name()\n",
        "        ln = last_name or fake.last_name()\n",
        "        mn = fake.first_name() if random.random() < 0.4 else \"\" # Increased middle name chance\n",
        "        full = f\"{fn} {mn} {ln}\".replace(\"  \", \" \").strip()\n",
        "\n",
        "        aliases = []\n",
        "        if mn: aliases.append(f\"{fn} {ln}\") # Alias without middle name\n",
        "        aliases.append(f\"{fn[0]}. {ln}\")\n",
        "        if random.random() < 0.2: aliases.append(f\"{fn} {ln[0]}.\")\n",
        "        if random.random() < 0.15: aliases.append(fake.first_name() + \" \" + ln) # Different first name, same last\n",
        "        if use_maiden_name and random.random() < 0.5 : # More common if flagged\n",
        "             maiden_name = fake.last_name()\n",
        "             aliases.append(f\"{fn} {maiden_name}\")\n",
        "             aliases.append(f\"{fn} {mn} {maiden_name}\".replace(\"  \", \" \").strip())\n",
        "\n",
        "\n",
        "        name_info = {\n",
        "            \"full\": full, \"structured\": {\"first\": fn, \"middle\": mn, \"last\": ln},\n",
        "            \"aliases\": list(set(aliases))[:3], # Limit number of aliases\n",
        "            \"nameComponents\": [n.lower() for n in full.split()]\n",
        "        }\n",
        "    else: # organization\n",
        "        base = company_name_base or fake.bs().replace(\" \", \"-\").split('-')[0].capitalize()\n",
        "        if random.random() < 0.2: # Add more varied base names\n",
        "            base = random.choice([fake.word().capitalize() + fake.word().capitalize(), fake.last_name() + \" Holdings\"])\n",
        "\n",
        "        suffix = random.choice([\n",
        "            \"Inc.\", \"Ltd.\", \"LLC\", \"Corp.\", \"Group\", \"Solutions\", \"Global\", \"Ventures\", \"Holdings\",\n",
        "            \"Enterprises\", \"International\", \"Partners\", \"Associates\", \"Industries\", \"Logistics\", \"Trading Co.\"\n",
        "        ])\n",
        "        full = f\"{base} {suffix}\"\n",
        "\n",
        "        aliases = []\n",
        "        if random.random() < 0.3: aliases.append(f\"{base} {random.choice(['Enterprises', 'Services', 'Worldwide', 'Group'])}\")\n",
        "        if random.random() < 0.2: aliases.append(f\"{base.split()[0] if ' ' in base else base[:5]} {suffix}\") # Abbreviated base\n",
        "\n",
        "        name_info = {\n",
        "            \"full\": full, \"structured\": {\"legalName\": full}, \"aliases\": list(set(aliases))[:2],\n",
        "            \"nameComponents\": [n.lower() for n in full.split()]\n",
        "        }\n",
        "    return name_info\n",
        "\n",
        "def create_address_data(primary=True, country_code=None, city=None, risk_level=None, structured=None, full=None, verified_status=None, address_type=None):\n",
        "    # Expanded country lists, especially high-risk\n",
        "    countries = {\n",
        "        \"low\": [(\"US\", \"United States\"), (\"CA\", \"Canada\"), (\"DE\", \"Germany\"), (\"FR\", \"France\"), (\"AU\", \"Australia\"), (\"JP\", \"Japan\"), (\"NZ\", \"New Zealand\"), (\"NO\", \"Norway\")],\n",
        "        \"medium\": [(\"GB\", \"United Kingdom\"), (\"CH\", \"Switzerland\"), (\"AE\", \"United Arab Emirates\"), (\"SG\", \"Singapore\"), (\"HK\", \"Hong Kong\"), (\"BR\", \"Brazil\"), (\"ZA\", \"South Africa\"), (\"CN\", \"China\")],\n",
        "        \"high\": [\n",
        "            (\"SY\", \"Syria\"), (\"KP\", \"North Korea\"), (\"VE\", \"Venezuela\"), (\"KY\", \"Cayman Islands\"), (\"PA\", \"Panama\"),\n",
        "            (\"IR\", \"Iran\"), (\"AF\", \"Afghanistan\"), (\"SO\", \"Somalia\"), (\"YE\", \"Yemen\"), (\"LY\", \"Libya\"), (\"IQ\", \"Iraq\"),\n",
        "            (\"VU\", \"Vanuatu\"), (\"BS\", \"Bahamas\"), (\"CY\", \"Cyprus\"), (\"MT\", \"Malta\"), (\"TC\", \"Turks and Caicos Islands\")\n",
        "        ]\n",
        "    }\n",
        "    country_map_direct = {code: name for k_list in countries.values() for code, name in k_list}\n",
        "\n",
        "\n",
        "    if structured and structured.get(\"country\"):\n",
        "        chosen_country_code = structured[\"country\"]\n",
        "        chosen_country_name = country_map_direct.get(chosen_country_code, fake.country())\n",
        "    elif country_code:\n",
        "        chosen_country_code = country_code\n",
        "        chosen_country_name = country_map_direct.get(country_code, fake.country())\n",
        "    else:\n",
        "        chosen_risk = risk_level or random.choice(list(countries.keys()))\n",
        "        # Ensure chosen_risk is valid if passed explicitly, otherwise default\n",
        "        if chosen_risk not in countries: chosen_risk = random.choice(list(countries.keys()))\n",
        "        chosen_country_code, chosen_country_name = random.choice(countries[chosen_risk])\n",
        "\n",
        "\n",
        "    addr_struct = structured\n",
        "    full_addr_override = full\n",
        "\n",
        "    if not addr_struct:\n",
        "        addr_city_gen = city or fake.city()\n",
        "        addr_street_gen = fake.street_address()\n",
        "        # More robust state/province generation\n",
        "        if chosen_country_code == \"US\": addr_state_gen = fake.state_abbr()\n",
        "        elif chosen_country_code == \"CA\": addr_state_gen = fake.province_abbr()\n",
        "        elif chosen_country_code == \"AU\": addr_state_gen = fake.state_abbr() # Faker has AU states\n",
        "        else: addr_state_gen = fake.state() if random.random() < 0.3 else \"\" # Generic state for others, or none\n",
        "\n",
        "        addr_postal_gen = fake.zipcode() if chosen_country_code == \"US\" else fake.postcode()\n",
        "        addr_struct = {\n",
        "            \"street\": addr_street_gen, \"city\": addr_city_gen, \"state\": addr_state_gen,\n",
        "            \"postalCode\": addr_postal_gen, \"country\": chosen_country_code\n",
        "        }\n",
        "\n",
        "    if not full_addr_override:\n",
        "        s = addr_struct\n",
        "        full_addr_override = f\"{s['street']}, {s['city']}{', '+s['state'] if s['state'] else ''}, {s['postalCode']}, {chosen_country_name}\"\n",
        "\n",
        "    if verified_status is not None:\n",
        "        is_verified = verified_status\n",
        "    else:\n",
        "        is_verified = random.random() > (0.4 if risk_level == \"high\" else 0.2) # Less likely verified if high risk address\n",
        "\n",
        "    addr_type_choices = [\"residential\", \"business\", \"mailing\", \"registered_office\", \"previous\", \"care_of\"]\n",
        "    addr = {\n",
        "        \"type\": address_type or random.choice(addr_type_choices),\n",
        "        \"primary\": primary,\n",
        "        \"full\": full_addr_override,\n",
        "        \"structured\": addr_struct,\n",
        "        \"coordinates\": [float(fake.longitude()), float(fake.latitude())] if random.random() < 0.6 else None,\n",
        "        \"validFrom\": fake.date_time_between(start_date=\"-10y\", end_date=\"-6m\", tzinfo=timezone.utc),\n",
        "        \"validTo\": None,\n",
        "        \"verified\": is_verified,\n",
        "        \"verificationMethod\": random.choice([\n",
        "            \"utility_bill\", \"electronic_idv\", \"site_visit\", \"lease_agreement\", \"public_record\", \"correspondence\"\n",
        "            ]) if is_verified else None,\n",
        "        \"verificationDate\": fake.date_time_this_year(tzinfo=timezone.utc) if is_verified else None\n",
        "    }\n",
        "    return addr\n",
        "\n",
        "def create_contact_data(primary=True, contact_type_override=None, value_override=None):\n",
        "    contact_type = contact_type_override or random.choice([\"email\", \"phone_mobile\", \"phone_landline\", \"fax\", \"social_media_handle\"])\n",
        "    if value_override:\n",
        "        value = value_override\n",
        "    elif \"email\" in contact_type: value = fake.email()\n",
        "    elif \"social_media\" in contact_type: value = \"@\" + fake.user_name()\n",
        "    else: value = fake.phone_number()\n",
        "\n",
        "    is_verified = random.random() > 0.35\n",
        "    return {\"type\": contact_type, \"value\": value, \"primary\": primary, \"verified\": is_verified,\n",
        "            \"verificationDate\": fake.date_time_this_year(tzinfo=timezone.utc) if is_verified else None}\n",
        "\n",
        "def create_identifier_data(entity_type=\"individual\", country_code=\"US\", id_type=None): # Added id_type override\n",
        "    actual_id_type, value = \"\", \"\"\n",
        "    issue_country = country_code\n",
        "    if entity_type == \"individual\":\n",
        "        id_types_available = [\"passport\", \"national_id\", \"drivers_license\", \"ssn\", \"tax_id\", \"voter_id\", \"health_card_id\"]\n",
        "        actual_id_type = id_type or random.choice(id_types_available)\n",
        "\n",
        "        if actual_id_type == \"passport\": value, issue_country = fake.unique.bothify(text=\"??#########\", letters=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"), random.choice([country_code, \"GB\", \"CA\", \"DE\", \"FR\", \"AU\"]) if random.random() < 0.7 else fake.country_code()\n",
        "        elif actual_id_type == \"ssn\" and country_code == \"US\": value = fake.ssn()\n",
        "        elif actual_id_type == \"national_id\": value = fake.unique.bothify(text=\"ID-############??\")\n",
        "        elif actual_id_type == \"tax_id\": value = fake.unique.bothify(text=\"TAXID-??########\")\n",
        "        else: value = fake.unique.bothify(text=\"??-?#########\", letters=\"ABCDEF\")\n",
        "    else: # organization\n",
        "        id_types_available = [\"registration_no\", \"tax_id_number\", \"vat_id\", \"lei_code\", \"duns_number\"]\n",
        "        actual_id_type = id_type or random.choice(id_types_available)\n",
        "        if actual_id_type == \"tax_id_number\": value = fake.unique.bothify(text=\"TIN##-#######\")\n",
        "        elif actual_id_type == \"vat_id\": value = f\"{country_code}{fake.unique.bothify(text='#########')}\"\n",
        "        elif actual_id_type == \"lei_code\": value = fake.unique.bothify(text=\"##################??\", letters=\"0123456789ABCDEFGHJKLMNPQRSTUVWXYZ\") # 20 chars\n",
        "        else: value = fake.unique.bothify(text=\"REG-##########??\")\n",
        "\n",
        "    is_verified = random.random() > (0.3 if actual_id_type == \"ssn\" else 0.15) # SSNs harder to verify synthetically\n",
        "    return {\"type\": actual_id_type, \"value\": value, \"country\": issue_country,\n",
        "            \"issueDate\": fake.date_time_between(start_date=\"-12y\", end_date=\"-3m\", tzinfo=timezone.utc),\n",
        "            \"expiryDate\": fake.date_time_between(start_date=\"+6m\", end_date=\"+10y\", tzinfo=timezone.utc) if actual_id_type in [\"passport\", \"drivers_license\", \"lei_code\"] else None,\n",
        "            \"verified\": is_verified,\n",
        "            \"verificationMethod\": random.choice([\"document_scan\", \"issuing_authority_check\", \"database_lookup\", \"api_validation\"]) if is_verified else None,\n",
        "            \"verificationDate\": fake.date_time_this_decade(tzinfo=timezone.utc) if is_verified else None}\n",
        "\n",
        "# Function to generate UBO data for organizations\n",
        "def generate_ubo_data(num_ubos=0, existing_individual_pool=None):\n",
        "    ubos = []\n",
        "    if num_ubos == 0:\n",
        "        num_ubos = random.choices([0,1,2,3], weights=[0.2, 0.4, 0.3, 0.1], k=1)[0]\n",
        "\n",
        "    for _ in range(num_ubos):\n",
        "        ubo_type = random.choices([\"individual\", \"corporate\"], weights=[0.85, 0.15], k=1)[0]\n",
        "        name_data = create_name_data(entity_type=\"individual\" if ubo_type == \"individual\" else \"organization\")\n",
        "\n",
        "        ubo_entry = {\n",
        "            \"name\": name_data[\"full\"],\n",
        "            \"entityType\": ubo_type,\n",
        "            \"nationality\": fake.country_code() if ubo_type == \"individual\" else None,\n",
        "            \"countryOfIncorporation\": fake.country_code() if ubo_type == \"corporate\" else None,\n",
        "            \"percentageOwnership\": round(random.uniform(5.0, 95.0), 2), # More varied ownership\n",
        "            \"controlType\": random.choice([\"direct_ownership\", \"indirect_ownership\", \"voting_rights\", \"board_control\", \"other_influence\"]),\n",
        "            \"identification\": { # Simplified ID for UBO for now\n",
        "                \"type\": \"passport\" if ubo_type == \"individual\" else \"registration_no\",\n",
        "                \"value\": fake.unique.bothify(text=\"UBO-ID-????####\")\n",
        "            } if random.random() < 0.7 else None,\n",
        "            \"linkedEntityId\": None # Placeholder for potential linking later\n",
        "        }\n",
        "        # Optionally link to an existing individual from a pool\n",
        "        if ubo_type == \"individual\" and existing_individual_pool and random.random() < 0.2:\n",
        "            chosen_ind = random.choice(existing_individual_pool)\n",
        "            ubo_entry[\"name\"] = chosen_ind[\"name\"][\"full\"]\n",
        "            ubo_entry[\"nationality\"] = chosen_ind[\"nationality\"][0] if chosen_ind.get(\"nationality\") else fake.country_code()\n",
        "            ubo_entry[\"linkedEntityId\"] = chosen_ind[\"entityId\"]\n",
        "            ubo_entry[\"percentageOwnership\"] = round(random.uniform(25.0, 75.0), 2) # Higher if linked to specific person\n",
        "\n",
        "        ubos.append(ubo_entry)\n",
        "    return ubos\n",
        "\n",
        "\n",
        "def calculate_detailed_risk(entity_doc):\n",
        "    risk_factors_details = {\"identity\": [], \"profile\": [], \"activity\": [], \"external\": [], \"network\": []}\n",
        "    # Base scores - can adjust these defaults\n",
        "    identity_score, profile_score, activity_score, external_score, network_score = 10, 10, 20, 0, 10\n",
        "\n",
        "    # --- Identity Risk Factors ---\n",
        "    if not entity_doc.get(\"dateOfBirth\") and entity_doc[\"entityType\"] == \"individual\":\n",
        "        identity_score += 25; risk_factors_details[\"identity\"].append({\"type\": \"missing_dob\", \"impact\": 25, \"description\": \"Date of birth is missing.\"})\n",
        "\n",
        "    unverified_ids_count = sum(1 for i in entity_doc.get(\"identifiers\", []) if not i.get(\"verified\"))\n",
        "    if unverified_ids_count > 0:\n",
        "        id_impact = unverified_ids_count * 15\n",
        "        identity_score += id_impact; risk_factors_details[\"identity\"].append({\"type\": \"unverified_identifiers\", \"impact\": id_impact, \"description\": f\"{unverified_ids_count} unverified identifier(s).\"})\n",
        "    if len(entity_doc.get(\"identifiers\", [])) == 0:\n",
        "        identity_score += 30; risk_factors_details[\"identity\"].append({\"type\": \"no_identifiers\", \"impact\": 30, \"description\": \"No identifiers provided.\"})\n",
        "\n",
        "    if len(entity_doc.get(\"name\",{}).get(\"aliases\",[])) > 2:\n",
        "        identity_score += 10; risk_factors_details[\"identity\"].append({\"type\": \"multiple_aliases\", \"impact\": 10, \"description\": \"Multiple aliases present.\"})\n",
        "\n",
        "    num_unverified_contacts = sum(1 for c in entity_doc.get(\"contactInfo\", []) if not c.get(\"verified\"))\n",
        "    if num_unverified_contacts > 1 :\n",
        "        identity_score += 5 * num_unverified_contacts; risk_factors_details[\"identity\"].append({\"type\": \"unverified_contact\", \"impact\": 5 * num_unverified_contacts, \"description\": f\"{num_unverified_contacts} unverified contact methods.\"})\n",
        "\n",
        "    # --- Profile Risk Factors ---\n",
        "    cust_info = entity_doc.get(\"customerInfo\", {})\n",
        "    if entity_doc[\"entityType\"] == \"individual\":\n",
        "        if cust_info.get(\"employmentStatus\") == \"unemployed\":\n",
        "            profile_score += 20; risk_factors_details[\"profile\"].append({\"type\": \"unemployed\", \"impact\": 20, \"description\": \"Individual is unemployed.\"})\n",
        "        occupation_value = cust_info.get(\"occupation\") # Get the value, could be None\n",
        "        occupation = str(occupation_value).lower() if occupation_value is not None else \"\" # Convert to string then lower, or default to \"\"\n",
        "        # Expanded high-risk industries/occupations\n",
        "        high_risk_occupations = [\n",
        "            \"casino dealer\", \"arms dealer\", \"pawnbroker\", \"money transmitter\", \"virtual currency trader\",\n",
        "            \"dealer in precious metals/stones\", \"political consultant\", \"lobbyist\"\n",
        "        ]\n",
        "        if any(hr_occ in occupation for hr_occ in high_risk_occupations):\n",
        "             profile_score += 30; risk_factors_details[\"profile\"].append({\"type\": \"high_risk_occupation\", \"impact\": 30, \"description\": f\"Occupation '{occupation}' is high-risk.\"})\n",
        "    else: # Organization\n",
        "        industry = cust_info.get(\"industry\", \"\").lower()\n",
        "        high_risk_industries = [\n",
        "            \"casinos\", \"arms manufacturing\", \"virtual currency exchange\", \"money service business\",\n",
        "            \"shell company formation\", \"offshore banking\", \"art and antiquities\", \"real estate (high value cash)\"\n",
        "        ]\n",
        "        if any(hr_ind in industry for hr_ind in high_risk_industries):\n",
        "            profile_score += 35; risk_factors_details[\"profile\"].append({\"type\": \"high_risk_industry_org\", \"impact\": 35, \"description\": f\"Industry '{industry}' is high-risk.\"})\n",
        "\n",
        "        if cust_info.get(\"businessType\") == \"shell_company_suspected\": # Need to set this in scenario\n",
        "             profile_score += 40; risk_factors_details[\"profile\"].append({\"type\": \"suspected_shell_company\", \"impact\": 40, \"description\": \"Business type and characteristics suggest shell company.\"})\n",
        "\n",
        "        if len(entity_doc.get(\"uboInfo\", [])) == 0 and random.random() < 0.3 : # No UBO info for an org is a risk\n",
        "             profile_score += 25; risk_factors_details[\"profile\"].append({\"type\": \"missing_ubo_data\", \"impact\": 25, \"description\": \"Ultimate Beneficial Ownership information is missing or incomplete.\"})\n",
        "\n",
        "\n",
        "    high_risk_address_countries = [\"KY\", \"PA\", \"SY\", \"KP\", \"VE\", \"IR\", \"AF\", \"SO\", \"YE\", \"VU\", \"BS\", \"CY\", \"MT\", \"TC\"]\n",
        "    num_hr_addresses = 0\n",
        "    for addr in entity_doc.get(\"addresses\", []):\n",
        "        if addr.get(\"structured\", {}).get(\"country\") in high_risk_address_countries:\n",
        "            num_hr_addresses +=1\n",
        "            if addr.get(\"primary\"): # Primary address in HR country is higher risk\n",
        "                profile_score += 30; risk_factors_details[\"profile\"].append({\"type\": \"primary_high_risk_jurisdiction\", \"impact\": 30, \"description\": \"Primary address in high-risk jurisdiction.\"})\n",
        "            else:\n",
        "                 profile_score += 15; risk_factors_details[\"profile\"].append({\"type\": \"other_high_risk_jurisdiction\", \"impact\": 15, \"description\": \"Non-primary address in high-risk jurisdiction.\"})\n",
        "            # break # one is enough for this factor usually, but could count them # Decided to allow multiple factors\n",
        "    if num_hr_addresses > 1:\n",
        "        profile_score += 10; risk_factors_details[\"profile\"].append({\"type\": \"multiple_high_risk_jurisdictions\", \"impact\": 10, \"description\": \"Presence in multiple high-risk jurisdictions.\"})\n",
        "\n",
        "    if entity_doc.get(\"sourceSystem\") == \"manual_entry_suspicious\": # Need to set this in scenario\n",
        "        profile_score += 15; risk_factors_details[\"profile\"].append({\"type\": \"suspicious_onboarding\", \"impact\": 15, \"description\": \"Onboarded via a potentially suspicious manual process.\"})\n",
        "\n",
        "\n",
        "    # --- External Risk Factors (mainly watchlist) ---\n",
        "    if entity_doc.get(\"watchlistMatches\"):\n",
        "        for match in entity_doc[\"watchlistMatches\"]:\n",
        "            if match.get(\"status\") == \"confirmed_hit\":\n",
        "                external_score += 70; risk_factors_details[\"external\"].append({\"type\": \"confirmed_watchlist_hit\", \"impact\": 70, \"description\": f\"Confirmed match on {match.get('listId')}.\"})\n",
        "            elif match.get(\"status\") == \"under_review\":\n",
        "                external_score += 35; risk_factors_details[\"external\"].append({\"type\": \"pending_watchlist_match\", \"impact\": 35, \"description\": f\"Potential match on {match.get('listId')} under review.\"})\n",
        "            elif match.get(\"status\") == \"fuzzy_match_high_confidence\":\n",
        "                external_score += 25; risk_factors_details[\"external\"].append({\"type\": \"fuzzy_watchlist_match_strong\", \"impact\": 25, \"description\": f\"Strong fuzzy match on {match.get('listId')}.\"})\n",
        "\n",
        "    # Activity and Network scores would typically be updated by other processes (transaction monitoring, graph analysis)\n",
        "    # For initial seeding, they can be low or have some baseline if certain profile elements imply network risk.\n",
        "    if len(entity_doc.get(\"resolution\", {}).get(\"linkedEntities\", [])) > 3:\n",
        "        network_score += 10; risk_factors_details[\"network\"].append({\"type\":\"multiple_linked_entities\", \"impact\":10, \"description\":\"Connected to multiple other entities.\"})\n",
        "\n",
        "\n",
        "    # Weights for each component\n",
        "    weights = {\"identity\": 0.25, \"profile\": 0.35, \"activity\": 0.20, \"external\": 0.15, \"network\": 0.05}\n",
        "\n",
        "    # Ensure scores are within 0-100 before weighting\n",
        "    identity_score = min(max(identity_score, 0), 100)\n",
        "    profile_score = min(max(profile_score, 0), 100)\n",
        "    activity_score = min(max(activity_score, 0), 100)\n",
        "    external_score = min(max(external_score, 0), 100)\n",
        "    network_score = min(max(network_score, 0), 100)\n",
        "\n",
        "    overall_score = (identity_score * weights[\"identity\"]) + \\\n",
        "                    (profile_score * weights[\"profile\"]) + \\\n",
        "                    (activity_score * weights[\"activity\"]) + \\\n",
        "                    (external_score * weights[\"external\"]) + \\\n",
        "                    (network_score * weights[\"network\"])\n",
        "\n",
        "    overall_score = min(max(int(overall_score), 0), 100)\n",
        "    level = \"high\" if overall_score > 70 else \"medium\" if overall_score > 40 else \"low\" # Adjusted thresholds\n",
        "\n",
        "    components_data = {\n",
        "        \"identity\": {\"score\": identity_score, \"weight\": weights[\"identity\"], \"factors\": risk_factors_details[\"identity\"]},\n",
        "        \"profile\": {\"score\": profile_score, \"weight\": weights[\"profile\"], \"factors\": risk_factors_details[\"profile\"]},\n",
        "        \"activity\": {\"score\": activity_score, \"weight\": weights[\"activity\"], \"factors\": risk_factors_details[\"activity\"]},\n",
        "        \"external\": {\"score\": external_score, \"weight\": weights[\"external\"], \"factors\": risk_factors_details[\"external\"]},\n",
        "        \"network\": {\"score\": network_score, \"weight\": weights[\"network\"], \"factors\": risk_factors_details[\"network\"]},\n",
        "    }\n",
        "    return overall_score, level, components_data\n",
        "\n",
        "\n",
        "def generate_entity_template(entity_type, scenario_key=\"generic\", existing_individual_pool=None, **kwargs):\n",
        "    created_at = fake.date_time_between(start_date=\"-7y\", end_date=\"-1d\", tzinfo=timezone.utc) # Ensure not too recent\n",
        "    updated_at = fake.date_time_between(start_date=created_at, end_date=\"now\", tzinfo=timezone.utc)\n",
        "\n",
        "    name_data = create_name_data(\n",
        "        entity_type,\n",
        "        kwargs.get(\"first_name\"),\n",
        "        kwargs.get(\"last_name\"),\n",
        "        kwargs.get(\"company_name_base\"),\n",
        "        kwargs.get(\"use_maiden_name_flag\", False)\n",
        "    )\n",
        "\n",
        "    addresses = []\n",
        "    # Primary Address\n",
        "    primary_addr_details = {\"primary\": True, \"country_code\": kwargs.get(\"country_code\"), \"city\": kwargs.get(\"city\"), \"risk_level\": kwargs.get(\"address_risk\")}\n",
        "    if \"primary_address_struct\" in kwargs: primary_addr_details[\"structured\"] = kwargs[\"primary_address_struct\"]\n",
        "    if \"primary_address_full\" in kwargs: primary_addr_details[\"full\"] = kwargs[\"primary_address_full\"]\n",
        "    if \"primary_address_verified\" in kwargs: primary_addr_details[\"verified_status\"] = kwargs[\"primary_address_verified\"]\n",
        "    addresses.append(create_address_data(**primary_addr_details))\n",
        "\n",
        "    # Optional: More addresses (historical, secondary)\n",
        "    num_other_addresses = random.choices([0,1,2], weights=[0.5, 0.3, 0.2], k=1)[0]\n",
        "    for i in range(num_other_addresses):\n",
        "        addr_risk = random.choice([\"low\", \"medium\", \"high\"]) if not kwargs.get(\"force_addr_risk\") else kwargs.get(\"force_addr_risk\")\n",
        "        past_address = create_address_data(\n",
        "            primary=False,\n",
        "            country_code=kwargs.get(f\"past_country_code_{i}\"),\n",
        "            risk_level=addr_risk, # Vary risk of past addresses\n",
        "            address_type=random.choice([\"previous\", \"mailing\", \"business\"])\n",
        "        )\n",
        "        past_address[\"validTo\"] = past_address[\"validFrom\"] + timedelta(days=random.randint(180, 1500))\n",
        "        if past_address[\"validTo\"] > datetime.now(timezone.utc): # ensure past is past\n",
        "            past_address[\"validTo\"] = fake.date_time_between(start_date=past_address[\"validFrom\"], end_date=\"-1d\", tzinfo=timezone.utc)\n",
        "        addresses.append(past_address)\n",
        "\n",
        "    current_country = addresses[0][\"structured\"][\"country\"] # Use primary address country for identifiers\n",
        "\n",
        "    identifiers = []\n",
        "    num_identifiers = random.choices([1,2,3], weights=[0.4, 0.4, 0.2], k=1)[0]\n",
        "    if \"num_ids\" in kwargs: num_identifiers = kwargs[\"num_ids\"]\n",
        "    if kwargs.get(\"force_no_ids\", False): num_identifiers = 0\n",
        "\n",
        "    for _ in range(num_identifiers):\n",
        "        identifiers.append(create_identifier_data(entity_type, country_code=current_country))\n",
        "    if \"specific_ids\" in kwargs: # Allow adding very specific IDs for scenarios\n",
        "        identifiers.extend(kwargs[\"specific_ids\"])\n",
        "\n",
        "\n",
        "    entity_doc = {\n",
        "        \"_id\": ObjectId(), \"entityId\": kwargs.get(\"entityId\", generate_unique_id(\"C\" if entity_type == \"individual\" else \"O\")),\n",
        "        \"scenarioKey\": scenario_key, \"entityType\": entity_type, \"status\": kwargs.get(\"status\", \"active\"),\n",
        "        \"sourceSystem\": kwargs.get(\"source_system_override\", random.choice([\n",
        "            \"onboarding_v3_digital\", \"crm_salesforce\", \"legacy_mainframe_sysX\",\n",
        "            \"partner_api_acme\", \"manual_entry_branch\", \"third_party_data_enrichment\"\n",
        "            ])),\n",
        "        \"createdAt\": created_at, \"updatedAt\": updated_at, \"name\": name_data, \"addresses\": addresses,\n",
        "        \"contactInfo\": [create_contact_data(primary=True, contact_type_override=kwargs.get(\"primary_contact_type\"), value_override=kwargs.get(\"primary_contact_value\"))] + \\\n",
        "                       ([create_contact_data(primary=False)] if random.random() < 0.6 else []) + \\\n",
        "                       ([create_contact_data(primary=False)] if random.random() < 0.3 else []), # More contacts\n",
        "        \"identifiers\": identifiers,\n",
        "        \"resolution\": {\"status\": \"unresolved\", \"masterEntityId\": None, \"confidence\": 0.0, \"linkedEntities\": [], \"lastReviewDate\": None, \"reviewedBy\": None},\n",
        "        \"watchlistMatches\": kwargs.get(\"watchlistMatches\", []),\n",
        "        \"customerInfo\": {\n",
        "            \"customerSince\": created_at - timedelta(days=random.randint(90, 365*5)), # Wider range for customer since\n",
        "            \"segments\": random.sample([\n",
        "                \"retail_banking\", \"private_wealth_management\", \"sme_lending\", \"corporate_banking_large\",\n",
        "                \"institutional_investor\", \"correspondent_banking\", \"mass_affluent\", \"student_accounts\"\n",
        "                ], k=random.randint(1,3)),\n",
        "            \"products\": random.sample([\n",
        "                \"checking_account_basic\", \"savings_plus_high_yield\", \"global_platinum_credit_card\",\n",
        "                \"commercial_real_estate_loan\", \"prime_residential_mortgage\", \"managed_investment_portfolio_aggressive\",\n",
        "                \"trade_finance_lc\", \"foreign_exchange_services\", \"digital_wallet_services\", \"business_overdraft_facility\"\n",
        "                ], k=random.randint(1,5)), # More products\n",
        "            \"notes\": fake.paragraph(nb_sentences=random.randint(1,2)) if random.random() < 0.2 else None\n",
        "        }\n",
        "    }\n",
        "    cust_info_ref = entity_doc[\"customerInfo\"] # Create a reference for easier use in summary\n",
        "\n",
        "    if entity_type == \"individual\":\n",
        "        entity_doc.update({\n",
        "            \"dateOfBirth\": kwargs.get(\"dob_str\") if kwargs.get(\"dob_str\", \"NOT_SET\") != \"NOT_SET\" else fake.date_of_birth(minimum_age=18, maximum_age=95).strftime(\"%Y-%m-%d\"),\n",
        "            \"placeOfBirth\": f\"{fake.city()}, {fake.country()}\",\n",
        "            \"gender\": random.choice([\"male\", \"female\", \"non_binary\", \"other\", \"undisclosed\"]),\n",
        "            \"nationality\": [addresses[0][\"structured\"][\"country\"], fake.country_code()] if random.random() < 0.25 else [addresses[0][\"structured\"][\"country\"]],\n",
        "            \"residency\": addresses[0][\"structured\"][\"country\"]\n",
        "        })\n",
        "        cust_info_ref.update({ # Use reference here\n",
        "            \"employmentStatus\": random.choice([\"employed\", \"self_employed\", \"unemployed\", \"student\", \"retired\", \"homemaker\", \"contractor\"]),\n",
        "            \"monthlyIncomeUSD\": random.randint(1000, 25000) if random.random() > 0.15 else None # Wider income range\n",
        "        })\n",
        "        if cust_info_ref[\"employmentStatus\"] in [\"employed\", \"self_employed\", \"contractor\"]:\n",
        "            cust_info_ref[\"occupation\"] = fake.job()\n",
        "            cust_info_ref[\"employer\"] = fake.company() if cust_info_ref[\"employmentStatus\"] == \"employed\" else \"Self-Employed/Contractor\"\n",
        "    else: # Organization\n",
        "        entity_doc.update({\n",
        "            \"incorporationDate\": fake.date_of_birth(minimum_age=1, maximum_age=100).strftime(\"%Y-%m-%d\"), # Wider range\n",
        "            \"jurisdictionOfIncorporation\": addresses[0][\"structured\"][\"country\"]\n",
        "        })\n",
        "        cust_info_ref.update({ # Use reference here\n",
        "            \"industry\": fake.bs(),\n",
        "            \"businessType\": random.choice([\n",
        "                \"sole_proprietorship\", \"partnership\", \"llc\", \"s_corporation\", \"c_corporation\",\n",
        "                \"non_profit_organization\", \"trust_entity\", \"holding_company\", \"joint_venture\", \"government_entity\"\n",
        "                ]),\n",
        "            \"numberOfEmployees\": random.randint(1, 15000) if random.random() > 0.1 else None, # Wider range\n",
        "            \"annualRevenueUSD\": random.randint(10000, 500000000) if random.random() > 0.1 else None # Wider range\n",
        "        })\n",
        "        # Add UBO Info\n",
        "        entity_doc[\"uboInfo\"] = kwargs.get(\"ubo_data\", generate_ubo_data(existing_individual_pool=existing_individual_pool))\n",
        "\n",
        "\n",
        "    # Allow kwargs to override any top-level or nested customerInfo fields\n",
        "    for k, v in kwargs.items():\n",
        "        if k == \"customerInfo\" and isinstance(v, dict):\n",
        "            cust_info_ref.update(v) # Use reference here\n",
        "        elif k in entity_doc and isinstance(entity_doc[k], dict) and isinstance(v, dict):\n",
        "             entity_doc[k].update(v)\n",
        "        elif k not in [ # list of kwargs handled by helper functions or specific logic above\n",
        "            \"first_name\", \"last_name\", \"company_name_base\", \"country_code\", \"city\",\n",
        "            \"address_risk\", \"past_country_code_0\", \"past_country_code_1\", \"dob_str\",\n",
        "            \"use_maiden_name_flag\", \"primary_address_struct\", \"primary_address_full\",\n",
        "            \"primary_address_verified\", \"num_ids\", \"force_no_ids\", \"specific_ids\",\n",
        "            \"primary_contact_type\", \"primary_contact_value\", \"source_system_override\",\n",
        "            \"ubo_data\", \"existing_individual_pool\", \"force_addr_risk\"\n",
        "            ]:\n",
        "            entity_doc[k] = v\n",
        "\n",
        "\n",
        "    overall_score, level, components = calculate_detailed_risk(entity_doc)\n",
        "    entity_doc[\"riskAssessment\"] = {\n",
        "        \"overall\": {\"score\": overall_score, \"level\": level, \"trend\": random.choice([\"stable\", \"increasing\", \"decreasing\"]),\n",
        "                    \"lastUpdated\": updated_at,\n",
        "                    \"nextScheduledReview\": updated_at + timedelta(days= (365 if level==\"low\" else (180 if level==\"medium\" else 60)) )}, # shorter review for high\n",
        "        \"components\": components,\n",
        "        \"history\": [{\"date\": updated_at, \"score\": overall_score, \"level\": level, \"changeTrigger\": \"initial_assessment\"}],\n",
        "        \"metadata\": {\"model\": \"aml_risk_v3.0\", \"assessmentType\": \"automated_initial\", \"overrides\": []}\n",
        "    }\n",
        "    if entity_doc[\"resolution\"][\"status\"] == \"resolved\" and not entity_doc[\"resolution\"].get(\"masterEntityId\"):\n",
        "        entity_doc[\"resolution\"][\"masterEntityId\"] = entity_doc[\"entityId\"]\n",
        "\n",
        "    # Enhanced Profile Summary Text\n",
        "    summary_parts = []\n",
        "    summary_parts.append(f\"Entity Name: {entity_doc['name']['full']}.\")\n",
        "    if entity_doc['name'].get('aliases'): summary_parts.append(f\"Aliases: {', '.join(entity_doc['name']['aliases'])}.\")\n",
        "\n",
        "    if entity_doc['entityType'] == 'individual':\n",
        "        summary_parts.append(f\"Type: Individual. DOB: {entity_doc.get('dateOfBirth', 'N/A')}. Gender: {entity_doc.get('gender', 'N/A')}.\")\n",
        "        summary_parts.append(f\"Nationality: {', '.join(entity_doc.get('nationality',[]))}. Residency: {entity_doc.get('residency','N/A')}.\")\n",
        "        if cust_info_ref.get('occupation'): summary_parts.append(f\"Occupation: {cust_info_ref['occupation']}.\")\n",
        "        if cust_info_ref.get('employer'): summary_parts.append(f\"Employer: {cust_info_ref['employer']}.\")\n",
        "        if cust_info_ref.get('employmentStatus'): summary_parts.append(f\"Employment: {cust_info_ref['employmentStatus']}.\")\n",
        "    else: # Organization\n",
        "        summary_parts.append(f\"Type: Organization. Incorporated: {entity_doc.get('incorporationDate', 'N/A')} in {entity_doc.get('jurisdictionOfIncorporation','N/A')}.\")\n",
        "        if cust_info_ref.get('industry'): summary_parts.append(f\"Industry: {cust_info_ref['industry']}.\")\n",
        "        if cust_info_ref.get('businessType'): summary_parts.append(f\"Business Type: {cust_info_ref['businessType']}.\")\n",
        "        if cust_info_ref.get('numberOfEmployees'): summary_parts.append(f\"Employees: {cust_info_ref['numberOfEmployees']}.\")\n",
        "        if entity_doc.get(\"uboInfo\"):\n",
        "            summary_parts.append(f\"UBOs Found: {len(entity_doc['uboInfo'])}.\")\n",
        "            for ubo_idx, ubo in enumerate(entity_doc[\"uboInfo\"][:2]): # Summarize first 2 UBOs\n",
        "                summary_parts.append(f\" UBO {ubo_idx+1}: {ubo['name']} ({ubo['entityType']}, {ubo['percentageOwnership']}% ownership).\")\n",
        "\n",
        "\n",
        "    primary_address_found = False\n",
        "    for addr_idx, addr in enumerate(entity_doc.get('addresses', [])):\n",
        "        if addr.get('primary') and not addr.get('validTo'):\n",
        "            primary_address_found = True\n",
        "            summary_parts.append(f\"Primary Address: {addr.get('full')}. Verified: {addr.get('verified')}.\")\n",
        "            break\n",
        "        elif not primary_address_found and addr_idx == 0: # Fallback to first address if no primary current\n",
        "             summary_parts.append(f\"Main Address: {addr.get('full')}. Verified: {addr.get('verified')}.\")\n",
        "\n",
        "    for id_obj in entity_doc.get(\"identifiers\", [])[:2]: # First 2 identifiers\n",
        "        summary_parts.append(f\"Identifier: {id_obj['type']} - {id_obj['value']} (Country: {id_obj['country']}, Verified: {id_obj['verified']}).\")\n",
        "\n",
        "    summary_parts.append(f\"Risk Level: {entity_doc.get('riskAssessment',{}).get('overall',{}).get('level','N/A')}.\")\n",
        "    summary_parts.append(f\"Risk Score: {entity_doc.get('riskAssessment',{}).get('overall',{}).get('score','N/A')}.\")\n",
        "\n",
        "    risk_components_calc = entity_doc.get('riskAssessment', {}).get('components', {}) # Use a different var name\n",
        "    for comp_name, comp_data in risk_components_calc.items():\n",
        "        if comp_data.get(\"factors\"):\n",
        "            summary_parts.append(f\"Key {comp_name.capitalize()} Risk Factors ({comp_data['score']}):\")\n",
        "            for factor in comp_data[\"factors\"][:2]: # Top 2 factors per component\n",
        "                 summary_parts.append(f\" - {factor.get('type', 'N/A')}: {factor.get('description', 'No description')[:100]}...\")\n",
        "\n",
        "    if entity_doc.get(\"watchlistMatches\"):\n",
        "        summary_parts.append(\"Watchlist Matches:\")\n",
        "        for match in entity_doc[\"watchlistMatches\"][:2]:\n",
        "            summary_parts.append(f\" - List: {match.get('listId', 'N/A')}, Status: {match.get('status', 'N/A')}, Score: {match.get('matchScore', 'N/A')}.\")\n",
        "\n",
        "    entity_doc[\"profileSummaryText\"] = \" \".join(summary_parts)\n",
        "    entity_doc[\"profileEmbedding\"] = get_embedding_from_bedrock_or_fallback(entity_doc[\"profileSummaryText\"], bedrock_runtime, EMBEDDING_MODEL_ID, EMBEDDING_DIMENSIONS)\n",
        "\n",
        "    return entity_doc\n",
        "\n",
        "print(\"Generating scenario-based entities with multiplication...\")\n",
        "all_entities_to_insert = []\n",
        "\n",
        "# --- Scenario Multiplication Factors ---\n",
        "NUM_CLEAR_DUPLICATE_SETS = 15\n",
        "NUM_PEP_INDIVIDUALS = 20\n",
        "NUM_EVOLVING_RISK_INDIVIDUALS = 10\n",
        "NUM_SANCTIONED_ORGANIZATIONS = 8\n",
        "NUM_COMPLEX_ORG_STRUCTURES = 5 # Each structure has multiple entities\n",
        "NUM_INCOMPLETE_DATA_INDIVIDUALS = 25\n",
        "NUM_HOUSEHOLD_SETS = 10 # Each set has 2 members\n",
        "NUM_SUBTLE_DUPLICATE_CLUSTERS = 8 # Each cluster has 3 members\n",
        "NUM_SHELL_COMPANY_CANDIDATES = 12\n",
        "NUM_HNWI_INDIVIDUALS = 15\n",
        "\n",
        "# --- SCENARIO 1: Clear Duplicate Pairs ---\n",
        "print(f\"Generating {NUM_CLEAR_DUPLICATE_SETS} sets of Clear Duplicates...\")\n",
        "for i in range(NUM_CLEAR_DUPLICATE_SETS):\n",
        "    dup_dob_s1 = fake.date_of_birth(minimum_age=25, maximum_age=60).strftime(\"%Y-%m-%d\")\n",
        "    base_last_name = fake.last_name()\n",
        "    s1_addr_struct_1 = {\"street\": fake.street_address(), \"city\": fake.city(), \"state\": fake.state_abbr(), \"postalCode\": fake.zipcode(), \"country\": \"US\"}\n",
        "    s1_addr_full_1 = f\"{s1_addr_struct_1['street']}, {s1_addr_struct_1['city']}, {s1_addr_struct_1['state']} {s1_addr_struct_1['postalCode']}, USA\"\n",
        "\n",
        "    ent_s1_dup1_id = generate_unique_id(f\"CDI{i}A\")\n",
        "    ent_s1_dup1 = generate_entity_template(\"individual\", scenario_key=f\"clear_duplicate_set{i}_1\", entityId=ent_s1_dup1_id,\n",
        "                                     first_name=fake.first_name(), last_name=base_last_name, dob_str=dup_dob_s1,\n",
        "                                     primary_address_struct=s1_addr_struct_1, primary_address_full=s1_addr_full_1,\n",
        "                                     primary_contact_type=\"email\", primary_contact_value=fake.email(),\n",
        "                                     resolution={\"status\": \"resolved\", \"masterEntityId\": ent_s1_dup1_id})\n",
        "    all_entities_to_insert.append(ent_s1_dup1); generated_entity_store[ent_s1_dup1_id] = ent_s1_dup1\n",
        "\n",
        "    s1_addr_struct_2 = {**s1_addr_struct_1, \"street\": fake.street_address()} # Different street, same city/state\n",
        "    s1_addr_full_2 = f\"{s1_addr_struct_2['street']}, {s1_addr_struct_2['city']}, {s1_addr_struct_2['state']} {s1_addr_struct_2['postalCode']}, USA\"\n",
        "    ent_s1_dup2_id = generate_unique_id(f\"CDI{i}B\")\n",
        "    ent_s1_dup2 = generate_entity_template(\"individual\", scenario_key=f\"clear_duplicate_set{i}_2\", entityId=ent_s1_dup2_id,\n",
        "                                     first_name=ent_s1_dup1[\"name\"][\"structured\"][\"first\"][:3], last_name=base_last_name, dob_str=dup_dob_s1, # Nickname\n",
        "                                     primary_address_struct=s1_addr_struct_2, primary_address_full=s1_addr_full_2,\n",
        "                                     primary_contact_type=\"phone_mobile\", primary_contact_value=fake.phone_number(),\n",
        "                                     resolution={\"status\": \"resolved\", \"masterEntityId\": ent_s1_dup1_id, \"confidence\": random.uniform(0.85, 0.95),\n",
        "                                                 \"linkedEntities\": [{\"entityId\": ent_s1_dup1_id, \"linkType\": \"confirmed_match\", \"confidence\": random.uniform(0.85,0.95), \"matchedAttributes\": [\"dob\", \"last_name\", \"address_city_state_zip_fuzzy\"], \"matchDate\": datetime.now(timezone.utc) - timedelta(days=random.randint(5,20)), \"decidedBy\": \"analyst_synthetic_01\", \"decision\": \"confirmed_match\"}],\n",
        "                                                 \"lastReviewDate\": datetime.now(timezone.utc) - timedelta(days=random.randint(5,20)), \"reviewedBy\": \"analyst_synthetic_01\"})\n",
        "    all_entities_to_insert.append(ent_s1_dup2); generated_entity_store[ent_s1_dup2_id] = ent_s1_dup2\n",
        "\n",
        "# --- SCENARIO 2: PEP Individuals ---\n",
        "print(f\"Generating {NUM_PEP_INDIVIDUALS} PEP Individuals...\")\n",
        "for i in range(NUM_PEP_INDIVIDUALS):\n",
        "    pep_id = generate_unique_id(f\"PEP{i}\")\n",
        "    pep_country = random.choice([\"US\", \"GB\", \"FR\", \"DE\", \"RU\", \"CN\", \"BR\", \"ZA\"])\n",
        "    pep_role = random.choice([\"Senator\", \"Minister\", \"Ambassador\", \"Head of State Enterprise\", \"Senior Judge\", \"Military General\"])\n",
        "    pep_entity_kwargs = {\n",
        "        \"entityId\":pep_id, \"first_name\":fake.first_name(), \"last_name\":fake.last_name() + \" (PEP)\", \"dob_str\":fake.date_of_birth(minimum_age=45, maximum_age=75).strftime(\"%Y-%m-%d\"),\n",
        "        \"country_code\":pep_country, \"address_risk\":\"medium\",\n",
        "        \"customerInfo\":{\"occupation\": pep_role, \"employmentStatus\": \"employed\", \"employer\": f\"{pep_country} Government Body\"},\n",
        "        \"watchlistMatches\":[\n",
        "            {\"listId\": f\"NATIONAL-PEP-{pep_country}\", \"matchId\": f\"PEP-{pep_id[:5]}\", \"matchScore\": 0.99, \"matchDate\": datetime.now(timezone.utc) - timedelta(days=random.randint(10,100)), \"status\": \"confirmed_hit\", \"details\": {\"role\": pep_role, \"country\": pep_country, \"source_reliability\":\"high\"}}\n",
        "        ],\n",
        "        \"status\": random.choice([\"active\", \"under_review\"])\n",
        "    }\n",
        "    pep_entity = generate_entity_template(\"individual\", scenario_key=f\"pep_individual_varied_{i}\", **pep_entity_kwargs)\n",
        "    all_entities_to_insert.append(pep_entity); generated_entity_store[pep_id] = pep_entity\n",
        "    potential_ubo_pool.append(pep_entity)\n",
        "\n",
        "# --- SCENARIO 3: Evolving Risk Individuals ---\n",
        "print(f\"Generating {NUM_EVOLVING_RISK_INDIVIDUALS} Evolving Risk Individuals...\")\n",
        "for i in range(NUM_EVOLVING_RISK_INDIVIDUALS):\n",
        "    evo_id = generate_unique_id(f\"EVO{i}\")\n",
        "    evo_country = random.choice([\"CA\", \"AU\", \"NZ\", \"US\", \"GB\"])\n",
        "    evolving_entity_kwargs = {\n",
        "        \"entityId\":evo_id, \"first_name\":fake.first_name(), \"last_name\":fake.last_name(), \"dob_str\":fake.date_of_birth(minimum_age=22, maximum_age=40).strftime(\"%Y-%m-%d\"),\n",
        "        \"country_code\":evo_country, \"address_risk\":\"low\", \"customerInfo\": {\"occupation\":fake.job(), \"employer\":fake.company()}\n",
        "    }\n",
        "    evolving_entity = generate_entity_template(\"individual\", scenario_key=f\"evolving_risk_individual_{i}\", **evolving_entity_kwargs)\n",
        "    evolving_entity[\"riskAssessment\"][\"overall\"].update({\"score\": random.randint(10,25), \"level\": \"low\"}) # Start low\n",
        "    evolving_entity[\"riskAssessment\"][\"components\"][\"profile\"][\"score\"] = random.randint(5,15)\n",
        "    evolving_entity[\"riskAssessment\"][\"components\"][\"identity\"][\"score\"] = random.randint(5,15)\n",
        "    evolving_entity[\"riskAssessment\"][\"history\"] = [{\"date\": evolving_entity[\"createdAt\"], \"score\": evolving_entity[\"riskAssessment\"][\"overall\"][\"score\"], \"level\": \"low\", \"changeTrigger\": \"initial_assessment\"}]\n",
        "    all_entities_to_insert.append(evolving_entity); generated_entity_store[evo_id] = evolving_entity\n",
        "\n",
        "# --- SCENARIO 4: Sanctioned Organizations ---\n",
        "print(f\"Generating {NUM_SANCTIONED_ORGANIZATIONS} Sanctioned Organizations...\")\n",
        "sanction_lists = {\n",
        "    \"OFAC-SDN-GEN\": {\"country\": \"US\", \"reason_keywords\": [\"terrorism\", \"proliferation\", \"narcotics\"]},\n",
        "    \"EU-CONSOLIDATED-GEN\": {\"country\": \"EU\", \"reason_keywords\": [\"undermining sovereignty\", \"human rights abuses\"]},\n",
        "    \"UN-SC-GEN\": {\"country\": \"UN\", \"reason_keywords\": [\"threat to peace\", \"arms embargo violation\"]},\n",
        "    \"UK-HMT-GEN\": {\"country\": \"GB\", \"reason_keywords\": [\"financial sanctions\", \"terrorism financing\"]}\n",
        "}\n",
        "for i in range(NUM_SANCTIONED_ORGANIZATIONS):\n",
        "    sanctioned_org_id = generate_unique_id(f\"SNO{i}\")\n",
        "    list_choice_key = random.choice(list(sanction_lists.keys()))\n",
        "    list_details = sanction_lists[list_choice_key]\n",
        "    org_country = random.choice([\"IR\", \"SY\", \"KP\", \"VE\", \"RU\", \"MM\"]) # High-risk countries\n",
        "\n",
        "    sanctioned_org_kwargs = {\n",
        "        \"entityId\":sanctioned_org_id, \"company_name_base\":fake.company_suffix().upper() + \" \" + fake.bs().capitalize().split(\" \")[0] + \" Global\",\n",
        "        \"country_code\":org_country, \"address_risk\":\"high\", \"force_addr_risk\":\"high\",\n",
        "        \"customerInfo\":{\"industry\": random.choice([\"Shipping\", \"Trading\", \"Manufacturing\", \"Financial Services\"]), \"businessType\": random.choice([\"c_corporation\", \"llc\", \"private_limited_company\"])},\n",
        "        \"watchlistMatches\":[\n",
        "            {\"listId\": list_choice_key, \"matchId\": f\"SANC-{org_country}-{i}\", \"matchScore\": random.uniform(0.95, 1.0), \"matchDate\": datetime.now(timezone.utc) - timedelta(days=random.randint(5,365)), \"status\": \"confirmed_hit\", \"details\": {\"reason\": f\"{random.choice(list_details['reason_keywords'])}, operating from {org_country}\"}}\n",
        "        ],\n",
        "        \"source_system_override\": \"regulatory_feed_processor\",\n",
        "        \"status\": random.choice([\"inactive\", \"restricted\", \"under_review\"])\n",
        "    }\n",
        "    sanctioned_org = generate_entity_template(\"organization\", scenario_key=f\"sanctioned_org_varied_{i}\", **sanctioned_org_kwargs)\n",
        "    all_entities_to_insert.append(sanctioned_org); generated_entity_store[sanctioned_org_id] = sanctioned_org\n",
        "\n",
        "# --- SCENARIO 5: Complex Org Structures ---\n",
        "print(f\"Generating {NUM_COMPLEX_ORG_STRUCTURES} Complex Organization Structures...\")\n",
        "for i in range(NUM_COMPLEX_ORG_STRUCTURES):\n",
        "    # Parent Company for structure 'i'\n",
        "    parent_co_id = generate_unique_id(f\"COPP{i}\")\n",
        "    parent_director_id = generate_unique_id(f\"DIRP{i}\")\n",
        "    parent_co_director = generate_entity_template(\"individual\", scenario_key=f\"director_parent_struct{i}\", entityId=parent_director_id,\n",
        "                                               first_name=fake.first_name(), last_name=fake.last_name(), dob_str=fake.date_of_birth(minimum_age=40, maximum_age=70).strftime(\"%Y-%m-%d\"),\n",
        "                                               country_code=random.choice([\"GB\", \"US\", \"LU\", \"CH\"]), customerInfo={\"occupation\":\"Executive Chairman\"})\n",
        "    all_entities_to_insert.append(parent_co_director); generated_entity_store[parent_director_id] = parent_co_director\n",
        "    potential_ubo_pool.append(parent_co_director)\n",
        "\n",
        "    parent_ubos = generate_ubo_data(num_ubos=1, existing_individual_pool=[parent_co_director])\n",
        "    parent_ubos[0][\"percentageOwnership\"] = random.uniform(30,70)\n",
        "    if random.random() < 0.5: # Add a corporate UBO or another individual UBO\n",
        "        if random.random() < 0.6 and len(potential_ubo_pool) > 1:\n",
        "            other_ubo_indiv = random.choice([p for p in potential_ubo_pool if p[\"entityId\"] != parent_director_id])\n",
        "            parent_ubos.append({\n",
        "                \"name\": other_ubo_indiv[\"name\"][\"full\"], \"entityType\":\"individual\", \"nationality\": other_ubo_indiv[\"nationality\"][0] if other_ubo_indiv.get(\"nationality\") else fake.country_code(),\n",
        "                \"percentageOwnership\": random.uniform(10,40), \"controlType\": \"indirect_ownership\", \"linkedEntityId\": other_ubo_indiv[\"entityId\"]\n",
        "            })\n",
        "        else:\n",
        "             parent_ubos.append({\n",
        "                \"name\": fake.company() + \" Investments\", \"entityType\": \"corporate\", \"countryOfIncorporation\": random.choice([\"KY\", \"VG\", \"PA\", \"LU\"]),\n",
        "                \"percentageOwnership\": random.uniform(10,40), \"controlType\": \"indirect_ownership_corporate\", \"linkedEntityId\": None\n",
        "            })\n",
        "\n",
        "    parent_co = generate_entity_template(\"organization\", scenario_key=f\"complex_org_parent_struct{i}\", entityId=parent_co_id,\n",
        "                                     company_name_base=fake.word().capitalize() + \" Group Holdings\", country_code=parent_co_director[\"residency\"], address_risk=\"low\",\n",
        "                                     customerInfo={\"businessType\":\"holding_company\", \"industry\":\"Diversified Global Investments\"}, ubo_data=parent_ubos)\n",
        "    all_entities_to_insert.append(parent_co); generated_entity_store[parent_co_id] = parent_co\n",
        "\n",
        "    # Subsidiaries for structure 'i' (1 to 3 subsidiaries)\n",
        "    num_subsidiaries = random.randint(1,3)\n",
        "    for j in range(num_subsidiaries):\n",
        "        sub_co_id = generate_unique_id(f\"COPS{i}_{j}\")\n",
        "        sub_director_id = generate_unique_id(f\"DIRS{i}_{j}\")\n",
        "        sub_director = generate_entity_template(\"individual\", scenario_key=f\"director_sub_struct{i}_{j}\", entityId=sub_director_id,\n",
        "                                                   first_name=fake.first_name(), last_name=fake.last_name(), dob_str=fake.date_of_birth(minimum_age=35, maximum_age=60).strftime(\"%Y-%m-%d\"),\n",
        "                                                   country_code=random.choice([\"DE\", \"FR\", \"SG\", \"HK\", \"AE\"]), customerInfo={\"occupation\":\"Managing Director\"})\n",
        "        all_entities_to_insert.append(sub_director); generated_entity_store[sub_director_id] = sub_director\n",
        "        potential_ubo_pool.append(sub_director)\n",
        "\n",
        "        sub_ubos = generate_ubo_data(num_ubos=random.randint(0,1), existing_individual_pool=[sub_director]) # Director might be UBO\n",
        "        # Parent company is also a UBO (as corporate shareholder)\n",
        "        sub_ubos.append({\n",
        "            \"name\": parent_co[\"name\"][\"full\"], \"entityType\": \"corporate\", \"countryOfIncorporation\": parent_co[\"jurisdictionOfIncorporation\"],\n",
        "            \"percentageOwnership\": random.uniform(51,100), \"controlType\": \"direct_ownership_corporate_parent\", \"linkedEntityId\": parent_co_id\n",
        "        })\n",
        "\n",
        "        sub_co = generate_entity_template(\"organization\", scenario_key=f\"complex_org_sub_struct{i}_{j}\", entityId=sub_co_id,\n",
        "                                         company_name_base=fake.bs().split(\" \")[0] + \" \" + random.choice([\"Tech\", \"Logistics\", \"Consulting\", \"Trading\"]),\n",
        "                                         country_code=sub_director[\"residency\"], address_risk=random.choice([\"low\",\"medium\"]),\n",
        "                                         customerInfo={\"industry\":fake.bs()}, ubo_data=sub_ubos)\n",
        "        all_entities_to_insert.append(sub_co); generated_entity_store[sub_co_id] = sub_co\n",
        "\n",
        "\n",
        "# --- SCENARIO 6: Individual with Incomplete Data ---\n",
        "print(f\"Generating {NUM_INCOMPLETE_DATA_INDIVIDUALS} Incomplete Data Individuals...\")\n",
        "for i in range(NUM_INCOMPLETE_DATA_INDIVIDUALS):\n",
        "    incomplete_id = generate_unique_id(f\"INC{i}\")\n",
        "    inc_country = random.choice([\"US\", \"GB\", \"CA\", \"AU\", \"??\"]) # ?? for unknown country sometimes\n",
        "    inc_kwargs = {\n",
        "        \"entityId\":incomplete_id, \"first_name\":fake.first_name() if random.random() > 0.3 else \"UnknownFN\",\n",
        "        \"last_name\":fake.last_name() if random.random() > 0.3 else \"UnknownLN\" + str(i),\n",
        "        \"dob_str\":None if random.random() > 0.4 else fake.date_of_birth(minimum_age=18, maximum_age=80).strftime(\"%Y-%m-%d\"),\n",
        "        \"primary_address_struct\": {\"street\": fake.street_name(), \"city\": fake.city() if random.random() > 0.2 else \"\", \"state\": \"\", \"postalCode\": fake.postcode()[:3] if random.random() > 0.3 else \"\", \"country\": inc_country},\n",
        "        \"primary_address_verified\": False,\n",
        "        \"force_no_ids\": random.random() > 0.5,\n",
        "        \"num_ids\": random.choices([0,1], weights=[0.6,0.4])[0], # More likely 0 or 1 ID\n",
        "        \"customerInfo\": {\"occupation\": None if random.random() > 0.3 else fake.job(), \"employmentStatus\":random.choice([\"unemployed\", \"self_employed\", \"other\"])},\n",
        "        \"source_system_override\": random.choice([\"manual_entry_branch\", \"legacy_data_import_errors\", \"web_form_unverified\"])\n",
        "    }\n",
        "    incomplete_entity = generate_entity_template(\"individual\", scenario_key=f\"incomplete_data_vague_{i}\", **inc_kwargs)\n",
        "    all_entities_to_insert.append(incomplete_entity); generated_entity_store[incomplete_id] = incomplete_entity\n",
        "\n",
        "# --- SCENARIO 7: Household Sets ---\n",
        "print(f\"Generating {NUM_HOUSEHOLD_SETS} Household Sets...\")\n",
        "for i in range(NUM_HOUSEHOLD_SETS):\n",
        "    household_addr_struct = {\"street\": fake.street_address(), \"city\": fake.city(), \"state\": fake.state_abbr(), \"postalCode\": fake.zipcode(), \"country\": \"US\"}\n",
        "    household_addr_full = f\"{household_addr_struct['street']}, {household_addr_struct['city']}, {household_addr_struct['state']} {household_addr_struct['postalCode']}, USA\"\n",
        "    common_last_name = fake.last_name()\n",
        "\n",
        "    member1_id = generate_unique_id(f\"CHMA{i}\")\n",
        "    member1 = generate_entity_template(\"individual\", scenario_key=f\"household_set{i}_member1\", entityId=member1_id,\n",
        "        first_name=fake.first_name_female(), last_name=common_last_name, dob_str=fake.date_of_birth(minimum_age=25, maximum_age=60).strftime(\"%Y-%m-%d\"),\n",
        "        primary_address_struct=household_addr_struct, primary_address_full=household_addr_full)\n",
        "    all_entities_to_insert.append(member1); generated_entity_store[member1_id] = member1\n",
        "\n",
        "    member2_id = generate_unique_id(f\"CHMB{i}\")\n",
        "    member2 = generate_entity_template(\"individual\", scenario_key=f\"household_set{i}_member2\", entityId=member2_id,\n",
        "        first_name=fake.first_name_male(), last_name=common_last_name, dob_str=fake.date_of_birth(minimum_age=25, maximum_age=60).strftime(\"%Y-%m-%d\"),\n",
        "        primary_address_struct=household_addr_struct, primary_address_full=household_addr_full,\n",
        "        use_maiden_name_flag= True if random.random() < 0.3 else False # One might have a maiden name alias\n",
        "        )\n",
        "    all_entities_to_insert.append(member2); generated_entity_store[member2_id] = member2\n",
        "    potential_ubo_pool.extend([member1, member2])\n",
        "\n",
        "\n",
        "# --- SCENARIO 8: Subtle Duplicate Clusters ---\n",
        "print(f\"Generating {NUM_SUBTLE_DUPLICATE_CLUSTERS} Subtle Duplicate Clusters...\")\n",
        "for i in range(NUM_SUBTLE_DUPLICATE_CLUSTERS):\n",
        "    sdup_dob = fake.date_of_birth(minimum_age=28, maximum_age=55).strftime(\"%Y-%m-%d\")\n",
        "    sdup_last_name_base = fake.last_name()\n",
        "    sdup_addr_base_street = fake.street_address()\n",
        "    sdup_addr_city = fake.city()\n",
        "    sdup_addr_country = random.choice([\"US\", \"CA\", \"GB\"])\n",
        "    sdup_state = fake.state_abbr() if sdup_addr_country == \"US\" else fake.province_abbr() if sdup_addr_country == \"CA\" else \"\"\n",
        "    sdup_zip = fake.zipcode() if sdup_addr_country == \"US\" else fake.postcode()\n",
        "    sdup_phone = fake.phone_number()\n",
        "\n",
        "    # Master for this cluster\n",
        "    sdup_ent1_id = generate_unique_id(f\"SDP{i}A\")\n",
        "    sdup_ent1_fn = fake.first_name()\n",
        "    sdup_ent1 = generate_entity_template(\"individual\", scenario_key=f\"subtle_dup_cluster{i}_1_master\", entityId=sdup_ent1_id,\n",
        "                                     first_name=sdup_ent1_fn, last_name=sdup_last_name_base, dob_str=sdup_dob,\n",
        "                                     primary_address_struct={\"street\": sdup_addr_base_street, \"city\": sdup_addr_city, \"state\":sdup_state, \"postalCode\":sdup_zip, \"country\":sdup_addr_country},\n",
        "                                     primary_contact_type=\"email\", primary_contact_value=fake.email(),\n",
        "                                     resolution={\"status\": \"resolved\", \"masterEntityId\": sdup_ent1_id})\n",
        "    all_entities_to_insert.append(sdup_ent1); generated_entity_store[sdup_ent1_id] = sdup_ent1\n",
        "\n",
        "    # Duplicate 2\n",
        "    sdup_ent2_id = generate_unique_id(f\"SDP{i}B\")\n",
        "    sdup_ent2 = generate_entity_template(\"individual\", scenario_key=f\"subtle_dup_cluster{i}_2_variant\", entityId=sdup_ent2_id,\n",
        "                                     first_name=sdup_ent1_fn, middle_name=fake.first_name()[:1] if random.random() < 0.7 else \"\", last_name=sdup_last_name_base, dob_str=sdup_dob,\n",
        "                                     primary_address_struct={\"street\": f\"{sdup_addr_base_street}, Apt {random.randint(1,100)}{random.choice(['A','B','C',''])}\", \"city\": sdup_addr_city, \"state\":sdup_state, \"postalCode\":sdup_zip, \"country\":sdup_addr_country},\n",
        "                                     primary_contact_type=\"phone_mobile\", primary_contact_value=sdup_phone, # Shared phone\n",
        "                                     resolution={\"status\": \"under_review\", \"masterEntityId\": None, \"confidence\": random.uniform(0.6, 0.8),\n",
        "                                                 \"linkedEntities\": [{\"entityId\": sdup_ent1_id, \"linkType\": \"potential_duplicate\", \"confidence\": random.uniform(0.6,0.8), \"matchedAttributes\": [\"dob\", \"last_name\", \"address_fuzzy_street_city\", \"shared_phone_candidate\"], \"matchDate\": datetime.now(timezone.utc) - timedelta(days=random.randint(1,10)), \"decidedBy\": \"system_er_v2.1\", \"decision\": \"under_review\"}]})\n",
        "    all_entities_to_insert.append(sdup_ent2); generated_entity_store[sdup_ent2_id] = sdup_ent2\n",
        "\n",
        "    # Duplicate 3\n",
        "    sdup_ent3_id = generate_unique_id(f\"SDP{i}C\")\n",
        "    dob_alt_format = datetime.strptime(sdup_dob, \"%Y-%m-%d\").strftime(\"%d/%m/%Y\") if random.random() < 0.5 else sdup_dob # Mix DOB format\n",
        "\n",
        "    # Define the addresses for sdup_ent3 separately for clarity\n",
        "    sdup_ent3_addresses = [\n",
        "        create_address_data(primary=True, country_code=sdup_addr_country, city=fake.city()), # A different current primary address\n",
        "        create_address_data( # This is the past address linking to the cluster\n",
        "            primary=False,\n",
        "            address_type=\"previous\", # This flag will ensure validTo is set in the past by create_address_data\n",
        "            structured={\n",
        "                \"street\": sdup_addr_base_street,\n",
        "                \"city\": sdup_addr_city,\n",
        "                \"state\":sdup_state,\n",
        "                \"postalCode\":sdup_zip,\n",
        "                \"country\":sdup_addr_country\n",
        "            }\n",
        "            # REMOVE validTo=datetime.now(timezone.utc)-timedelta(days=random.randint(200,500)) from here\n",
        "        )\n",
        "    ]\n",
        "    # The create_address_data function when address_type=\"previous\" or primary=False and it's not the first address\n",
        "    # will internally set a validTo in the past. If you need more specific control for THIS EXACT past address's validTo,\n",
        "    # you would generate it and then modify it:\n",
        "    # sdup_ent3_addresses[1][\"validTo\"] = datetime.now(timezone.utc)-timedelta(days=random.randint(200,500)) # If specific control needed AFTER generation\n",
        "\n",
        "    sdup_ent3 = generate_entity_template(\"individual\", scenario_key=f\"subtle_dup_cluster{i}_3_weaklinks\", entityId=sdup_ent3_id,\n",
        "                                     first_name=sdup_ent1_fn[0] + \".\", last_name=sdup_last_name_base[:-1] + random.choice(['s','z','x']) if random.random() < 0.5 else sdup_last_name_base, # Initial, typo\n",
        "                                     dob_str=dob_alt_format,\n",
        "                                     addresses = sdup_ent3_addresses, # Assign the pre-generated list\n",
        "                                     primary_contact_type=\"phone_mobile\", primary_contact_value=sdup_phone, # Shared phone\n",
        "                                     resolution={\"status\": \"unresolved\"})\n",
        "    all_entities_to_insert.append(sdup_ent3); generated_entity_store[sdup_ent3_id] = sdup_ent3\n",
        "\n",
        "\n",
        "# --- SCENARIO 9: Shell Company Candidates ---\n",
        "print(f\"Generating {NUM_SHELL_COMPANY_CANDIDATES} Shell Company Candidates...\")\n",
        "for i in range(NUM_SHELL_COMPANY_CANDIDATES):\n",
        "    shell_co_id = generate_unique_id(f\"SHL{i}\")\n",
        "    nominee_director_id = generate_unique_id(f\"NOMD{i}\")\n",
        "    nom_country = random.choice([\"VG\", \"KY\", \"PA\", \"SC\", \"BZ\", \"MT\", \"CY\"]) # Typical nominee/offshore jurisdictions\n",
        "    nominee_director = generate_entity_template(\"individual\", scenario_key=f\"nominee_director_shell{i}\", entityId=nominee_director_id,\n",
        "                                                first_name=random.choice([\"Generic\",\"Nominee\",\"Service\"]), last_name=\"Director \" + str(random.randint(1000,9999)),\n",
        "                                                dob_str=None, country_code=nom_country, address_risk=\"high\", force_addr_risk=\"high\",\n",
        "                                                customerInfo={\"occupation\":\"Corporate Services Provider\"}, force_no_ids=True if random.random() < 0.7 else False)\n",
        "    all_entities_to_insert.append(nominee_director); generated_entity_store[nominee_director_id] = nominee_director\n",
        "    potential_ubo_pool.append(nominee_director)\n",
        "\n",
        "    shell_ubos = generate_ubo_data(num_ubos=1, existing_individual_pool=[nominee_director])\n",
        "    shell_ubos[0][\"percentageOwnership\"] = 100.0\n",
        "    shell_ubos[0][\"controlType\"] = \"nominee_shareholder_director\"\n",
        "    if random.random() < 0.2: # Sometimes, another layer of corporate UBO\n",
        "        shell_ubos.append({\n",
        "            \"name\": fake.company() + \" Offshore Holdings Ltd.\", \"entityType\": \"corporate\", \"countryOfIncorporation\": random.choice([\"PA\", \"VG\", \"SC\"]),\n",
        "            \"percentageOwnership\": 100.0, \"controlType\": \"corporate_beneficiary_unspecified_ultimate\", \"linkedEntityId\": None\n",
        "        })\n",
        "\n",
        "\n",
        "    shell_co_country = random.choice([\"KY\", \"VG\", \"PA\", \"AE\", \"HK\", \"SG\", \"MT\", \"CY\"]) # Shells can be in various places\n",
        "    shell_co = generate_entity_template(\"organization\", scenario_key=f\"shell_company_candidate_var{i}\", entityId=shell_co_id,\n",
        "                                    company_name_base=random.choice([\"Alpha\", \"Beta\", \"Omega\", \"Prime\", \"Global\", \"Universal\", \"Strategic\", \"Dynamic\"]) + \" \" + random.choice([\"Consultants\", \"Trading\", \"Ventures\", \"Holdings\", \"Management\", \"Services\"]) + \" Ltd.\",\n",
        "                                    country_code=shell_co_country, address_risk=\"high\", force_addr_risk=\"high\",\n",
        "                                    customerInfo={\"industry\": \"General Business Activities / Holding\", \"businessType\": \"international_business_company\", \"numberOfEmployees\": random.randint(0,3), \"annualRevenueUSD\": random.randint(0, 10000) if random.random() < 0.8 else None},\n",
        "                                    ubo_data=shell_ubos, source_system_override=\"csp_onboarding_platform\",\n",
        "                                    status=random.choice([\"active\",\"dormant_pending_strike_off\"]))\n",
        "    shell_co[\"customerInfo\"][\"businessType\"] = \"shell_company_suspected\"\n",
        "    all_entities_to_insert.append(shell_co); generated_entity_store[shell_co_id] = shell_co\n",
        "\n",
        "# --- SCENARIO 10: High Net Worth Individuals ---\n",
        "print(f\"Generating {NUM_HNWI_INDIVIDUALS} HNWIs...\")\n",
        "for i in range(NUM_HNWI_INDIVIDUALS):\n",
        "    hnwi_id = generate_unique_id(f\"HNWI{i}\")\n",
        "    primary_country = random.choice([\"CH\", \"SG\", \"LU\", \"MC\", \"GB\", \"US\"]) # Typical HNW residences\n",
        "    hnwi_city = \"Geneva\" if primary_country == \"CH\" else \"Singapore\" if primary_country == \"SG\" else \"Luxembourg City\" if primary_country == \"LU\" else \"Monaco\" if primary_country == \"MC\" else fake.city()\n",
        "\n",
        "    hnwi_primary_addr_struct = {\"street\": fake.street_address(), \"city\": hnwi_city, \"state\": \"\", \"postalCode\": fake.postcode(), \"country\": primary_country}\n",
        "\n",
        "    hnwi_specific_ids_list = [create_identifier_data(\"individual\", primary_country, id_type=\"passport\")]\n",
        "    if random.random() < 0.7: hnwi_specific_ids_list.append(create_identifier_data(\"individual\", primary_country, id_type=\"national_id\"))\n",
        "    if random.random() < 0.5: hnwi_specific_ids_list.append(create_identifier_data(\"individual\", random.choice([\"US\",\"GB\", \"CA\"]), id_type=\"tax_id\")) # Foreign tax id\n",
        "\n",
        "    hnwi_instance = generate_entity_template(\"individual\", scenario_key=f\"hnwi_global_investor_{i}\", entityId=hnwi_id,\n",
        "                                    first_name=fake.first_name_nonbinary(), last_name=fake.last_name(), dob_str=fake.date_of_birth(minimum_age=40, maximum_age=75).strftime(\"%Y-%m-%d\"),\n",
        "                                    primary_address_struct=hnwi_primary_addr_struct, address_risk=\"low\",\n",
        "                                    customerInfo={\n",
        "                                        \"occupation\":random.choice([\"Private Equity Investor\", \"Real Estate Developer\", \"Retired Entrepreneur\", \"Art Collector\", \"Hedge Fund Manager\"]), \"employmentStatus\":\"self_employed\",\n",
        "                                        \"segments\":[\"private_wealth_management\", \"global_family_office_services\"],\n",
        "                                        \"products\":random.sample([\"managed_investment_portfolio_bespoke\", \"offshore_trust_complex\", \"jumbo_mortgage_luxury_property\", \"art_secured_loan\", \"private_jet_financing\", \"philanthropic_advisory_services\"], k=random.randint(2,4)),\n",
        "                                        \"monthlyIncomeUSD\": random.randint(75000, 750000)\n",
        "                                        },\n",
        "                                    specific_ids = hnwi_specific_ids_list\n",
        "                                    )\n",
        "    # Add secondary/tertiary addresses in different (potentially medium/high risk) jurisdictions\n",
        "    num_other_hnw_addrs = random.randint(1,2)\n",
        "    for k in range(num_other_hnw_addrs):\n",
        "        other_addr_country = random.choice([\"KY\", \"AE\", \"MT\", \"CY\", \"PA\", \"BS\", \"VG\"] if random.random() < 0.4 else [\"GB\", \"FR\", \"US\", \"DE\"]) # Mix of offshore and major financial centers\n",
        "        other_addr_risk = \"high\" if other_addr_country in [\"KY\", \"AE\", \"MT\", \"CY\", \"PA\", \"BS\", \"VG\"] else \"medium\"\n",
        "        hnwi_instance[\"addresses\"].append(create_address_data(primary=False, country_code=other_addr_country, risk_level=other_addr_risk, address_type=random.choice([\"investment_property\", \"vacation_home_address\", \"business_correspondence_offshore\"])))\n",
        "\n",
        "    all_entities_to_insert.append(hnwi_instance); generated_entity_store[hnwi_id] = hnwi_instance\n",
        "    potential_ubo_pool.append(hnwi_instance)\n",
        "\n",
        "\n",
        "# --- INCREASE GENERIC ENTITIES ---\n",
        "NUM_GENERIC_INDIVIDUALS = 200 # Further increased\n",
        "NUM_GENERIC_ORGANIZATIONS = 100  # Further increased\n",
        "\n",
        "print(f\"Generating {NUM_GENERIC_INDIVIDUALS} generic individuals...\")\n",
        "for i in range(NUM_GENERIC_INDIVIDUALS):\n",
        "    ent_id = generate_unique_id(f\"CGI{i}\")\n",
        "    entity = generate_entity_template(\"individual\", scenario_key=\"generic_individual\", entityId=ent_id,\n",
        "                                      existing_individual_pool=potential_ubo_pool if i < NUM_GENERIC_INDIVIDUALS * 0.05 else None) # Smaller % links to existing UBO pool\n",
        "    all_entities_to_insert.append(entity); generated_entity_store[ent_id] = entity\n",
        "    if random.random() < 0.15: # Add 15% of generic individuals to UBO pool for future orgs\n",
        "        potential_ubo_pool.append(entity)\n",
        "\n",
        "print(f\"Generating {NUM_GENERIC_ORGANIZATIONS} generic organizations...\")\n",
        "for i in range(NUM_GENERIC_ORGANIZATIONS):\n",
        "    ent_id = generate_unique_id(f\"CGO{i}\")\n",
        "    entity = generate_entity_template(\"organization\", scenario_key=\"generic_organization\", entityId=ent_id,\n",
        "                                      existing_individual_pool=potential_ubo_pool if len(potential_ubo_pool)>0 else None)\n",
        "    all_entities_to_insert.append(entity); generated_entity_store[ent_id] = entity\n",
        "\n",
        "# --- Insert all entities ---\n",
        "if all_entities_to_insert:\n",
        "    print(f\"\\nTotal entities to insert: {len(all_entities_to_insert)}\")\n",
        "    print(f\"Attempting to insert entities into '{entities_collection.name}' collection...\")\n",
        "    try:\n",
        "        entities_collection.drop()\n",
        "        result = entities_collection.insert_many(all_entities_to_insert, ordered=False)\n",
        "        print(f\"Successfully inserted {len(result.inserted_ids)} entities.\")\n",
        "    except pymongo.errors.BulkWriteError as bwe:\n",
        "        print(\"Bulk write error during entity insertion:\")\n",
        "        for error_detail in bwe.details.get('writeErrors', []): print(f\"  Index: {error_detail['index']}, Code: {error_detail['code']}, Message: {error_detail['errmsg']}\")\n",
        "    except Exception as e: print(f\"An error occurred during entity insertion: {e}\")\n",
        "else: print(\"No entities were generated to insert.\")\n",
        "\n",
        "print(\"\\n--- Entity Seeding with Scenario Multiplication Complete ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. `relationships` Collection\n",
        "\n",
        "*   **Schema:** (Your schema is good)\n",
        "    *   `_id`: `ObjectId()`\n",
        "    *   `relationshipId`: String (e.g., \"REL\" + random) - **Unique**\n",
        "    *   `source`: { `entityId`, `entityType` }\n",
        "    *   `target`: { `entityId`, `entityType` }\n",
        "    *   `type`: String (e.g., \"potential_duplicate\", \"confirmed_same_entity\", \"household_member\", \"business_associate\", \"director_of\", \"shareholder_of\", \"transactional_link\")\n",
        "    *   `subType`: String (optional)\n",
        "    *   `direction`: \"bidirectional\", \"directed\" (source->target)\n",
        "    *   `strength`: Number (0-1, especially for ER or inferred links)\n",
        "    *   `active`: Boolean\n",
        "    *   `verified`, `verifiedBy`, `verificationDate`\n",
        "    *   `evidence`: Array of Objects [{ `type`, `attribute`, `similarity`, `details` }]\n",
        "    *   `created`, `updated`, `validFrom`, `validTo`: `ISODate()`\n",
        "    *   `riskContribution`, `riskDirection`, `riskFactors`\n",
        "    *   `datasource`: String (e.g., \"entity_resolution\", \"manual_investigation\", \"transaction_analysis\")\n",
        "    *   `confidence`: Number\n",
        "    *   `notes`, `tags`\n",
        "    *   `createdBy`, `reviewStatus`, `reviewDate`, `reviewedBy`\n",
        "*   **Data Tweaks for `relationships`:**\n",
        "    1.  Populate based on the ER \"duplicate\" scenarios defined for entities.\n",
        "        *   If Entity A and B are duplicates, create a `confirmed_same_entity` relationship.\n",
        "    2.  Create explicit relationships:\n",
        "        *   Entity H (`Peter Jones`) `director_of` Org G.\n",
        "        *   Entity H (`Peter Jones`) `shareholder_of` Org I.\n",
        "        *   Entity X and Y `household_member` (share same primary residential address).\n",
        "    3.  Some relationships should be `active: false` or have `validTo` in the past to show temporal graph changes."
      ],
      "metadata": {
        "id": "UeuC4VeCW_rG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NEW RELATIONSHIPS"
      ],
      "metadata": {
        "id": "VWfYB7SPW0L4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relationships_collection = db[\"relationships\"]\n",
        "entities_collection = db[\"entities\"] # Assumed to be populated\n",
        "\n",
        "# --- Helper: Get Entity Reference for Relationships ---\n",
        "def get_entity_ref_details(entity_id_val):\n",
        "    \"\"\"Fetches entityId, entityType, and full name for context.\"\"\"\n",
        "    if not entity_id_val: return None\n",
        "    entity_doc = entities_collection.find_one(\n",
        "        {\"entityId\": entity_id_val},\n",
        "        {\"entityId\": 1, \"entityType\": 1, \"name.full\": 1, \"_id\": 0}\n",
        "    )\n",
        "    if entity_doc:\n",
        "        return {\"entityId\": entity_doc[\"entityId\"], \"entityType\": entity_doc[\"entityType\"], \"name\": entity_doc.get(\"name\", {}).get(\"full\")}\n",
        "    # print(f\"WARN: Entity with entityId '{entity_id_val}' not found for relationship.\")\n",
        "    return None\n",
        "\n",
        "def get_entity_ref_by_scenario(scenario_key_val):\n",
        "    \"\"\"Fetches entityId and entityType by scenarioKey.\"\"\"\n",
        "    if not scenario_key_val: return None\n",
        "    entity_doc = entities_collection.find_one(\n",
        "        {\"scenarioKey\": scenario_key_val},\n",
        "        {\"entityId\": 1, \"entityType\": 1, \"_id\": 0}\n",
        "    )\n",
        "    if entity_doc:\n",
        "        return {\"entityId\": entity_doc[\"entityId\"], \"entityType\": entity_doc[\"entityType\"]}\n",
        "    # print(f\"WARN: Entity with scenarioKey '{scenario_key_val}' not found for relationship ref.\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# --- Relationship Template ---\n",
        "def generate_relationship_template(**kwargs):\n",
        "    created_at = kwargs.get(\"created_at\", fake.date_time_between(start_date=\"-4y\", end_date=\"-1d\", tzinfo=timezone.utc))\n",
        "    updated_at = fake.date_time_between(start_date=created_at, end_date=\"now\", tzinfo=timezone.utc)\n",
        "\n",
        "    source_ref = kwargs.get(\"source_ref\")\n",
        "    target_ref = kwargs.get(\"target_ref\")\n",
        "\n",
        "    if not source_ref or not target_ref or not source_ref.get(\"entityId\") or not target_ref.get(\"entityId\"):\n",
        "        # print(f\"ERROR: Source or Target ref is None or missing entityId. Cannot create relationship. Source: {source_ref}, Target: {target_ref}\")\n",
        "        return None\n",
        "\n",
        "    rel_type = kwargs.get(\"type\")\n",
        "    default_strength = 1.0\n",
        "    if rel_type in [\"potential_duplicate\", \"inferred_transactional_link\", \"social_media_connection_public\", \"known_associate_unverified\", \"business_associate_suspected\"]:\n",
        "        default_strength = round(random.uniform(0.3, 0.75), 2)\n",
        "    elif rel_type in [\"confirmed_same_entity\", \"shareholder_of\", \"director_of\", \"ubo_of\", \"parent_of_subsidiary\", \"household_member\"]:\n",
        "        default_strength = round(random.uniform(0.9, 1.0), 2)\n",
        "\n",
        "    default_confidence = default_strength\n",
        "    if rel_type == \"potential_duplicate\":\n",
        "        default_confidence = round(random.uniform(0.4, 0.8), 2)\n",
        "\n",
        "    rel = {\n",
        "        \"_id\": ObjectId(),\n",
        "        \"relationshipId\": f\"REL-{uuid.uuid4().hex[:10].upper()}\",\n",
        "        \"source\": {\"entityId\": source_ref[\"entityId\"], \"entityType\": source_ref[\"entityType\"]},\n",
        "        \"target\": {\"entityId\": target_ref[\"entityId\"], \"entityType\": target_ref[\"entityType\"]},\n",
        "        \"type\": rel_type,\n",
        "        \"subType\": kwargs.get(\"sub_type\"),\n",
        "        \"direction\": kwargs.get(\"direction\", \"bidirectional\" if rel_type not in [\"director_of\", \"ubo_of\", \"parent_of_subsidiary\", \"potential_beneficial_owner_of\"] else \"directed\"),\n",
        "        \"strength\": kwargs.get(\"strength\", default_strength),\n",
        "        \"active\": kwargs.get(\"active\", True),\n",
        "        \"verified\": kwargs.get(\"verified\", rel_type not in [\"potential_duplicate\", \"inferred_transactional_link\", \"social_media_connection_public\", \"known_associate_unverified\", \"business_associate_suspected\"]),\n",
        "        \"verifiedBy\": kwargs.get(\"verified_by\"),\n",
        "        \"verificationDate\": kwargs.get(\"verification_date\"),\n",
        "        \"evidence\": kwargs.get(\"evidence\", []),\n",
        "        \"created\": created_at,\n",
        "        \"updated\": updated_at,\n",
        "        \"validFrom\": kwargs.get(\"valid_from\", created_at - timedelta(days=random.randint(0, 365*3))),\n",
        "        \"validTo\": kwargs.get(\"valid_to\"),\n",
        "        \"riskContribution\": kwargs.get(\"risk_contribution\", round(random.uniform(0.05, 0.6), 2) if kwargs.get(\"active\", True) else 0.0),\n",
        "        \"datasource\": kwargs.get(\"datasource\", \"synthetic_aml_rules_engine_v3.1\"),\n",
        "        \"confidence\": kwargs.get(\"confidence\", default_confidence),\n",
        "        \"notes\": kwargs.get(\"notes\"),\n",
        "        \"tags\": kwargs.get(\"tags\", []),\n",
        "        \"createdBy\": kwargs.get(\"created_by\", \"system_data_gen_aml_v3\"),\n",
        "        \"reviewStatus\": kwargs.get(\"review_status\"),\n",
        "        \"reviewDate\": kwargs.get(\"review_date\"),\n",
        "        \"reviewedBy\": kwargs.get(\"reviewed_by\")\n",
        "    }\n",
        "\n",
        "    if not rel.get(\"reviewStatus\"):\n",
        "        rel[\"reviewStatus\"] = \"confirmed_verified\" if rel[\"verified\"] else \"pending_review\"\n",
        "\n",
        "    if rel[\"verified\"] and not rel.get(\"verifiedBy\"):\n",
        "        rel[\"verifiedBy\"] = \"system_auto_verified_data_load\"\n",
        "        rel[\"verificationDate\"] = rel[\"created\"] + timedelta(days=random.randint(1,10))\n",
        "\n",
        "    for key in [\"subType\", \"verifiedBy\", \"verificationDate\", \"validTo\", \"notes\", \"tags\", \"reviewDate\", \"reviewedBy\"]:\n",
        "        if rel.get(key) is None:\n",
        "            if key in rel: del rel[key]\n",
        "\n",
        "    if rel.get(\"validTo\") and rel.get(\"validFrom\"):\n",
        "        if rel[\"validTo\"] <= rel[\"validFrom\"]:\n",
        "            rel[\"validTo\"] = rel[\"validFrom\"] + timedelta(days=random.randint(30, 730))\n",
        "        if not rel[\"active\"] and rel.get(\"validTo\") and rel[\"validTo\"] > datetime.now(timezone.utc):\n",
        "            rel[\"validTo\"] = datetime.now(timezone.utc) - timedelta(days=random.randint(1,30))\n",
        "            if rel[\"validFrom\"] >= rel[\"validTo\"]:\n",
        "                 rel[\"validFrom\"] = rel[\"validTo\"] - timedelta(days=random.randint(30,100))\n",
        "    elif not rel[\"active\"] and not rel.get(\"validTo\"):\n",
        "        rel[\"validTo\"] = rel.get(\"updated\", rel[\"created\"]) - timedelta(days=random.randint(1, 365))\n",
        "        if rel.get(\"validFrom\") and rel[\"validFrom\"] >= rel[\"validTo\"]:\n",
        "            rel[\"validFrom\"] = rel[\"validTo\"] - timedelta(days=random.randint(30,100))\n",
        "    return rel\n",
        "\n",
        "# --- Define NUM_ constants (MUST MATCH YOUR ENTITY GENERATION SCRIPT) ---\n",
        "NUM_CLEAR_DUPLICATE_SETS = 15\n",
        "NUM_PEP_INDIVIDUALS = 20\n",
        "NUM_EVOLVING_RISK_INDIVIDUALS = 10\n",
        "NUM_SANCTIONED_ORGANIZATIONS = 8\n",
        "NUM_COMPLEX_ORG_STRUCTURES = 5\n",
        "# NUM_INCOMPLETE_DATA_INDIVIDUALS = 25 # Not directly used\n",
        "NUM_HOUSEHOLD_SETS = 10\n",
        "NUM_SUBTLE_DUPLICATE_CLUSTERS = 8\n",
        "NUM_SHELL_COMPANY_CANDIDATES = 12\n",
        "NUM_HNWI_INDIVIDUALS = 15\n",
        "# --- End of NUM_ constants ---\n",
        "\n",
        "# Enhanced Relationships Collection Generation\n",
        "# This replaces the existing relationships generation code starting from \"all_relationships_to_insert = []\"\n",
        "# Creates 500-600 relationships with multi-hop patterns (up to 4 degrees)\n",
        "# Excludes geographic proximity and transaction-based relationships as requested\n",
        "\n",
        "all_relationships_to_insert = []\n",
        "print(\"Generating enhanced relationships with multi-hop patterns...\")\n",
        "\n",
        "# Store relationships by entity for multi-hop generation\n",
        "entity_relationships_map = {}\n",
        "\n",
        "def add_relationship_to_map(rel):\n",
        "    \"\"\"Helper to track relationships for multi-hop generation\"\"\"\n",
        "    if rel and rel.get(\"source\") and rel.get(\"target\"):\n",
        "        source_id = rel[\"source\"][\"entityId\"]\n",
        "        target_id = rel[\"target\"][\"entityId\"]\n",
        "\n",
        "        if source_id not in entity_relationships_map:\n",
        "            entity_relationships_map[source_id] = {\"outgoing\": [], \"incoming\": []}\n",
        "        if target_id not in entity_relationships_map:\n",
        "            entity_relationships_map[target_id] = {\"outgoing\": [], \"incoming\": []}\n",
        "\n",
        "        entity_relationships_map[source_id][\"outgoing\"].append(target_id)\n",
        "        entity_relationships_map[target_id][\"incoming\"].append(source_id)\n",
        "\n",
        "# --- 1. Entity Resolution Links (Duplicates) - Enhanced ---\n",
        "print(f\"Creating ER links for {NUM_CLEAR_DUPLICATE_SETS} Clear Duplicate sets...\")\n",
        "for i in range(NUM_CLEAR_DUPLICATE_SETS):\n",
        "    master_ref = get_entity_ref_by_scenario(f\"clear_duplicate_set{i}_1\")\n",
        "    dup_ref = get_entity_ref_by_scenario(f\"clear_duplicate_set{i}_2\")\n",
        "\n",
        "    if master_ref and dup_ref:\n",
        "        dup_entity_doc = entities_collection.find_one({\"entityId\": dup_ref[\"entityId\"]}, {\"resolution\": 1})\n",
        "        er_confidence = dup_entity_doc.get(\"resolution\", {}).get(\"confidence\", 0.92) if dup_entity_doc else 0.92\n",
        "        rel_er = generate_relationship_template(\n",
        "            source_ref=master_ref, target_ref=dup_ref, type=\"confirmed_same_entity\",\n",
        "            direction=\"bidirectional\", strength=1.0, confidence=er_confidence, verified=True,\n",
        "            verified_by=\"analyst_synthetic_01\", verification_date=datetime.now(timezone.utc) - timedelta(days=random.randint(5,20)),\n",
        "            evidence=[\n",
        "                {\"type\": \"attribute_match\", \"attribute\": \"dob\", \"similarity\": 1.0, \"details\": \"Exact DOB match\"},\n",
        "                {\"type\": \"attribute_match\", \"attribute\": \"last_name\", \"similarity\": 1.0, \"details\": \"Exact last name match\"},\n",
        "                {\"type\": \"attribute_match\", \"attribute\": \"address_fuzzy\", \"similarity\": round(random.uniform(0.8,0.95),2), \"details\": \"Highly similar address components\"}\n",
        "            ],\n",
        "            datasource=\"entity_resolution_engine_v3\", notes=f\"Resolved as duplicate for set {i}.\"\n",
        "        )\n",
        "        if rel_er:\n",
        "            all_relationships_to_insert.append(rel_er)\n",
        "            add_relationship_to_map(rel_er)\n",
        "\n",
        "print(f\"Creating ER links for {NUM_SUBTLE_DUPLICATE_CLUSTERS} Subtle Duplicate Clusters...\")\n",
        "for i in range(NUM_SUBTLE_DUPLICATE_CLUSTERS):\n",
        "    master_ref = get_entity_ref_by_scenario(f\"subtle_dup_cluster{i}_1_master\")\n",
        "    variant2_ref = get_entity_ref_by_scenario(f\"subtle_dup_cluster{i}_2_variant\")\n",
        "    variant3_ref = get_entity_ref_by_scenario(f\"subtle_dup_cluster{i}_3_weaklinks\")\n",
        "\n",
        "    if master_ref and variant2_ref:\n",
        "        var2_entity_doc = entities_collection.find_one({\"entityId\": variant2_ref[\"entityId\"]}, {\"resolution\": 1})\n",
        "        er_conf_v2 = var2_entity_doc.get(\"resolution\", {}).get(\"confidence\", 0.75) if var2_entity_doc else 0.75\n",
        "        er_status_v2 = var2_entity_doc.get(\"resolution\", {}).get(\"status\", \"under_review\") if var2_entity_doc else \"under_review\"\n",
        "        rel_er_v2 = generate_relationship_template(\n",
        "            source_ref=master_ref, target_ref=variant2_ref, type=\"potential_duplicate\",\n",
        "            strength=er_conf_v2, confidence=er_conf_v2, verified= (er_status_v2 == \"resolved\"),\n",
        "            review_status= \"confirmed_match\" if er_status_v2 == \"resolved\" else \"pending_further_review\",\n",
        "            evidence=[{\"type\":\"multiple_attribute_weak_match\", \"details\":\"Matches on DOB, partial name, fuzzy address, potential shared phone.\"}],\n",
        "            datasource=\"entity_resolution_fuzzy_matcher_v2\", notes=f\"Potential duplicate in cluster {i} (variant 2).\"\n",
        "        )\n",
        "        if rel_er_v2:\n",
        "            all_relationships_to_insert.append(rel_er_v2)\n",
        "            add_relationship_to_map(rel_er_v2)\n",
        "\n",
        "    if master_ref and variant3_ref:\n",
        "         rel_er_v3 = generate_relationship_template(\n",
        "            source_ref=master_ref, target_ref=variant3_ref, type=\"potential_duplicate\",\n",
        "            strength=round(random.uniform(0.5,0.7),2), confidence=round(random.uniform(0.5,0.7),2), verified=False,\n",
        "            review_status= \"requires_manual_investigation\",\n",
        "            evidence=[{\"type\":\"shared_phone_past_address\", \"details\":\"Shared phone number, and past address matches master's current.\"}],\n",
        "            datasource=\"entity_resolution_linker_v1\", notes=f\"Weak potential duplicate in cluster {i} (variant 3).\"\n",
        "        )\n",
        "         if rel_er_v3:\n",
        "            all_relationships_to_insert.append(rel_er_v3)\n",
        "            add_relationship_to_map(rel_er_v3)\n",
        "\n",
        "# --- 2. Enhanced Organizational Structure & UBO Links with Multi-Level ---\n",
        "print(f\"Creating Enhanced Organizational Structure & UBO links for {NUM_COMPLEX_ORG_STRUCTURES} structures...\")\n",
        "for i in range(NUM_COMPLEX_ORG_STRUCTURES):\n",
        "    parent_co_ref = get_entity_ref_by_scenario(f\"complex_org_parent_struct{i}\")\n",
        "    parent_director_ref = get_entity_ref_by_scenario(f\"director_parent_struct{i}\")\n",
        "\n",
        "    if not parent_co_ref:\n",
        "        continue\n",
        "\n",
        "    if parent_director_ref:\n",
        "        rel_dir_parent = generate_relationship_template(\n",
        "            source_ref=parent_director_ref, target_ref=parent_co_ref, type=\"director_of\", direction=\"directed\",\n",
        "            sub_type=\"Executive Chairman/CEO\", strength=1.0, verified=True,\n",
        "            evidence=[{\"type\":\"company_registry_simulated\", \"doc_ref\":f\"REG-P{i}-DIR\"}]\n",
        "        )\n",
        "        if rel_dir_parent:\n",
        "            all_relationships_to_insert.append(rel_dir_parent)\n",
        "            add_relationship_to_map(rel_dir_parent)\n",
        "\n",
        "    parent_co_doc = entities_collection.find_one({\"entityId\": parent_co_ref[\"entityId\"]}, {\"uboInfo\":1, \"name\":1})\n",
        "    if parent_co_doc and parent_co_doc.get(\"uboInfo\"):\n",
        "        for ubo in parent_co_doc[\"uboInfo\"]:\n",
        "            ubo_source_entity_ref = None\n",
        "            if ubo.get(\"linkedEntityId\"):\n",
        "                ubo_source_entity_ref = get_entity_ref_details(ubo[\"linkedEntityId\"])\n",
        "\n",
        "            if ubo_source_entity_ref:\n",
        "                rel_ubo_parent = generate_relationship_template(\n",
        "                    source_ref=ubo_source_entity_ref, target_ref=parent_co_ref, type=\"ubo_of\", direction=\"directed\",\n",
        "                    sub_type=f\"{ubo.get('percentageOwnership', '')}% ownership via {ubo.get('controlType','N/A')}\", strength=1.0, verified=True,\n",
        "                    evidence=[{\"type\":\"ubo_registry_declaration_simulated\", \"doc_ref\":f\"UBO-P{i}-{ubo_source_entity_ref['entityId'][:4]}\"}],\n",
        "                    notes=f\"UBO {ubo.get('name', ubo_source_entity_ref.get('name','N/A'))} for {parent_co_ref.get('name', parent_co_ref['entityId'])}\"\n",
        "                )\n",
        "                if rel_ubo_parent:\n",
        "                    all_relationships_to_insert.append(rel_ubo_parent)\n",
        "                    add_relationship_to_map(rel_ubo_parent)\n",
        "\n",
        "    # Create subsidiaries and their relationships\n",
        "    for j in range(3):\n",
        "        sub_co_ref = get_entity_ref_by_scenario(f\"complex_org_sub_struct{i}_{j}\")\n",
        "        if not sub_co_ref: continue\n",
        "\n",
        "        sub_director_ref = get_entity_ref_by_scenario(f\"director_sub_struct{i}_{j}\")\n",
        "\n",
        "        rel_parent_sub = generate_relationship_template(\n",
        "            source_ref=parent_co_ref, target_ref=sub_co_ref, type=\"parent_of_subsidiary\", direction=\"directed\",\n",
        "            sub_type=\"Majority Owned\", strength=1.0, verified=True,\n",
        "            evidence=[{\"type\":\"group_structure_filing_sim\", \"doc_ref\":f\"GRP-STRUCT-{i}-{j}\"}]\n",
        "        )\n",
        "        if rel_parent_sub:\n",
        "            all_relationships_to_insert.append(rel_parent_sub)\n",
        "            add_relationship_to_map(rel_parent_sub)\n",
        "\n",
        "        if sub_director_ref:\n",
        "            rel_dir_sub = generate_relationship_template(\n",
        "                source_ref=sub_director_ref, target_ref=sub_co_ref, type=\"director_of\", direction=\"directed\",\n",
        "                sub_type=\"Managing Director\", strength=1.0, verified=True,\n",
        "                evidence=[{\"type\":\"company_registry_simulated\", \"doc_ref\":f\"REG-S{i}{j}-DIR\"}]\n",
        "            )\n",
        "            if rel_dir_sub:\n",
        "                all_relationships_to_insert.append(rel_dir_sub)\n",
        "                add_relationship_to_map(rel_dir_sub)\n",
        "\n",
        "# --- 3. Enhanced Business Relationships Between Organizations ---\n",
        "print(\"Creating enhanced business relationships between organizations...\")\n",
        "all_orgs = list(entities_collection.find(\n",
        "    {\"entityType\": \"organization\"},\n",
        "    {\"entityId\":1, \"entityType\":1, \"name.full\":1, \"customerInfo.industry\":1, \"jurisdictionOfIncorporation\":1}\n",
        ").limit(100))\n",
        "\n",
        "if len(all_orgs) >= 20:\n",
        "    # Create supplier-customer relationships\n",
        "    for _ in range(40):  # Increased from 30\n",
        "        if len(all_orgs) < 2: break\n",
        "        supplier, customer = random.sample(all_orgs, 2)\n",
        "\n",
        "        rel_business = generate_relationship_template(\n",
        "            source_ref={\"entityId\": supplier[\"entityId\"], \"entityType\": \"organization\", \"name\": supplier.get(\"name\",{}).get(\"full\")},\n",
        "            target_ref={\"entityId\": customer[\"entityId\"], \"entityType\": \"organization\", \"name\": customer.get(\"name\",{}).get(\"full\")},\n",
        "            type=\"supplier_of\", direction=\"directed\",\n",
        "            sub_type=random.choice([\"Primary Supplier\", \"Secondary Supplier\", \"Exclusive Supplier\"]),\n",
        "            strength=round(random.uniform(0.6,0.9),2), verified=True,\n",
        "            evidence=[{\"type\":\"contract_database\", \"doc_ref\":f\"CONTRACT-{uuid.uuid4().hex[:8]}\"}],\n",
        "            datasource=\"procurement_system_integration\"\n",
        "        )\n",
        "        if rel_business:\n",
        "            all_relationships_to_insert.append(rel_business)\n",
        "            add_relationship_to_map(rel_business)\n",
        "\n",
        "    # Create joint venture relationships\n",
        "    for _ in range(40):  # Increased from 25  # Increased from 15\n",
        "        if len(all_orgs) < 2: break\n",
        "        partner1, partner2 = random.sample(all_orgs, 2)\n",
        "\n",
        "        rel_jv = generate_relationship_template(\n",
        "            source_ref={\"entityId\": partner1[\"entityId\"], \"entityType\": \"organization\", \"name\": partner1.get(\"name\",{}).get(\"full\")},\n",
        "            target_ref={\"entityId\": partner2[\"entityId\"], \"entityType\": \"organization\", \"name\": partner2.get(\"name\",{}).get(\"full\")},\n",
        "            type=\"joint_venture_partner\", direction=\"bidirectional\",\n",
        "            sub_type=f\"{random.randint(30,70)}%-{100-random.randint(30,70)}% Partnership\",\n",
        "            strength=round(random.uniform(0.7,0.95),2), verified=True,\n",
        "            evidence=[{\"type\":\"jv_agreement\", \"doc_ref\":f\"JV-{uuid.uuid4().hex[:8]}\"}],\n",
        "            datasource=\"corporate_filings_database\"\n",
        "        )\n",
        "        if rel_jv:\n",
        "            all_relationships_to_insert.append(rel_jv)\n",
        "            add_relationship_to_map(rel_jv)\n",
        "\n",
        "# --- 4. Professional Service Provider Networks ---\n",
        "print(\"Creating professional service provider networks...\")\n",
        "# Get some HNWIs and organizations to link to service providers\n",
        "hnwi_list = list(entities_collection.find(\n",
        "    {\"scenarioKey\": {\"$regex\": \"^hnwi_global_investor_\"}},\n",
        "    {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        ").limit(NUM_HNWI_INDIVIDUALS))\n",
        "\n",
        "shell_companies = list(entities_collection.find(\n",
        "    {\"scenarioKey\": {\"$regex\": \"^shell_company_candidate_var\"}},\n",
        "    {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        ").limit(NUM_SHELL_COMPANY_CANDIDATES))\n",
        "\n",
        "# Create a few professional service providers (lawyers, accountants)\n",
        "service_providers = []\n",
        "for i in range(12):  # Increased from 8\n",
        "    provider_type = random.choice([\"law_firm\", \"accounting_firm\", \"wealth_management_firm\", \"trust_company\"])\n",
        "    provider_name = f\"{fake.last_name()} & {fake.last_name()} {provider_type.replace('_', ' ').title()}\"\n",
        "\n",
        "    # Find or create a generic org to be the service provider\n",
        "    provider_entity = entities_collection.find_one(\n",
        "        {\"entityType\": \"organization\", \"scenarioKey\": \"generic_organization\"},\n",
        "        {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        "    )\n",
        "\n",
        "    if provider_entity:\n",
        "        service_providers.append({\n",
        "            \"entityId\": provider_entity[\"entityId\"],\n",
        "            \"entityType\": \"organization\",\n",
        "            \"name\": provider_entity.get(\"name\",{}).get(\"full\"),\n",
        "            \"service_type\": provider_type\n",
        "        })\n",
        "\n",
        "# Link HNWIs and shell companies to service providers\n",
        "for provider in service_providers[:6]:  # Use first 6 providers (increased from 4)\n",
        "    # Each provider serves multiple clients\n",
        "    num_clients = random.randint(5, 12)  # Increased from (3, 8)\n",
        "    potential_clients = hnwi_list + shell_companies\n",
        "\n",
        "    if len(potential_clients) >= num_clients:\n",
        "        clients = random.sample(potential_clients, num_clients)\n",
        "\n",
        "        for client in clients:\n",
        "            service_type_map = {\n",
        "                \"law_firm\": \"legal_advisor_for\",\n",
        "                \"accounting_firm\": \"accountant_for\",\n",
        "                \"wealth_management_firm\": \"wealth_manager_for\",\n",
        "                \"trust_company\": \"trustee_for\"\n",
        "            }\n",
        "\n",
        "            rel_service = generate_relationship_template(\n",
        "                source_ref=provider,\n",
        "                target_ref={\"entityId\": client[\"entityId\"], \"entityType\": client[\"entityType\"], \"name\": client.get(\"name\",{}).get(\"full\")},\n",
        "                type=service_type_map.get(provider[\"service_type\"], \"professional_service_provider\"),\n",
        "                direction=\"directed\",\n",
        "                strength=round(random.uniform(0.7,0.9),2),\n",
        "                verified=random.random() > 0.3,\n",
        "                evidence=[{\"type\":\"client_onboarding_record\", \"doc_ref\":f\"CLIENT-{uuid.uuid4().hex[:8]}\"}],\n",
        "                datasource=\"professional_services_database\",\n",
        "                notes=f\"{provider['name']} provides {provider['service_type'].replace('_', ' ')} services\"\n",
        "            )\n",
        "            if rel_service:\n",
        "                all_relationships_to_insert.append(rel_service)\n",
        "                add_relationship_to_map(rel_service)\n",
        "\n",
        "# --- 5. Multi-Hop Criminal/Suspicious Networks ---\n",
        "print(\"Creating multi-hop suspicious networks...\")\n",
        "# Get sanctioned organizations and PEPs as network centers\n",
        "sanctioned_orgs = list(entities_collection.find(\n",
        "    {\"scenarioKey\": {\"$regex\": \"^sanctioned_org_varied_\"}},\n",
        "    {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        ").limit(NUM_SANCTIONED_ORGANIZATIONS))\n",
        "\n",
        "peps = list(entities_collection.find(\n",
        "    {\"scenarioKey\": {\"$regex\": \"^pep_individual_varied_\"}},\n",
        "    {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        ").limit(NUM_PEP_INDIVIDUALS))\n",
        "\n",
        "# Create layered networks around high-risk entities\n",
        "for center_entity in (sanctioned_orgs[:5] + peps[:5]):  # Use 5 of each as network centers (increased from 3)\n",
        "    # First hop - direct associates\n",
        "    num_direct_associates = random.randint(3, 6)  # Increased from (2, 4)\n",
        "    potential_associates = list(entities_collection.find(\n",
        "        {\"entityType\": {\"$in\": [\"individual\", \"organization\"]}, \"entityId\": {\"$ne\": center_entity[\"entityId\"]}},\n",
        "        {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        "    ).limit(20))\n",
        "\n",
        "    if len(potential_associates) >= num_direct_associates:\n",
        "        direct_associates = random.sample(potential_associates, num_direct_associates)\n",
        "\n",
        "        for associate in direct_associates:\n",
        "            rel_type = random.choice([\n",
        "                \"business_associate_suspected\",\n",
        "                \"financial_beneficiary_suspected\",\n",
        "                \"proxy_relationship_suspected\"\n",
        "            ])\n",
        "\n",
        "            rel_first_hop = generate_relationship_template(\n",
        "                source_ref={\"entityId\": center_entity[\"entityId\"], \"entityType\": center_entity[\"entityType\"], \"name\": center_entity.get(\"name\",{}).get(\"full\")},\n",
        "                target_ref={\"entityId\": associate[\"entityId\"], \"entityType\": associate[\"entityType\"], \"name\": associate.get(\"name\",{}).get(\"full\")},\n",
        "                type=rel_type,\n",
        "                direction=\"bidirectional\",\n",
        "                strength=round(random.uniform(0.5,0.8),2),\n",
        "                verified=False,\n",
        "                review_status=\"high_priority_investigation\",\n",
        "                evidence=[{\"type\":\"transaction_pattern_analysis\", \"details\":\"Suspicious transaction patterns detected\"}],\n",
        "                datasource=\"network_analysis_engine\",\n",
        "                risk_contribution=round(random.uniform(0.3,0.7),2)\n",
        "            )\n",
        "            if rel_first_hop:\n",
        "                all_relationships_to_insert.append(rel_first_hop)\n",
        "                add_relationship_to_map(rel_first_hop)\n",
        "\n",
        "            # Second hop - associates of associates\n",
        "            if random.random() < 0.8:  # Increased from 0.6\n",
        "                second_hop_candidates = list(entities_collection.find(\n",
        "                    {\"entityType\": associate[\"entityType\"],\n",
        "                     \"entityId\": {\"$nin\": [center_entity[\"entityId\"], associate[\"entityId\"]]}},\n",
        "                    {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        "                ).limit(10))\n",
        "\n",
        "                if second_hop_candidates:\n",
        "                    second_hop_entity = random.choice(second_hop_candidates)\n",
        "\n",
        "                    rel_second_hop = generate_relationship_template(\n",
        "                        source_ref={\"entityId\": associate[\"entityId\"], \"entityType\": associate[\"entityType\"], \"name\": associate.get(\"name\",{}).get(\"full\")},\n",
        "                        target_ref={\"entityId\": second_hop_entity[\"entityId\"], \"entityType\": second_hop_entity[\"entityType\"], \"name\": second_hop_entity.get(\"name\",{}).get(\"full\")},\n",
        "                        type=random.choice([\"known_associate_unverified\", \"business_partner\", \"financial_link_suspected\"]),\n",
        "                        direction=\"bidirectional\",\n",
        "                        strength=round(random.uniform(0.4,0.7),2),\n",
        "                        verified=False,\n",
        "                        datasource=\"extended_network_analysis\",\n",
        "                        notes=\"Second-degree connection in suspicious network\"\n",
        "                    )\n",
        "                    if rel_second_hop:\n",
        "                        all_relationships_to_insert.append(rel_second_hop)\n",
        "                        add_relationship_to_map(rel_second_hop)\n",
        "\n",
        "                    # Third hop - occasionally\n",
        "                    if random.random() < 0.5:  # Increased from 0.3\n",
        "                        third_hop_candidates = list(entities_collection.find(\n",
        "                            {\"entityId\": {\"$nin\": [center_entity[\"entityId\"], associate[\"entityId\"], second_hop_entity[\"entityId\"]]}},\n",
        "                            {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        "                        ).limit(5))\n",
        "\n",
        "                        if third_hop_candidates:\n",
        "                            third_hop_entity = random.choice(third_hop_candidates)\n",
        "\n",
        "                            rel_third_hop = generate_relationship_template(\n",
        "                                source_ref={\"entityId\": second_hop_entity[\"entityId\"], \"entityType\": second_hop_entity[\"entityType\"], \"name\": second_hop_entity.get(\"name\",{}).get(\"full\")},\n",
        "                                target_ref={\"entityId\": third_hop_entity[\"entityId\"], \"entityType\": third_hop_entity[\"entityType\"], \"name\": third_hop_entity.get(\"name\",{}).get(\"full\")},\n",
        "                                type=\"peripheral_connection\",\n",
        "                                direction=\"bidirectional\",\n",
        "                                strength=round(random.uniform(0.3,0.5),2),\n",
        "                                verified=False,\n",
        "                                datasource=\"deep_network_analysis\",\n",
        "                                notes=\"Third-degree connection in extended network\"\n",
        "                            )\n",
        "                            if rel_third_hop:\n",
        "                                all_relationships_to_insert.append(rel_third_hop)\n",
        "                                add_relationship_to_map(rel_third_hop)\n",
        "\n",
        "# --- 6. Family and Extended Social Networks ---\n",
        "print(\"Creating extended family and social networks...\")\n",
        "# Extend household relationships to include extended family\n",
        "household_members = list(entities_collection.find(\n",
        "    {\"scenarioKey\": {\"$regex\": \"^household_set.*_member\"}},\n",
        "    {\"entityId\":1, \"entityType\":1, \"name.full\":1, \"scenarioKey\":1}\n",
        "))\n",
        "\n",
        "# Create extended family relationships\n",
        "for member in household_members[:20]:  # Process first 20 household members (increased from 10)\n",
        "    # Add parents, siblings, in-laws\n",
        "    extended_family_candidates = list(entities_collection.find(\n",
        "        {\"entityType\": \"individual\", \"entityId\": {\"$ne\": member[\"entityId\"]}},\n",
        "        {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        "    ).limit(15))\n",
        "\n",
        "    if len(extended_family_candidates) >= 3:\n",
        "        num_family = random.randint(1, 3)\n",
        "        family_members = random.sample(extended_family_candidates, num_family)\n",
        "\n",
        "        for family in family_members:\n",
        "            rel_type = random.choice([\n",
        "                \"family_member_parent\", \"family_member_sibling\",\n",
        "                \"family_member_child\", \"family_member_in_law\"\n",
        "            ])\n",
        "\n",
        "            rel_family = generate_relationship_template(\n",
        "                source_ref={\"entityId\": member[\"entityId\"], \"entityType\": \"individual\", \"name\": member.get(\"name\",{}).get(\"full\")},\n",
        "                target_ref={\"entityId\": family[\"entityId\"], \"entityType\": \"individual\", \"name\": family.get(\"name\",{}).get(\"full\")},\n",
        "                type=rel_type,\n",
        "                direction=\"bidirectional\",\n",
        "                strength=round(random.uniform(0.8,0.95),2),\n",
        "                verified=True,\n",
        "                evidence=[{\"type\":\"identity_document_relationship\", \"details\":\"Family relationship verified through documentation\"}],\n",
        "                datasource=\"kyc_family_verification\"\n",
        "            )\n",
        "            if rel_family:\n",
        "                all_relationships_to_insert.append(rel_family)\n",
        "                add_relationship_to_map(rel_family)\n",
        "\n",
        "# --- 7. Financial Institution Relationships ---\n",
        "print(\"Creating financial institution relationships...\")\n",
        "# Get financial services organizations\n",
        "fin_orgs = list(entities_collection.find(\n",
        "    {\"entityType\": \"organization\", \"$or\": [\n",
        "        {\"customerInfo.industry\": {\"$regex\": \"financ|bank|invest\", \"$options\": \"i\"}},\n",
        "        {\"name.full\": {\"$regex\": \"bank|financial|capital|invest\", \"$options\": \"i\"}}\n",
        "    ]},\n",
        "    {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        ").limit(20))\n",
        "\n",
        "# Create lending relationships\n",
        "individuals_needing_loans = list(entities_collection.find(\n",
        "    {\"entityType\": \"individual\"},\n",
        "    {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        ").limit(50))\n",
        "\n",
        "if fin_orgs and individuals_needing_loans:\n",
        "    for _ in range(25):\n",
        "        lender = random.choice(fin_orgs)\n",
        "        borrower = random.choice(individuals_needing_loans)\n",
        "\n",
        "        loan_type = random.choice([\n",
        "            \"mortgage_loan\", \"personal_loan\", \"business_loan\",\n",
        "            \"line_of_credit\", \"auto_loan\"\n",
        "        ])\n",
        "\n",
        "        rel_loan = generate_relationship_template(\n",
        "            source_ref={\"entityId\": lender[\"entityId\"], \"entityType\": \"organization\", \"name\": lender.get(\"name\",{}).get(\"full\")},\n",
        "            target_ref={\"entityId\": borrower[\"entityId\"], \"entityType\": borrower[\"entityType\"], \"name\": borrower.get(\"name\",{}).get(\"full\")},\n",
        "            type=\"loan_provider_for\",\n",
        "            sub_type=loan_type,\n",
        "            direction=\"directed\",\n",
        "            strength=round(random.uniform(0.7,0.9),2),\n",
        "            verified=True,\n",
        "            evidence=[{\"type\":\"loan_agreement\", \"doc_ref\":f\"LOAN-{uuid.uuid4().hex[:8]}\"}],\n",
        "            datasource=\"lending_platform\",\n",
        "            additional_details={\"loan_amount\": random.randint(10000, 1000000)}\n",
        "        )\n",
        "        if rel_loan:\n",
        "            all_relationships_to_insert.append(rel_loan)\n",
        "            add_relationship_to_map(rel_loan)\n",
        "\n",
        "# --- 8. Employment and Board Networks ---\n",
        "print(\"Creating employment and board member networks...\")\n",
        "# Get organizations and individuals for employment relationships\n",
        "orgs_for_employment = list(entities_collection.find(\n",
        "    {\"entityType\": \"organization\"},\n",
        "    {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        ").limit(50))\n",
        "\n",
        "individuals_for_employment = list(entities_collection.find(\n",
        "    {\"entityType\": \"individual\", \"customerInfo.employmentStatus\": {\"$in\": [\"employed\", \"self_employed\"]}},\n",
        "    {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        ").limit(100))\n",
        "\n",
        "if orgs_for_employment and individuals_for_employment:\n",
        "    # Create employment relationships\n",
        "    for _ in range(60):  # Increased from 40\n",
        "        employer = random.choice(orgs_for_employment)\n",
        "        employee = random.choice(individuals_for_employment)\n",
        "\n",
        "        employment_type = random.choice([\n",
        "            \"full_time_employee\", \"contractor\", \"consultant\",\n",
        "            \"part_time_employee\", \"advisor\"\n",
        "        ])\n",
        "\n",
        "        rel_employment = generate_relationship_template(\n",
        "            source_ref={\"entityId\": employee[\"entityId\"], \"entityType\": \"individual\", \"name\": employee.get(\"name\",{}).get(\"full\")},\n",
        "            target_ref={\"entityId\": employer[\"entityId\"], \"entityType\": \"organization\", \"name\": employer.get(\"name\",{}).get(\"full\")},\n",
        "            type=\"employed_by\",\n",
        "            sub_type=employment_type,\n",
        "            direction=\"directed\",\n",
        "            strength=round(random.uniform(0.7,0.95),2),\n",
        "            verified=True,\n",
        "            evidence=[{\"type\":\"employment_verification\", \"doc_ref\":f\"EMP-{uuid.uuid4().hex[:8]}\"}],\n",
        "            datasource=\"hr_system_integration\"\n",
        "        )\n",
        "        if rel_employment:\n",
        "            all_relationships_to_insert.append(rel_employment)\n",
        "            add_relationship_to_map(rel_employment)\n",
        "\n",
        "    # Create board member relationships (individuals serving on multiple boards)\n",
        "    board_candidates = random.sample(individuals_for_employment, min(20, len(individuals_for_employment)))\n",
        "\n",
        "    for board_member in board_candidates[:15]:  # Increased from 10\n",
        "        # Each board member serves on 2-5 boards (increased from 2-4)\n",
        "        num_boards = random.randint(2, 5)\n",
        "        if len(orgs_for_employment) >= num_boards:\n",
        "            boards = random.sample(orgs_for_employment, num_boards)\n",
        "\n",
        "            for org in boards:\n",
        "                rel_board = generate_relationship_template(\n",
        "                    source_ref={\"entityId\": board_member[\"entityId\"], \"entityType\": \"individual\", \"name\": board_member.get(\"name\",{}).get(\"full\")},\n",
        "                    target_ref={\"entityId\": org[\"entityId\"], \"entityType\": \"organization\", \"name\": org.get(\"name\",{}).get(\"full\")},\n",
        "                    type=\"board_member_of\",\n",
        "                    sub_type=random.choice([\"Independent Director\", \"Executive Director\", \"Advisory Board\"]),\n",
        "                    direction=\"directed\",\n",
        "                    strength=0.9,\n",
        "                    verified=True,\n",
        "                    evidence=[{\"type\":\"board_appointment\", \"doc_ref\":f\"BOARD-{uuid.uuid4().hex[:8]}\"}],\n",
        "                    datasource=\"corporate_governance_db\"\n",
        "                )\n",
        "                if rel_board:\n",
        "                    all_relationships_to_insert.append(rel_board)\n",
        "                    add_relationship_to_map(rel_board)\n",
        "\n",
        "# --- Keep existing relationship types from original code ---\n",
        "# (Include the household, high-risk entity links, past relationships, social links, and evolving risk relationships)\n",
        "# [Original code sections would be inserted here]\n",
        "# --- 3. Household Links ---\n",
        "print(f\"Creating Household links for {NUM_HOUSEHOLD_SETS} sets...\")\n",
        "for i in range(NUM_HOUSEHOLD_SETS):\n",
        "    member1_ref = get_entity_ref_by_scenario(f\"household_set{i}_member1\")\n",
        "    member2_ref = get_entity_ref_by_scenario(f\"household_set{i}_member2\")\n",
        "\n",
        "    if member1_ref and member2_ref:\n",
        "        rel_household = generate_relationship_template(\n",
        "            source_ref=member1_ref, target_ref=member2_ref, type=\"household_member\",\n",
        "            direction=\"bidirectional\", strength=0.95, verified=True,\n",
        "            evidence=[{\"type\": \"shared_primary_address_confirmed\", \"details\": f\"Shared address for household set {i}.\"}],\n",
        "            datasource=\"synthetic_scenario_design_v2\"\n",
        "        )\n",
        "        if rel_household: all_relationships_to_insert.append(rel_household)\n",
        "\n",
        "# --- 4. Links involving High-Risk / Watchlisted Entities ---\n",
        "print(\"Creating links involving High-Risk/Watchlisted entities...\")\n",
        "pep_sample = list(entities_collection.find({\"scenarioKey\": {\"$regex\": \"^pep_individual_varied_\"}}, {\"entityId\":1, \"entityType\":1, \"name.full\":1}).limit(NUM_PEP_INDIVIDUALS // 2 + 1))\n",
        "hnwi_sample = list(entities_collection.find({\"scenarioKey\": {\"$regex\": \"^hnwi_global_investor_\"}}, {\"entityId\":1, \"entityType\":1, \"name.full\":1}).limit(NUM_HNWI_INDIVIDUALS // 2 + 1))\n",
        "shell_co_sample = list(entities_collection.find({\"scenarioKey\": {\"$regex\": \"^shell_company_candidate_var\"}}, {\"entityId\":1, \"entityType\":1, \"name.full\":1}).limit(NUM_SHELL_COMPANY_CANDIDATES // 2 + 1))\n",
        "\n",
        "for pep_entity_dict in pep_sample:\n",
        "    pep_ref = {\"entityId\": pep_entity_dict[\"entityId\"], \"entityType\": pep_entity_dict[\"entityType\"], \"name\": pep_entity_dict.get(\"name\",{}).get(\"full\")}\n",
        "    if random.random() < 0.4 and hnwi_sample:\n",
        "        target_hnwi_dict = random.choice(hnwi_sample)\n",
        "        target_ref = {\"entityId\": target_hnwi_dict[\"entityId\"], \"entityType\": target_hnwi_dict[\"entityType\"], \"name\": target_hnwi_dict.get(\"name\",{}).get(\"full\")}\n",
        "        rel_pep_hnwi = generate_relationship_template(\n",
        "            source_ref=pep_ref, target_ref=target_ref, type=\"business_associate_suspected\", direction=\"bidirectional\",\n",
        "            strength=round(random.uniform(0.5,0.7),2), verified=False, review_status=\"requires_investigation\",\n",
        "            notes=f\"Suspected association between PEP {pep_ref.get('name','N/A')} and HNWI {target_ref.get('name','N/A')}.\",\n",
        "            datasource=\"intelligence_leak_simulated_v2\"\n",
        "        )\n",
        "        if rel_pep_hnwi: all_relationships_to_insert.append(rel_pep_hnwi)\n",
        "\n",
        "    if random.random() < 0.3 and shell_co_sample:\n",
        "        target_shell_dict = random.choice(shell_co_sample)\n",
        "        target_ref = {\"entityId\": target_shell_dict[\"entityId\"], \"entityType\": target_shell_dict[\"entityType\"], \"name\": target_shell_dict.get(\"name\",{}).get(\"full\")}\n",
        "        rel_pep_shell = generate_relationship_template(\n",
        "            source_ref=pep_ref, target_ref=target_ref, type=\"potential_beneficial_owner_of\", direction=\"directed\",\n",
        "            strength=round(random.uniform(0.4,0.65),2), verified=False, review_status=\"high_priority_investigation\",\n",
        "            notes=f\"PEP {pep_ref.get('name','N/A')} potentially linked to shell company {target_ref.get('name','N/A')}.\",\n",
        "            datasource=\"financial_investigation_unit_tipoff_sim\"\n",
        "        )\n",
        "        if rel_pep_shell: all_relationships_to_insert.append(rel_pep_shell)\n",
        "\n",
        "sanctioned_org_sample = list(entities_collection.find({\"scenarioKey\": {\"$regex\": \"^sanctioned_org_varied_\"}}, {\"entityId\":1, \"entityType\":1, \"name.full\":1}).limit(NUM_SANCTIONED_ORGANIZATIONS // 2 + 1))\n",
        "other_org_sample = list(entities_collection.find(\n",
        "    {\"entityType\": \"organization\", \"scenarioKey\":{\"$not\": {\"$regex\":\"^sanctioned_org_varied_\"}}},\n",
        "    {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        ").limit(30))\n",
        "\n",
        "if sanctioned_org_sample and other_org_sample:\n",
        "    for sn_org_dict in sanctioned_org_sample:\n",
        "        sn_org_ref = {\"entityId\": sn_org_dict[\"entityId\"], \"entityType\": sn_org_dict[\"entityType\"], \"name\": sn_org_dict.get(\"name\",{}).get(\"full\")}\n",
        "        if random.random() < 0.6: # Link to 1-2 other orgs\n",
        "            for _ in range(random.randint(1,2)):\n",
        "                if not other_org_sample: break # Break if no more other orgs to pick from\n",
        "                target_org_dict = random.choice(other_org_sample)\n",
        "                target_org_ref = {\"entityId\": target_org_dict[\"entityId\"], \"entityType\": target_org_dict[\"entityType\"], \"name\": target_org_dict.get(\"name\",{}).get(\"full\")}\n",
        "                if target_org_ref[\"entityId\"] == sn_org_ref[\"entityId\"]: continue\n",
        "\n",
        "                rel_sn_other = generate_relationship_template(\n",
        "                    source_ref=sn_org_ref, target_ref=target_org_ref, type=\"transactional_counterparty_high_risk\", direction=\"bidirectional\",\n",
        "                    strength=round(random.uniform(0.6,0.8),2), verified=False,\n",
        "                    notes=f\"High-risk transactions detected between sanctioned org {sn_org_ref.get('name','N/A')} and {target_org_ref.get('name','N/A')}.\",\n",
        "                    datasource=\"transaction_monitoring_alert_sim_v2\"\n",
        "                )\n",
        "                if rel_sn_other: all_relationships_to_insert.append(rel_sn_other)\n",
        "\n",
        "# --- 5. Some Past/Inactive Relationships ---\n",
        "print(\"Creating some Past/Inactive relationships...\")\n",
        "# Use the full potential_ubo_pool which contains various individuals\n",
        "all_individuals_for_past_roles = list(entities_collection.find({\"entityType\":\"individual\"}, {\"entityId\":1, \"entityType\":1, \"name.full\":1}).limit(50))\n",
        "all_orgs_for_past_roles = list(entities_collection.find({\"entityType\":\"organization\"}, {\"entityId\":1, \"entityType\":1, \"name.full\":1}).limit(50))\n",
        "\n",
        "if len(all_individuals_for_past_roles) > 5 and len(all_orgs_for_past_roles) > 2 :\n",
        "    for _ in range(max(5, NUM_COMPLEX_ORG_STRUCTURES)): # Create a few more past directorships\n",
        "        director_dict = random.choice(all_individuals_for_past_roles)\n",
        "        director_ref = {\"entityId\": director_dict[\"entityId\"], \"entityType\": director_dict[\"entityType\"], \"name\": director_dict.get(\"name\",{}).get(\"full\")}\n",
        "\n",
        "        past_org_dict = random.choice(all_orgs_for_past_roles)\n",
        "        past_org_ref = {\"entityId\": past_org_dict[\"entityId\"], \"entityType\": past_org_dict[\"entityType\"], \"name\": past_org_dict.get(\"name\",{}).get(\"full\")}\n",
        "\n",
        "        if director_ref[\"entityId\"] == past_org_ref[\"entityId\"]: continue # Should not happen with type check but safety\n",
        "\n",
        "        valid_from_past = fake.date_time_between(start_date=\"-10y\", end_date=\"-3y\", tzinfo=timezone.utc)\n",
        "        valid_to_past = fake.date_time_between(start_date=valid_from_past + timedelta(days=365), end_date=\"-1y\", tzinfo=timezone.utc)\n",
        "\n",
        "        rel_past_directorship = generate_relationship_template(\n",
        "            source_ref=director_ref, target_ref=past_org_ref,\n",
        "            type=\"director_of\", direction=\"directed\", active=False, verified=True,\n",
        "            validFrom=valid_from_past, validTo=valid_to_past,\n",
        "            notes=f\"Past directorship of {director_ref.get('name','N/A')} at {past_org_ref.get('name','N/A')}, resigned/term ended.\",\n",
        "            datasource=\"historical_corporate_filings_sim_v2\"\n",
        "        )\n",
        "        if rel_past_directorship: all_relationships_to_insert.append(rel_past_directorship)\n",
        "\n",
        "# --- 6. Generic \"Social\" or \"Professional\" Links for Network Density ---\n",
        "print(\"Creating a few generic social/professional links for graph density...\")\n",
        "generic_individuals = list(entities_collection.find({\"scenarioKey\":\"generic_individual\"}, {\"entityId\":1, \"entityType\":1, \"name.full\":1}).limit(60))\n",
        "if len(generic_individuals) >= 10:\n",
        "    for _ in range(25): # Increased slightly\n",
        "        if len(generic_individuals) < 2: break\n",
        "        source_ind_dict, target_ind_dict = random.sample(generic_individuals, 2)\n",
        "        source_ref = {\"entityId\": source_ind_dict[\"entityId\"], \"entityType\": source_ind_dict[\"entityType\"], \"name\": source_ind_dict.get(\"name\",{}).get(\"full\")}\n",
        "        target_ref = {\"entityId\": target_ind_dict[\"entityId\"], \"entityType\": target_ind_dict[\"entityType\"], \"name\": target_ind_dict.get(\"name\",{}).get(\"full\")}\n",
        "\n",
        "        rel_social = generate_relationship_template(\n",
        "            source_ref=source_ref, target_ref=target_ref,\n",
        "            type=random.choice([\"professional_colleague_public\", \"social_media_connection_public\", \"known_associate_unverified\"]),\n",
        "            strength=round(random.uniform(0.3,0.6),2), verified=False,\n",
        "            datasource=\"public_domain_data_scrape_sim_v2\"\n",
        "        )\n",
        "        if rel_social: all_relationships_to_insert.append(rel_social)\n",
        "\n",
        "\n",
        "# --- 7. Links for Evolving Risk Individuals (to showcase potential future risk) ---\n",
        "print(\"Creating some speculative links for Evolving Risk Individuals...\")\n",
        "evolving_risk_sample = list(entities_collection.find(\n",
        "    {\"scenarioKey\": {\"$regex\": \"^evolving_risk_individual_\"}},\n",
        "    {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        ").limit(max(5, NUM_EVOLVING_RISK_INDIVIDUALS // 2))) # NUM_EVOLVING_RISK_INDIVIDUALS from entity script\n",
        "\n",
        "# Sample of other entities they might connect to:\n",
        "# Could be other generic individuals, or even HNWIs, or less critical orgs\n",
        "other_individuals_sample = list(entities_collection.find(\n",
        "    {\"entityType\": \"individual\", \"scenarioKey\": {\"$not\": {\"$regex\": \"^evolving_risk_individual_\"}}}, # Not another evolving risk\n",
        "    {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        ").limit(30))\n",
        "\n",
        "other_orgs_sample = list(entities_collection.find(\n",
        "    {\"entityType\": \"organization\", \"scenarioKey\": {\"$not\": {\"$regex\": \"^sanctioned_org_varied_\"}}}, # Not sanctioned\n",
        "    {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        ").limit(20))\n",
        "\n",
        "\n",
        "if evolving_risk_sample:\n",
        "    for evo_entity_dict in evolving_risk_sample:\n",
        "        evo_ref = {\"entityId\": evo_entity_dict[\"entityId\"], \"entityType\": evo_entity_dict[\"entityType\"], \"name\": evo_entity_dict.get(\"name\",{}).get(\"full\")}\n",
        "\n",
        "        # Chance to link to another individual (e.g., new business partner, associate)\n",
        "        if random.random() < 0.4 and other_individuals_sample:\n",
        "            target_ind_dict = random.choice(other_individuals_sample)\n",
        "            target_ref = {\"entityId\": target_ind_dict[\"entityId\"], \"entityType\": target_ind_dict[\"entityType\"], \"name\": target_ind_dict.get(\"name\",{}).get(\"full\")}\n",
        "            if evo_ref[\"entityId\"] == target_ref[\"entityId\"]: continue\n",
        "\n",
        "            rel_evo_ind = generate_relationship_template(\n",
        "                source_ref=evo_ref, target_ref=target_ref,\n",
        "                type=\"emerging_business_associate\", # A custom type for this\n",
        "                direction=\"bidirectional\",\n",
        "                strength=round(random.uniform(0.4, 0.6),2),\n",
        "                verified=False,\n",
        "                review_status=\"monitoring_activity\",\n",
        "                notes=f\"New association noted between {evo_ref.get('name','N/A')} and {target_ref.get('name','N/A')}. Monitor for risk changes.\",\n",
        "                datasource=\"internal_observation_log_sim\"\n",
        "            )\n",
        "            if rel_evo_ind: all_relationships_to_insert.append(rel_evo_ind)\n",
        "\n",
        "        # Chance to link to an organization (e.g., becomes director of a small/new company, or consultant for)\n",
        "        if random.random() < 0.3 and other_orgs_sample:\n",
        "            target_org_dict = random.choice(other_orgs_sample)\n",
        "            target_ref = {\"entityId\": target_org_dict[\"entityId\"], \"entityType\": target_org_dict[\"entityType\"], \"name\": target_org_dict.get(\"name\",{}).get(\"full\")}\n",
        "\n",
        "            rel_type_org = random.choice([\"consultant_for\", \"director_of_small_entity\", \"shareholder_minority_private_co\"])\n",
        "            rel_evo_org = generate_relationship_template(\n",
        "                source_ref=evo_ref, target_ref=target_ref,\n",
        "                type=rel_type_org,\n",
        "                direction=\"directed\",\n",
        "                strength=round(random.uniform(0.5, 0.75),2),\n",
        "                verified= (rel_type_org != \"consultant_for\"), # Directorship/shareholding might be verifiable\n",
        "                notes=f\"{evo_ref.get('name','N/A')} now linked to organization {target_ref.get('name','N/A')} as {rel_type_org}.\",\n",
        "                datasource=\"business_intelligence_update_sim\"\n",
        "            )\n",
        "            if rel_evo_org: all_relationships_to_insert.append(rel_evo_org)\n",
        "\n",
        "# --- 9. Create Fourth-Hop Relationships Using the Map ---\n",
        "print(\"Creating fourth-hop relationships based on existing network...\")\n",
        "# Find entities that are already 3 hops away from high-risk entities\n",
        "high_risk_entities = list(entities_collection.find(\n",
        "    {\"$or\": [\n",
        "        {\"scenarioKey\": {\"$regex\": \"sanctioned\"}},\n",
        "        {\"scenarioKey\": {\"$regex\": \"pep\"}},\n",
        "        {\"riskAssessment.overall.level\": \"high\"}\n",
        "    ]},\n",
        "    {\"entityId\":1}\n",
        ").limit(5))\n",
        "\n",
        "for high_risk_entity in high_risk_entities:\n",
        "    entity_id = high_risk_entity[\"entityId\"]\n",
        "\n",
        "    # Find 3-hop connections\n",
        "    if entity_id in entity_relationships_map:\n",
        "        # First hop\n",
        "        first_hops = entity_relationships_map[entity_id].get(\"outgoing\", [])\n",
        "\n",
        "        for first_hop_id in first_hops[:2]:  # Limit to avoid explosion\n",
        "            if first_hop_id in entity_relationships_map:\n",
        "                # Second hop\n",
        "                second_hops = entity_relationships_map[first_hop_id].get(\"outgoing\", [])\n",
        "\n",
        "                for second_hop_id in second_hops[:2]:\n",
        "                    if second_hop_id in entity_relationships_map:\n",
        "                        # Third hop\n",
        "                        third_hops = entity_relationships_map[second_hop_id].get(\"outgoing\", [])\n",
        "\n",
        "                        for third_hop_id in third_hops[:1]:\n",
        "                            # Create fourth hop\n",
        "                            fourth_hop_candidates = list(entities_collection.find(\n",
        "                                {\"entityId\": {\"$nin\": [entity_id, first_hop_id, second_hop_id, third_hop_id]}},\n",
        "                                {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        "                            ).limit(3))\n",
        "\n",
        "                            if fourth_hop_candidates:\n",
        "                                fourth_hop = random.choice(fourth_hop_candidates)\n",
        "                                third_hop_entity = entities_collection.find_one({\"entityId\": third_hop_id})\n",
        "\n",
        "                                if third_hop_entity:\n",
        "                                    rel_fourth_hop = generate_relationship_template(\n",
        "                                        source_ref={\"entityId\": third_hop_id, \"entityType\": third_hop_entity[\"entityType\"], \"name\": third_hop_entity.get(\"name\",{}).get(\"full\")},\n",
        "                                        target_ref={\"entityId\": fourth_hop[\"entityId\"], \"entityType\": fourth_hop[\"entityType\"], \"name\": fourth_hop.get(\"name\",{}).get(\"full\")},\n",
        "                                        type=\"distant_connection\",\n",
        "                                        sub_type=\"fourth_degree_separation\",\n",
        "                                        direction=\"bidirectional\",\n",
        "                                        strength=round(random.uniform(0.2,0.4),2),\n",
        "                                        verified=False,\n",
        "                                        datasource=\"extended_network_analysis\",\n",
        "                                        notes=f\"Fourth-degree connection from high-risk entity\",\n",
        "                                        tags=[\"extended_network\", \"requires_monitoring\"]\n",
        "                                    )\n",
        "                                    if rel_fourth_hop:\n",
        "                                        all_relationships_to_insert.append(rel_fourth_hop)\n",
        "\n",
        "# --- Clean up and insert relationships ---\n",
        "if all_relationships_to_insert:\n",
        "    unique_rels_dict = {}\n",
        "    valid_relationships = []\n",
        "\n",
        "    for rel_item in all_relationships_to_insert:\n",
        "        if rel_item is None: continue\n",
        "\n",
        "        s_id = rel_item[\"source\"][\"entityId\"]\n",
        "        t_id = rel_item[\"target\"][\"entityId\"]\n",
        "\n",
        "        # Create unique key\n",
        "        if rel_item[\"direction\"] == \"directed\":\n",
        "            key = (s_id, t_id, rel_item[\"type\"])\n",
        "        else:\n",
        "            key = (tuple(sorted((s_id, t_id))), rel_item[\"type\"])\n",
        "\n",
        "        if key not in unique_rels_dict:\n",
        "            unique_rels_dict[key] = rel_item\n",
        "            valid_relationships.append(rel_item)\n",
        "\n",
        "    print(f\"\\nTotal unique relationships to insert: {len(valid_relationships)}\")\n",
        "\n",
        "    # Add more relationships if needed to reach 500-600\n",
        "    if len(valid_relationships) < 500:\n",
        "        print(f\"Adding additional generic relationships to reach target...\")\n",
        "\n",
        "        # Add more generic business relationships\n",
        "        generic_individuals = list(entities_collection.find(\n",
        "            {\"entityType\": \"individual\"},\n",
        "            {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        "        ).limit(200))\n",
        "\n",
        "        generic_orgs = list(entities_collection.find(\n",
        "            {\"entityType\": \"organization\"},\n",
        "            {\"entityId\":1, \"entityType\":1, \"name.full\":1}\n",
        "        ).limit(100))\n",
        "\n",
        "        while len(valid_relationships) < 600 and len(generic_individuals) >= 2:\n",
        "            # Add various relationship types\n",
        "            rel_type_options = [\n",
        "                (\"professional_colleague\", \"bidirectional\", 0.5),\n",
        "                (\"former_associate\", \"bidirectional\", 0.4),\n",
        "                (\"referral_source\", \"directed\", 0.6),\n",
        "                (\"mentor_mentee\", \"directed\", 0.7),\n",
        "                (\"alumni_connection\", \"bidirectional\", 0.3),\n",
        "                (\"industry_contact\", \"bidirectional\", 0.4),\n",
        "                (\"business_referral\", \"directed\", 0.5),\n",
        "                (\"past_business_partner\", \"bidirectional\", 0.4),\n",
        "                (\"investment_advisor\", \"directed\", 0.6),\n",
        "                (\"legal_representative\", \"directed\", 0.7)\n",
        "            ]\n",
        "\n",
        "            if random.random() < 0.7 and len(generic_individuals) >= 2:\n",
        "                # Individual to individual\n",
        "                source, target = random.sample(generic_individuals, 2)\n",
        "                rel_type, direction, base_strength = random.choice(rel_type_options)\n",
        "            else:\n",
        "                # Individual to organization or org to org\n",
        "                if generic_individuals and generic_orgs:\n",
        "                    if random.random() < 0.5:\n",
        "                        source = random.choice(generic_individuals)\n",
        "                        target = random.choice(generic_orgs)\n",
        "                        rel_type = random.choice([\"customer_of\", \"vendor_for\", \"affiliated_with\"])\n",
        "                    else:\n",
        "                        source = random.choice(generic_orgs)\n",
        "                        target = random.choice(generic_orgs)\n",
        "                        rel_type = random.choice([\"competitor_of\", \"partner_with\", \"subsidiary_of\"])\n",
        "                    direction = \"directed\" if rel_type in [\"customer_of\", \"vendor_for\", \"subsidiary_of\"] else \"bidirectional\"\n",
        "                    base_strength = 0.5\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "            generic_rel = generate_relationship_template(\n",
        "                source_ref={\"entityId\": source[\"entityId\"], \"entityType\": source[\"entityType\"], \"name\": source.get(\"name\",{}).get(\"full\")},\n",
        "                target_ref={\"entityId\": target[\"entityId\"], \"entityType\": target[\"entityType\"], \"name\": target.get(\"name\",{}).get(\"full\")},\n",
        "                type=rel_type,\n",
        "                direction=direction,\n",
        "                strength=round(random.uniform(base_strength-0.2, base_strength+0.2),2),\n",
        "                verified=random.random() > 0.5,\n",
        "                datasource=\"various_sources\"\n",
        "            )\n",
        "\n",
        "            if generic_rel:\n",
        "                # Check uniqueness\n",
        "                s_id = generic_rel[\"source\"][\"entityId\"]\n",
        "                t_id = generic_rel[\"target\"][\"entityId\"]\n",
        "\n",
        "                if generic_rel[\"direction\"] == \"directed\":\n",
        "                    key = (s_id, t_id, generic_rel[\"type\"])\n",
        "                else:\n",
        "                    key = (tuple(sorted((s_id, t_id))), generic_rel[\"type\"])\n",
        "\n",
        "                if key not in unique_rels_dict:\n",
        "                    unique_rels_dict[key] = generic_rel\n",
        "                    valid_relationships.append(generic_rel)\n",
        "\n",
        "    print(f\"Final total unique relationships to insert: {len(valid_relationships)}\")\n",
        "\n",
        "    if valid_relationships:\n",
        "        print(f\"Attempting to insert relationships into '{relationships_collection.name}' collection...\")\n",
        "        try:\n",
        "            relationships_collection.drop()\n",
        "            result = relationships_collection.insert_many(valid_relationships, ordered=False)\n",
        "            print(f\"Successfully inserted {len(result.inserted_ids)} relationships.\")\n",
        "        except pymongo.errors.BulkWriteError as bwe:\n",
        "            print(\"Bulk write error during relationship insertion:\")\n",
        "            write_errors = bwe.details.get('writeErrors', [])\n",
        "            print(f\"Total errors: {len(write_errors)}\")\n",
        "            # Show only first 5 errors\n",
        "            for error_detail in write_errors[:5]:\n",
        "                print(f\"  Index: {error_detail['index']}, Code: {error_detail['code']}, Message: {error_detail['errmsg']}\")\n",
        "            if len(write_errors) > 5:\n",
        "                print(f\"  ... and {len(write_errors) - 5} more errors\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during relationship insertion: {e}\")\n",
        "else:\n",
        "    print(\"No relationships were generated to insert.\")\n",
        "\n",
        "print(\"\\n--- Enhanced Relationship Seeding Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqSTqG-ZWzue",
        "outputId": "aa9f5d5e-60bd-4ab8-b92f-ab4c87e71a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating enhanced relationships with multi-hop patterns...\n",
            "Creating ER links for 15 Clear Duplicate sets...\n",
            "Creating ER links for 8 Subtle Duplicate Clusters...\n",
            "Creating Enhanced Organizational Structure & UBO links for 5 structures...\n",
            "Creating enhanced business relationships between organizations...\n",
            "Creating professional service provider networks...\n",
            "Creating multi-hop suspicious networks...\n",
            "Creating extended family and social networks...\n",
            "Creating financial institution relationships...\n",
            "Creating employment and board member networks...\n",
            "Creating Household links for 10 sets...\n",
            "Creating links involving High-Risk/Watchlisted entities...\n",
            "Creating some Past/Inactive relationships...\n",
            "Creating a few generic social/professional links for graph density...\n",
            "Creating some speculative links for Evolving Risk Individuals...\n",
            "Creating fourth-hop relationships based on existing network...\n",
            "\n",
            "Total unique relationships to insert: 519\n",
            "Final total unique relationships to insert: 519\n",
            "Attempting to insert relationships into 'relationships' collection...\n",
            "Successfully inserted 519 relationships.\n",
            "\n",
            "--- Enhanced Relationship Seeding Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (At the end of your relationship generation script, or in a separate indexing script)\n",
        "\n",
        "print(\"\\n--- Attempting to Create Indexes for 'relationships' Collection ---\")\n",
        "\n",
        "try:\n",
        "    print(\"Creating indexes for 'relationships' collection...\")\n",
        "\n",
        "    # 1. For finding relationships starting FROM a specific entity (Outbound edges)\n",
        "    # Often used in $graphLookup's 'connectFromField' or direct queries.\n",
        "    # Type and active status are common filters.\n",
        "    relationships_collection.create_index(\n",
        "        [\n",
        "            (\"source.entityId\", pymongo.ASCENDING),\n",
        "            (\"type\", pymongo.ASCENDING),\n",
        "            (\"active\", pymongo.ASCENDING) # -1 if you more often query for active=true\n",
        "        ],\n",
        "        name=\"rel_source_type_active_idx\"\n",
        "    )\n",
        "    print(\"- Index on 'source.entityId', 'type', 'active' created or already exists.\")\n",
        "\n",
        "    # 2. For finding relationships going TO a specific entity (Inbound edges)\n",
        "    # Often used in $graphLookup's 'connectToField' or direct queries.\n",
        "    relationships_collection.create_index(\n",
        "        [\n",
        "            (\"target.entityId\", pymongo.ASCENDING),\n",
        "            (\"type\", pymongo.ASCENDING),\n",
        "            (\"active\", pymongo.ASCENDING) # -1 if you more often query for active=true\n",
        "        ],\n",
        "        name=\"rel_target_type_active_idx\"\n",
        "    )\n",
        "    print(\"- Index on 'target.entityId', 'type', 'active' created or already exists.\")\n",
        "\n",
        "    # 3. For querying by relationship type globally\n",
        "    relationships_collection.create_index([(\"type\", pymongo.ASCENDING)], name=\"rel_type_idx\")\n",
        "    print(\"- Index on 'type' created or already exists.\")\n",
        "\n",
        "    # 4. For looking up a specific relationship by its own ID (if you do this)\n",
        "    # This should be unique.\n",
        "    relationships_collection.create_index(\n",
        "        [(\"relationshipId\", pymongo.ASCENDING)],\n",
        "        name=\"rel_relationshipId_idx\",\n",
        "        unique=True\n",
        "    )\n",
        "    print(\"- Unique index on 'relationshipId' created or already exists.\")\n",
        "\n",
        "    # 5. Optional: For queries filtering by datasource\n",
        "    relationships_collection.create_index([(\"datasource\", pymongo.ASCENDING)], name=\"rel_datasource_idx\")\n",
        "    print(\"- Index on 'datasource' created or already exists.\")\n",
        "\n",
        "    # 6. Optional: For queries filtering by active status (though often covered by compound indexes above)\n",
        "    # relationships_collection.create_index([(\"active\", pymongo.ASCENDING)], name=\"rel_active_idx\")\n",
        "    # print(\"- Index on 'active' created or already exists.\")\n",
        "\n",
        "    # 7. Optional: If you frequently query for relationships active within a certain time window\n",
        "    # relationships_collection.create_index(\n",
        "    #     [\n",
        "    #         (\"active\", pymongo.ASCENDING),\n",
        "    #         (\"validFrom\", pymongo.ASCENDING),\n",
        "    #         (\"validTo\", pymongo.ASCENDING)\n",
        "    #     ],\n",
        "    #     name=\"rel_active_validity_idx\",\n",
        "    #     partialFilterExpression={\"active\": True} # Index only active relationships with validity dates\n",
        "    # )\n",
        "    # print(\"- Index on 'active', 'validFrom', 'validTo' (partial) created or already exists.\")\n",
        "\n",
        "\n",
        "    print(\"Relationship index creation process completed.\")\n",
        "\n",
        "except pymongo.errors.OperationFailure as e:\n",
        "    # Handle specific errors, like \"duplicate key error\" if unique index fails\n",
        "    if \"duplicate key error\" in str(e).lower() and \"rel_relationshipId_idx\" in str(e).lower():\n",
        "         print(f\"Hint: The unique index on 'relationshipId' failed. Check for duplicate relationshipId values if this was not expected: {e}\")\n",
        "    elif \"IndexOptionsConflict\" in str(e) or \"IndexKeySpecsConflict\" in str(e):\n",
        "        print(f\"Index option conflict. An index with similar fields but different options might exist: {e}\")\n",
        "    else:\n",
        "        print(f\"An error occurred during relationship index creation: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred during relationship index creation: {e}\")\n",
        "\n",
        "# client.close() # If this is the end of this specific script block"
      ],
      "metadata": {
        "id": "LVC33SW_Zo3q",
        "outputId": "4db10f61-0882-4321-972c-f7f71748ee90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Attempting to Create Indexes for 'relationships' Collection ---\n",
            "Creating indexes for 'relationships' collection...\n",
            "- Index on 'source.entityId', 'type', 'active' created or already exists.\n",
            "- Index on 'target.entityId', 'type', 'active' created or already exists.\n",
            "- Index on 'type' created or already exists.\n",
            "- Unique index on 'relationshipId' created or already exists.\n",
            "- Index on 'datasource' created or already exists.\n",
            "Relationship index creation process completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. `transactionsv2` Collection\n",
        "\n",
        "*   **Schema:**\n",
        "    *   `_id`: `ObjectId()`\n",
        "    *   `transactionId`: String (e.g., \"TXN\" + random) - **Unique**\n",
        "    *   `entityId`: String (ID of your customer involved)\n",
        "    *   `timestamp`: `ISODate()`\n",
        "    *   `amount`: Number\n",
        "    *   `currency`: String (e.g., \"USD\", \"EUR\")\n",
        "    *   `direction`: \"incoming\", \"outgoing\"\n",
        "    *   `counterpartyName`: String\n",
        "    *   `counterpartyBank`: String (optional)\n",
        "    *   `counterpartyCountry`: String (2-letter code, important for risk)\n",
        "    *   `transactionType`: String (e.g., \"wire_transfer\", \"card_payment\", \"cash_deposit\")\n",
        "    *   `description`: String (optional)\n",
        "*   **Data Tweaks for `transactions`:**\n",
        "    1.  Entity J (low risk) - few, small, domestic transactions.\n",
        "    2.  Entity K (high risk) - large, frequent, international transactions, some to/from high-risk countries.\n",
        "    3.  Entity L (evolving risk) - initially like J, then add a burst of transactions to a high-risk country.\n",
        "    4.  Transactions that could be seen as \"structuring\" (e.g., multiple $9,500 transactions)."
      ],
      "metadata": {
        "id": "WWoNSorbYwQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transactionsv2 Collection Generation\n",
        "# Creates transactions with fromEntityId and toEntityId for $graphLookup support\n",
        "\n",
        "import pymongo\n",
        "from faker import Faker\n",
        "import random\n",
        "from datetime import datetime, timedelta, timezone\n",
        "from bson import ObjectId\n",
        "import uuid\n",
        "import numpy as np\n",
        "\n",
        "# --- Database and Collection Setup ---\n",
        "transactions_collection = db[\"transactionsv2\"]\n",
        "entities_collection = db[\"entities\"]\n",
        "\n",
        "# --- Constants ---\n",
        "TOTAL_TRANSACTIONS = 15000\n",
        "BACKGROUND_NOISE_TRANSACTIONS = 12000\n",
        "SCENARIO_SPECIFIC_TRANSACTIONS = 3000\n",
        "\n",
        "# Define countries_by_risk\n",
        "COUNTRIES_BY_RISK_GLOBAL = {\n",
        "    \"low\": [\"US\", \"CA\", \"DE\", \"FR\", \"AU\", \"JP\", \"GB\", \"NL\", \"SE\", \"NZ\"],\n",
        "    \"medium\": [\"SG\", \"AE\", \"CH\", \"HK\", \"BR\", \"IN\", \"CN\", \"ZA\", \"KR\", \"ES\", \"IT\"],\n",
        "    \"high\": [\"SY\", \"KP\", \"VE\", \"IR\", \"AF\", \"SO\", \"YE\", \"LY\", \"IQ\", \"MM\", \"RU\", \"BY\",\n",
        "             \"KY\", \"PA\", \"BS\", \"VU\", \"MT\", \"CY\", \"TC\", \"SC\", \"BZ\", \"LI\"]\n",
        "}\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def get_all_entities_for_transactions():\n",
        "    \"\"\"Fetches all entities with their key information for transaction generation.\"\"\"\n",
        "    entities = list(entities_collection.find(\n",
        "        {},\n",
        "        {\n",
        "            \"entityId\": 1,\n",
        "            \"entityType\": 1,\n",
        "            \"scenarioKey\": 1,\n",
        "            \"name.full\": 1,\n",
        "            \"riskAssessment.overall.level\": 1,\n",
        "            \"addresses\": 1,\n",
        "            \"customerInfo.industry\": 1,\n",
        "            \"customerInfo.businessType\": 1,\n",
        "            \"_id\": 0\n",
        "        }\n",
        "    ))\n",
        "\n",
        "    # Add home country to each entity\n",
        "    for entity in entities:\n",
        "        home_country = \"US\"  # Default\n",
        "        if entity.get(\"addresses\"):\n",
        "            for addr in entity.get(\"addresses\", []):\n",
        "                if addr.get(\"primary\") and addr.get(\"structured\", {}).get(\"country\"):\n",
        "                    home_country = addr[\"structured\"][\"country\"]\n",
        "                    break\n",
        "        entity[\"homeCountry\"] = home_country\n",
        "\n",
        "    return entities\n",
        "\n",
        "def get_entities_by_scenario(entities, scenario_pattern):\n",
        "    \"\"\"Filter entities by scenario key pattern.\"\"\"\n",
        "    return [e for e in entities if scenario_pattern in e.get(\"scenarioKey\", \"\")]\n",
        "\n",
        "def get_entity_relationships(entity_id, relationships_collection=None):\n",
        "    \"\"\"Get all entities connected to a given entity through relationships.\"\"\"\n",
        "    if not relationships_collection:\n",
        "        relationships_collection = db[\"relationships\"]\n",
        "\n",
        "    connected_entities = set()\n",
        "\n",
        "    # Find relationships where entity is source or target\n",
        "    relationships = list(relationships_collection.find({\n",
        "        \"$or\": [\n",
        "            {\"source.entityId\": entity_id},\n",
        "            {\"target.entityId\": entity_id}\n",
        "        ],\n",
        "        \"active\": True\n",
        "    }))\n",
        "\n",
        "    for rel in relationships:\n",
        "        if rel[\"source\"][\"entityId\"] == entity_id:\n",
        "            connected_entities.add(rel[\"target\"][\"entityId\"])\n",
        "        else:\n",
        "            connected_entities.add(rel[\"source\"][\"entityId\"])\n",
        "\n",
        "    return list(connected_entities)\n",
        "\n",
        "def generate_transaction_with_entities(from_entity, to_entity, **kwargs):\n",
        "    \"\"\"Generate a transaction between two specific entities.\"\"\"\n",
        "    timestamp = kwargs.get(\"timestamp\", fake.date_time_between(start_date=\"-3y\", end_date=\"now\", tzinfo=timezone.utc))\n",
        "\n",
        "    # Determine transaction characteristics based on entity types and risk levels\n",
        "    from_risk = from_entity.get(\"riskAssessment\", {}).get(\"overall\", {}).get(\"level\", \"low\")\n",
        "    to_risk = to_entity.get(\"riskAssessment\", {}).get(\"overall\", {}).get(\"level\", \"low\")\n",
        "    combined_risk = max(from_risk, to_risk, key=lambda x: [\"low\", \"medium\", \"high\"].index(x))\n",
        "\n",
        "    # Base amount determination\n",
        "    if kwargs.get(\"amount\"):\n",
        "        amount = kwargs[\"amount\"]\n",
        "    elif kwargs.get(\"is_structuring\"):\n",
        "        amount = round(random.uniform(8000, 9990), 2)\n",
        "    elif kwargs.get(\"is_large_value\"):\n",
        "        amount = round(random.uniform(100000, 5000000), 2)\n",
        "    else:\n",
        "        if combined_risk == \"high\":\n",
        "            amount = round(random.uniform(5000, 250000), 2)\n",
        "        elif combined_risk == \"medium\":\n",
        "            amount = round(random.uniform(1000, 50000), 2)\n",
        "        else:\n",
        "            amount = round(random.uniform(50, 10000), 2)\n",
        "\n",
        "    # Transaction type based on entity types and scenario\n",
        "    transaction_type = kwargs.get(\"transaction_type\")\n",
        "    if not transaction_type:\n",
        "        if from_entity[\"entityType\"] == \"organization\" and to_entity[\"entityType\"] == \"organization\":\n",
        "            transaction_type = random.choice([\n",
        "                \"b2b_wire_transfer\", \"trade_payment\", \"intercompany_transfer\",\n",
        "                \"investment_transfer\", \"loan_disbursement\", \"dividend_payment\"\n",
        "            ])\n",
        "        elif from_entity[\"entityType\"] == \"individual\" and to_entity[\"entityType\"] == \"individual\":\n",
        "            transaction_type = random.choice([\n",
        "                \"p2p_transfer\", \"family_support\", \"personal_loan\",\n",
        "                \"gift_transfer\", \"investment_transfer\"\n",
        "            ])\n",
        "        else:\n",
        "            # Mixed individual/organization\n",
        "            if from_entity[\"entityType\"] == \"organization\":\n",
        "                transaction_type = random.choice([\n",
        "                    \"salary_payment\", \"dividend_payout\", \"expense_reimbursement\",\n",
        "                    \"commission_payment\", \"loan_disbursement\"\n",
        "                ])\n",
        "            else:\n",
        "                transaction_type = random.choice([\n",
        "                    \"investment_deposit\", \"service_payment\", \"purchase_payment\",\n",
        "                    \"loan_repayment\", \"subscription_payment\"\n",
        "                ])\n",
        "\n",
        "    # Payment method\n",
        "    payment_method = kwargs.get(\"payment_method\")\n",
        "    if not payment_method:\n",
        "        if \"wire\" in transaction_type or amount > 50000:\n",
        "            payment_method = \"SWIFT\" if from_entity[\"homeCountry\"] != to_entity[\"homeCountry\"] else \"Wire\"\n",
        "        elif \"p2p\" in transaction_type:\n",
        "            payment_method = random.choice([\"P2PApp\", \"MobileWallet\", \"OnlineBanking\"])\n",
        "        elif amount > 10000:\n",
        "            payment_method = random.choice([\"Wire\", \"ACH\", \"Check\"])\n",
        "        else:\n",
        "            payment_method = random.choice([\"ACH\", \"CardNetwork\", \"OnlineBanking\"])\n",
        "\n",
        "    # Currency - use home country currency or USD for international\n",
        "    currency = \"USD\"\n",
        "    if from_entity[\"homeCountry\"] == to_entity[\"homeCountry\"]:\n",
        "        currency_map = {\"US\": \"USD\", \"GB\": \"GBP\", \"DE\": \"EUR\", \"FR\": \"EUR\", \"JP\": \"JPY\", \"CA\": \"CAD\", \"AU\": \"AUD\"}\n",
        "        currency = currency_map.get(from_entity[\"homeCountry\"], \"USD\")\n",
        "\n",
        "    # Build transaction\n",
        "    txn = {\n",
        "        \"_id\": ObjectId(),\n",
        "        \"transactionId\": f\"TXN-{uuid.uuid4().hex[:12].upper()}\",\n",
        "        \"fromEntityId\": from_entity[\"entityId\"],\n",
        "        \"fromEntityType\": from_entity[\"entityType\"],\n",
        "        \"fromEntityName\": from_entity.get(\"name\", {}).get(\"full\", \"Unknown\"),\n",
        "        \"toEntityId\": to_entity[\"entityId\"],\n",
        "        \"toEntityType\": to_entity[\"entityType\"],\n",
        "        \"toEntityName\": to_entity.get(\"name\", {}).get(\"full\", \"Unknown\"),\n",
        "        \"timestamp\": timestamp,\n",
        "        \"amount\": amount,\n",
        "        \"currency\": currency,\n",
        "        \"transactionType\": transaction_type,\n",
        "        \"paymentMethod\": payment_method,\n",
        "        \"status\": kwargs.get(\"status\", \"completed\" if random.random() > 0.05 else \"pending\"),\n",
        "        \"channel\": kwargs.get(\"channel\", random.choice([\n",
        "            \"online_banking\", \"mobile_app\", \"branch\", \"api\", \"batch_upload\"\n",
        "        ])),\n",
        "        \"description\": kwargs.get(\"description\", fake.sentence(nb_words=random.randint(3, 8))),\n",
        "        \"tags\": kwargs.get(\"tags\", []),\n",
        "        \"riskScore\": kwargs.get(\"risk_score\", 0),\n",
        "        \"flagged\": kwargs.get(\"flagged\", False),\n",
        "        \"additionalDetails\": kwargs.get(\"additional_details\", {})\n",
        "    }\n",
        "\n",
        "    # Auto-tag based on characteristics\n",
        "    if amount > 100000:\n",
        "        txn[\"tags\"].append(\"large_value\")\n",
        "    if from_entity[\"homeCountry\"] != to_entity[\"homeCountry\"]:\n",
        "        txn[\"tags\"].append(\"cross_border\")\n",
        "    if combined_risk == \"high\":\n",
        "        txn[\"tags\"].append(\"high_risk_entity\")\n",
        "    if to_entity[\"homeCountry\"] in COUNTRIES_BY_RISK_GLOBAL[\"high\"]:\n",
        "        txn[\"tags\"].append(\"high_risk_jurisdiction\")\n",
        "    if kwargs.get(\"is_structuring\"):\n",
        "        txn[\"tags\"].append(\"potential_structuring\")\n",
        "\n",
        "    # Risk scoring\n",
        "    risk_score = 0\n",
        "    if \"high_risk_entity\" in txn[\"tags\"]: risk_score += 30\n",
        "    if \"high_risk_jurisdiction\" in txn[\"tags\"]: risk_score += 25\n",
        "    if \"large_value\" in txn[\"tags\"]: risk_score += 15\n",
        "    if \"cross_border\" in txn[\"tags\"]: risk_score += 10\n",
        "    if \"potential_structuring\" in txn[\"tags\"]: risk_score += 40\n",
        "\n",
        "    txn[\"riskScore\"] = min(risk_score, 100)\n",
        "    txn[\"flagged\"] = txn[\"riskScore\"] > 60\n",
        "\n",
        "    return txn\n",
        "\n",
        "# --- Main Transaction Generation ---\n",
        "print(\"Fetching all entities for transaction generation...\")\n",
        "all_entities = get_all_entities_for_transactions()\n",
        "entities_by_id = {e[\"entityId\"]: e for e in all_entities}\n",
        "\n",
        "# Categorize entities by scenario\n",
        "print(\"Categorizing entities by scenario...\")\n",
        "scenario_entities = {\n",
        "    \"pep\": get_entities_by_scenario(all_entities, \"pep_individual\"),\n",
        "    \"sanctioned_org\": get_entities_by_scenario(all_entities, \"sanctioned_org\"),\n",
        "    \"shell_company\": get_entities_by_scenario(all_entities, \"shell_company\"),\n",
        "    \"hnwi\": get_entities_by_scenario(all_entities, \"hnwi\"),\n",
        "    \"evolving_risk\": get_entities_by_scenario(all_entities, \"evolving_risk\"),\n",
        "    \"household\": get_entities_by_scenario(all_entities, \"household_set\"),\n",
        "    \"complex_org_parent\": get_entities_by_scenario(all_entities, \"complex_org_parent\"),\n",
        "    \"complex_org_sub\": get_entities_by_scenario(all_entities, \"complex_org_sub\"),\n",
        "    \"director\": get_entities_by_scenario(all_entities, \"director_\"),\n",
        "    \"nominee\": get_entities_by_scenario(all_entities, \"nominee_director\")\n",
        "}\n",
        "\n",
        "all_transactions = []\n",
        "\n",
        "# --- 1. Scenario-Specific Transactions (3,000) ---\n",
        "print(f\"Generating {SCENARIO_SPECIFIC_TRANSACTIONS} scenario-specific transactions...\")\n",
        "\n",
        "# 1.1 PEP Transactions (400)\n",
        "print(\"  - PEP transactions...\")\n",
        "for pep in scenario_entities[\"pep\"][:10]:  # Top 10 PEPs\n",
        "    # PEP receiving from shell companies\n",
        "    for _ in range(3):\n",
        "        if scenario_entities[\"shell_company\"]:\n",
        "            shell = random.choice(scenario_entities[\"shell_company\"])\n",
        "            txn = generate_transaction_with_entities(\n",
        "                shell, pep,\n",
        "                amount=round(random.uniform(50000, 500000), 2),\n",
        "                transaction_type=\"consulting_fee\",\n",
        "                description=\"Consulting services rendered\",\n",
        "                tags=[\"pep_transaction\", \"shell_to_pep\"]\n",
        "            )\n",
        "            all_transactions.append(txn)\n",
        "\n",
        "    # PEP sending to offshore accounts (other entities in high-risk countries)\n",
        "    high_risk_entities = [e for e in all_entities if e[\"homeCountry\"] in COUNTRIES_BY_RISK_GLOBAL[\"high\"]]\n",
        "    if high_risk_entities:\n",
        "        for _ in range(2):\n",
        "            offshore_entity = random.choice(high_risk_entities)\n",
        "            txn = generate_transaction_with_entities(\n",
        "                pep, offshore_entity,\n",
        "                amount=round(random.uniform(100000, 1000000), 2),\n",
        "                transaction_type=\"investment_transfer\",\n",
        "                description=\"Investment in overseas venture\",\n",
        "                tags=[\"pep_transaction\", \"pep_to_offshore\"]\n",
        "            )\n",
        "            all_transactions.append(txn)\n",
        "\n",
        "# 1.2 Shell Company Layering (600)\n",
        "print(\"  - Shell company layering transactions...\")\n",
        "shell_companies = scenario_entities[\"shell_company\"]\n",
        "if len(shell_companies) >= 3:\n",
        "    # Create chains of transactions between shell companies\n",
        "    for _ in range(100):\n",
        "        # Pick 3-5 shell companies for a chain\n",
        "        chain_length = random.randint(3, 5)\n",
        "        if len(shell_companies) >= chain_length:\n",
        "            chain = random.sample(shell_companies, chain_length)\n",
        "            base_amount = round(random.uniform(50000, 500000), 2)\n",
        "\n",
        "            for i in range(len(chain) - 1):\n",
        "                # Each hop loses a small percentage (fees)\n",
        "                amount = base_amount * (0.98 ** i)\n",
        "                txn = generate_transaction_with_entities(\n",
        "                    chain[i], chain[i + 1],\n",
        "                    amount=round(amount, 2),\n",
        "                    transaction_type=\"intercompany_transfer\",\n",
        "                    description=\"Business transfer\",\n",
        "                    tags=[\"layering\", \"shell_company_chain\"],\n",
        "                    timestamp=fake.date_time_between(start_date=\"-6m\", end_date=\"now\", tzinfo=timezone.utc)\n",
        "                )\n",
        "                all_transactions.append(txn)\n",
        "\n",
        "# 1.3 Complex Org Structure Transactions (500)\n",
        "print(\"  - Complex organization structure transactions...\")\n",
        "for parent in scenario_entities[\"complex_org_parent\"]:\n",
        "    # Find subsidiaries through relationships\n",
        "    connected_entities = get_entity_relationships(parent[\"entityId\"])\n",
        "    subsidiaries = [entities_by_id.get(eid) for eid in connected_entities\n",
        "                   if entities_by_id.get(eid) and \"complex_org_sub\" in entities_by_id.get(eid).get(\"scenarioKey\", \"\")]\n",
        "\n",
        "    for subsidiary in [s for s in subsidiaries if s]:\n",
        "        # Regular intercompany transfers\n",
        "        for _ in range(5):\n",
        "            direction = random.choice([\"parent_to_sub\", \"sub_to_parent\"])\n",
        "            if direction == \"parent_to_sub\":\n",
        "                txn = generate_transaction_with_entities(\n",
        "                    parent, subsidiary,\n",
        "                    amount=round(random.uniform(100000, 2000000), 2),\n",
        "                    transaction_type=\"capital_injection\",\n",
        "                    description=\"Subsidiary funding\",\n",
        "                    tags=[\"intercompany\", \"parent_subsidiary\"]\n",
        "                )\n",
        "            else:\n",
        "                txn = generate_transaction_with_entities(\n",
        "                    subsidiary, parent,\n",
        "                    amount=round(random.uniform(50000, 1000000), 2),\n",
        "                    transaction_type=\"dividend_payment\",\n",
        "                    description=\"Quarterly dividend\",\n",
        "                    tags=[\"intercompany\", \"subsidiary_parent\"]\n",
        "                )\n",
        "            all_transactions.append(txn)\n",
        "\n",
        "# 1.4 Sanctioned Organization Transactions (400)\n",
        "print(\"  - Sanctioned organization transactions...\")\n",
        "for sanctioned_org in scenario_entities[\"sanctioned_org\"]:\n",
        "    # Find intermediaries (other orgs that might unknowingly deal with sanctioned entities)\n",
        "    intermediary_orgs = [e for e in all_entities\n",
        "                        if e[\"entityType\"] == \"organization\"\n",
        "                        and \"sanctioned\" not in e.get(\"scenarioKey\", \"\")\n",
        "                        and e[\"entityId\"] != sanctioned_org[\"entityId\"]]\n",
        "\n",
        "    if intermediary_orgs:\n",
        "        # Create indirect transaction chains\n",
        "        for _ in range(5):\n",
        "            intermediary = random.choice(intermediary_orgs)\n",
        "            final_recipient = random.choice(all_entities)\n",
        "\n",
        "            # Sanctioned -> Intermediary\n",
        "            txn1 = generate_transaction_with_entities(\n",
        "                sanctioned_org, intermediary,\n",
        "                amount=round(random.uniform(50000, 500000), 2),\n",
        "                transaction_type=\"trade_payment\",\n",
        "                description=\"Equipment purchase\",\n",
        "                tags=[\"sanctions_evasion_risk\", \"sanctioned_entity\"],\n",
        "                status=\"flagged_for_review\"\n",
        "            )\n",
        "            all_transactions.append(txn1)\n",
        "\n",
        "            # Intermediary -> Final recipient (1-2 days later)\n",
        "            txn2 = generate_transaction_with_entities(\n",
        "                intermediary, final_recipient,\n",
        "                amount=round(txn1[\"amount\"] * 0.95, 2),  # Slight reduction\n",
        "                transaction_type=\"trade_payment\",\n",
        "                description=\"Resale of goods\",\n",
        "                tags=[\"potential_sanctions_evasion\"],\n",
        "                timestamp=txn1[\"timestamp\"] + timedelta(days=random.randint(1, 2))\n",
        "            )\n",
        "            all_transactions.append(txn2)\n",
        "\n",
        "# 1.5 HNWI Investment Patterns (400)\n",
        "print(\"  - HNWI investment pattern transactions...\")\n",
        "for hnwi in scenario_entities[\"hnwi\"][:10]:\n",
        "    # Find their service providers through relationships\n",
        "    connected_entities = get_entity_relationships(hnwi[\"entityId\"])\n",
        "\n",
        "    # Large investment movements\n",
        "    investment_targets = [e for e in all_entities\n",
        "                         if e[\"entityType\"] == \"organization\"\n",
        "                         and \"investment\" in e.get(\"customerInfo\", {}).get(\"industry\", \"\").lower()]\n",
        "\n",
        "    if investment_targets:\n",
        "        for _ in range(4):\n",
        "            target = random.choice(investment_targets)\n",
        "            txn = generate_transaction_with_entities(\n",
        "                hnwi, target,\n",
        "                amount=round(random.uniform(500000, 5000000), 2),\n",
        "                transaction_type=\"investment_deposit\",\n",
        "                description=\"Portfolio investment\",\n",
        "                tags=[\"hnwi_transaction\", \"large_investment\"]\n",
        "            )\n",
        "            all_transactions.append(txn)\n",
        "\n",
        "# 1.6 Evolving Risk Pattern Transactions (300)\n",
        "print(\"  - Evolving risk pattern transactions...\")\n",
        "for evolving_entity in scenario_entities[\"evolving_risk\"]:\n",
        "    # Create a pattern that shows risk evolution\n",
        "    # Early transactions: normal\n",
        "    for _ in range(5):\n",
        "        counterparty = random.choice([e for e in all_entities if e[\"homeCountry\"] == evolving_entity[\"homeCountry\"]])\n",
        "        txn = generate_transaction_with_entities(\n",
        "            evolving_entity, counterparty,\n",
        "            amount=round(random.uniform(500, 5000), 2),\n",
        "            timestamp=fake.date_time_between(start_date=\"-3y\", end_date=\"-1y\", tzinfo=timezone.utc),\n",
        "            tags=[\"normal_pattern\"]\n",
        "        )\n",
        "        all_transactions.append(txn)\n",
        "\n",
        "    # Recent transactions: suspicious\n",
        "    high_risk_counterparties = [e for e in all_entities\n",
        "                               if e.get(\"riskAssessment\", {}).get(\"overall\", {}).get(\"level\") == \"high\"\n",
        "                               or e[\"homeCountry\"] in COUNTRIES_BY_RISK_GLOBAL[\"high\"]]\n",
        "\n",
        "    if high_risk_counterparties:\n",
        "        for _ in range(5):\n",
        "            counterparty = random.choice(high_risk_counterparties)\n",
        "            txn = generate_transaction_with_entities(\n",
        "                evolving_entity, counterparty,\n",
        "                amount=round(random.uniform(10000, 100000), 2),\n",
        "                timestamp=fake.date_time_between(start_date=\"-3m\", end_date=\"now\", tzinfo=timezone.utc),\n",
        "                tags=[\"pattern_change\", \"risk_escalation\"],\n",
        "                flagged=True\n",
        "            )\n",
        "            all_transactions.append(txn)\n",
        "\n",
        "# 1.7 Household Member Transactions (200)\n",
        "print(\"  - Household member transactions...\")\n",
        "household_members = scenario_entities[\"household\"]\n",
        "for i in range(0, len(household_members) - 1, 2):\n",
        "    if i + 1 < len(household_members):\n",
        "        member1 = household_members[i]\n",
        "        member2 = household_members[i + 1]\n",
        "\n",
        "        # Regular transfers between household members\n",
        "        for _ in range(10):\n",
        "            sender, receiver = random.choice([(member1, member2), (member2, member1)])\n",
        "            txn = generate_transaction_with_entities(\n",
        "                sender, receiver,\n",
        "                amount=round(random.uniform(100, 10000), 2),\n",
        "                transaction_type=random.choice([\"family_support\", \"household_expense\", \"gift_transfer\"]),\n",
        "                tags=[\"household_transfer\"]\n",
        "            )\n",
        "            all_transactions.append(txn)\n",
        "\n",
        "# 1.8 Structuring Patterns (200)\n",
        "print(\"  - Structuring pattern transactions...\")\n",
        "# Pick random entities to perform structuring\n",
        "structuring_entities = random.sample(all_entities, min(20, len(all_entities)))\n",
        "for entity in structuring_entities[:10]:\n",
        "    # Create a structuring pattern\n",
        "    target_entity = random.choice([e for e in all_entities if e[\"entityId\"] != entity[\"entityId\"]])\n",
        "    base_timestamp = fake.date_time_between(start_date=\"-1m\", end_date=\"now\", tzinfo=timezone.utc)\n",
        "\n",
        "    # Multiple transactions just under reporting threshold\n",
        "    num_structured = random.randint(3, 6)\n",
        "    for j in range(num_structured):\n",
        "        txn = generate_transaction_with_entities(\n",
        "            entity, target_entity,\n",
        "            amount=round(random.uniform(9000, 9900), 2),\n",
        "            timestamp=base_timestamp + timedelta(hours=j * random.randint(2, 8)),\n",
        "            is_structuring=True,\n",
        "            description=\"Cash deposit\",\n",
        "            tags=[\"potential_structuring\", \"below_threshold\"]\n",
        "        )\n",
        "        all_transactions.append(txn)\n",
        "\n",
        "# --- 2. Background Noise Transactions (12,000) ---\n",
        "print(f\"Generating {BACKGROUND_NOISE_TRANSACTIONS} background noise transactions...\")\n",
        "\n",
        "# Get all individual and organization entities for background transactions\n",
        "individuals = [e for e in all_entities if e[\"entityType\"] == \"individual\"]\n",
        "organizations = [e for e in all_entities if e[\"entityType\"] == \"organization\"]\n",
        "\n",
        "for i in range(BACKGROUND_NOISE_TRANSACTIONS):\n",
        "    if i % 1000 == 0:\n",
        "        print(f\"  - Generated {i}/{BACKGROUND_NOISE_TRANSACTIONS} background transactions...\")\n",
        "\n",
        "    # Randomly select transaction pattern\n",
        "    pattern = random.choices(\n",
        "        [\"individual_to_individual\", \"individual_to_org\", \"org_to_individual\", \"org_to_org\"],\n",
        "        weights=[0.15, 0.35, 0.25, 0.25],\n",
        "        k=1\n",
        "    )[0]\n",
        "\n",
        "    # Select entities based on pattern\n",
        "    if pattern == \"individual_to_individual\" and len(individuals) >= 2:\n",
        "        from_entity, to_entity = random.sample(individuals, 2)\n",
        "    elif pattern == \"individual_to_org\" and individuals and organizations:\n",
        "        from_entity = random.choice(individuals)\n",
        "        to_entity = random.choice(organizations)\n",
        "    elif pattern == \"org_to_individual\" and organizations and individuals:\n",
        "        from_entity = random.choice(organizations)\n",
        "        to_entity = random.choice(individuals)\n",
        "    elif pattern == \"org_to_org\" and len(organizations) >= 2:\n",
        "        from_entity, to_entity = random.sample(organizations, 2)\n",
        "    else:\n",
        "        # Fallback to any two entities\n",
        "        if len(all_entities) >= 2:\n",
        "            from_entity, to_entity = random.sample(all_entities, 2)\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    # Generate normal transaction\n",
        "    txn = generate_transaction_with_entities(\n",
        "        from_entity, to_entity,\n",
        "        timestamp=fake.date_time_between(start_date=\"-3y\", end_date=\"now\", tzinfo=timezone.utc),\n",
        "        tags=[\"background_noise\"]\n",
        "    )\n",
        "    all_transactions.append(txn)\n",
        "\n",
        "# --- 3. Insert Transactions ---\n",
        "print(f\"\\nTotal transactions generated: {len(all_transactions)}\")\n",
        "\n",
        "if all_transactions:\n",
        "    print(f\"Attempting to insert transactions into '{transactions_collection.name}' collection...\")\n",
        "    try:\n",
        "        transactions_collection.drop()\n",
        "        result = transactions_collection.insert_many(all_transactions, ordered=False)\n",
        "        print(f\"Successfully inserted {len(result.inserted_ids)} transactions.\")\n",
        "    except pymongo.errors.BulkWriteError as bwe:\n",
        "        print(f\"Bulk write error during transaction insertion:\")\n",
        "        write_errors = bwe.details.get('writeErrors', [])\n",
        "        print(f\"Total errors: {len(write_errors)}\")\n",
        "        for error_detail in write_errors[:5]:\n",
        "            print(f\"  Index: {error_detail['index']}, Code: {error_detail['code']}, Message: {error_detail['errmsg']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during transaction insertion: {e}\")\n",
        "\n",
        "# --- 4. Create Indexes for Graph Lookups ---\n",
        "print(\"\\n--- Creating indexes for graph lookups on transactions ---\")\n",
        "try:\n",
        "    # Primary indexes for graph traversal\n",
        "    transactions_collection.create_index(\n",
        "        [(\"fromEntityId\", pymongo.ASCENDING), (\"timestamp\", pymongo.DESCENDING)],\n",
        "        name=\"txn_from_entity_time_idx\"\n",
        "    )\n",
        "    print(\"- Index on 'fromEntityId' and 'timestamp' created.\")\n",
        "\n",
        "    transactions_collection.create_index(\n",
        "        [(\"toEntityId\", pymongo.ASCENDING), (\"timestamp\", pymongo.DESCENDING)],\n",
        "        name=\"txn_to_entity_time_idx\"\n",
        "    )\n",
        "    print(\"- Index on 'toEntityId' and 'timestamp' created.\")\n",
        "\n",
        "    # Compound index for bidirectional lookups\n",
        "    transactions_collection.create_index(\n",
        "        [(\"fromEntityId\", pymongo.ASCENDING), (\"toEntityId\", pymongo.ASCENDING)],\n",
        "        name=\"txn_from_to_idx\"\n",
        "    )\n",
        "    print(\"- Index on 'fromEntityId' and 'toEntityId' created.\")\n",
        "\n",
        "    # Other useful indexes\n",
        "    transactions_collection.create_index([(\"transactionId\", pymongo.ASCENDING)], unique=True, name=\"txn_id_unique_idx\")\n",
        "    transactions_collection.create_index([(\"timestamp\", pymongo.DESCENDING)], name=\"txn_timestamp_idx\")\n",
        "    transactions_collection.create_index([(\"amount\", pymongo.DESCENDING)], name=\"txn_amount_idx\")\n",
        "    transactions_collection.create_index([(\"riskScore\", pymongo.DESCENDING)], name=\"txn_risk_idx\")\n",
        "    transactions_collection.create_index([(\"tags\", pymongo.ASCENDING)], name=\"txn_tags_idx\")\n",
        "    transactions_collection.create_index([(\"flagged\", pymongo.ASCENDING)], name=\"txn_flagged_idx\")\n",
        "\n",
        "    print(\"- Additional indexes created successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error creating indexes: {e}\")\n",
        "\n",
        "print(\"\\n--- Enhanced transaction generation complete ---\")\n",
        "print(f\"\"\"\n",
        "Summary:\n",
        "- Total transactions: {len(all_transactions)}\n",
        "- Background noise: {sum(1 for t in all_transactions if \"background_noise\" in t.get(\"tags\", []))}\n",
        "- Scenario-specific: {sum(1 for t in all_transactions if \"background_noise\" not in t.get(\"tags\", []))}\n",
        "- Flagged transactions: {sum(1 for t in all_transactions if t.get(\"flagged\", False))}\n",
        "\n",
        "The transactions now support MongoDB $graphLookup with:\n",
        "- fromEntityId: References the source entity\n",
        "- toEntityId: References the target entity\n",
        "- Both fields link to actual entities in the entities collection\n",
        "- Proper indexes for efficient graph traversal\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13DVmfYWUO9I",
        "outputId": "7e0e672c-690a-4ff3-83f8-7768d358a8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching all entities for transaction generation...\n",
            "Categorizing entities by scenario...\n",
            "Generating 3000 scenario-specific transactions...\n",
            "  - PEP transactions...\n",
            "  - Shell company layering transactions...\n",
            "  - Complex organization structure transactions...\n",
            "  - Sanctioned organization transactions...\n",
            "  - HNWI investment pattern transactions...\n",
            "  - Evolving risk pattern transactions...\n",
            "  - Household member transactions...\n",
            "  - Structuring pattern transactions...\n",
            "Generating 12000 background noise transactions...\n",
            "  - Generated 0/12000 background transactions...\n",
            "  - Generated 1000/12000 background transactions...\n",
            "  - Generated 2000/12000 background transactions...\n",
            "  - Generated 3000/12000 background transactions...\n",
            "  - Generated 4000/12000 background transactions...\n",
            "  - Generated 5000/12000 background transactions...\n",
            "  - Generated 6000/12000 background transactions...\n",
            "  - Generated 7000/12000 background transactions...\n",
            "  - Generated 8000/12000 background transactions...\n",
            "  - Generated 9000/12000 background transactions...\n",
            "  - Generated 10000/12000 background transactions...\n",
            "  - Generated 11000/12000 background transactions...\n",
            "\n",
            "Total transactions generated: 12766\n",
            "Attempting to insert transactions into 'transactionsv2' collection...\n",
            "Successfully inserted 12766 transactions.\n",
            "\n",
            "--- Creating indexes for graph lookups on transactions ---\n",
            "- Index on 'fromEntityId' and 'timestamp' created.\n",
            "- Index on 'toEntityId' and 'timestamp' created.\n",
            "- Index on 'fromEntityId' and 'toEntityId' created.\n",
            "- Additional indexes created successfully.\n",
            "\n",
            "--- Enhanced transaction generation complete ---\n",
            "\n",
            "Summary:\n",
            "- Total transactions: 12766\n",
            "- Background noise: 12000\n",
            "- Scenario-specific: 766\n",
            "- Flagged transactions: 17\n",
            "\n",
            "The transactions now support MongoDB $graphLookup with:\n",
            "- fromEntityId: References the source entity\n",
            "- toEntityId: References the target entity\n",
            "- Both fields link to actual entities in the entities collection\n",
            "- Proper indexes for efficient graph traversal\n",
            "\n"
          ]
        }
      ]
    }
  ]
}