{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFZVGTdynQKc"
      },
      "source": [
        "# ThreatSight 360"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NfTPHJyoUj5"
      },
      "source": [
        "### This notebook creates synthetic data for a financial fraud detection system called \"ThreatSight 360\".\n",
        "\n",
        " This system leverages MongoDB's document model and advanced features to provide dynamic behavioral profiling. Unlike traditional SQL/rules-based approaches, this solution can adapt to emerging fraud patterns and provide more sophisticated detection capabilities.\n",
        "\n",
        "Key features demonstrated:\n",
        "- Rich document model for complex user profiles and transaction data\n",
        "- Nested documents for behavioral patterns\n",
        "- Geospatial data for location-based fraud detection\n",
        "- Vector search for similarity-based pattern matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GG6VEUXI2tVo"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade docutils==0.20 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K75T4lawnCXV"
      },
      "outputs": [],
      "source": [
        "!pip install pymongo pandas faker numpy scikit-learn python-dotenv geojson boto3 awscli -q\n",
        "\n",
        "import pymongo\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import datetime\n",
        "import json\n",
        "import uuid\n",
        "from faker import Faker\n",
        "from bson import ObjectId\n",
        "from sklearn.preprocessing import normalize\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import geojson\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import boto3\n",
        "from botocore.config import Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dg98ST4_ogP0"
      },
      "outputs": [],
      "source": [
        "# Initialize Faker for generating synthetic data\n",
        "fake = Faker()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BadIJ_-aog2w"
      },
      "source": [
        "### Setting Up MongoDB Atlas Connection (and AWS Bedrock)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsFt0QDSojR0"
      },
      "outputs": [],
      "source": [
        "# MongoDB Atlas connection string (replace with your actual connection string)\n",
        "MONGODB_URI = \"ENTER URI\"\n",
        "DB_NAME = \"threatsight360\"\n",
        "\n",
        "# Add your AWS credentials and region\n",
        "aws_access_key = \"ENTER\"\n",
        "aws_secret_key = \"ENTER\"\n",
        "aws_region = \"us-east-1\"  # Change to your preferred region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIhly_SGom1C"
      },
      "outputs": [],
      "source": [
        "# Connect to MongoDB Atlas\n",
        "client = pymongo.MongoClient(MONGODB_URI)\n",
        "db = client[DB_NAME]\n",
        "\n",
        "\n",
        "print(\"Connected to MongoDB Atlas!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8hCVGcuzhDW"
      },
      "outputs": [],
      "source": [
        "# Create collections\n",
        "customers_collection = db[\"customers\"]\n",
        "transactions_collection = db[\"transactions\"]\n",
        "fraud_patterns_collection = db[\"fraud_patterns\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NWQP4JTzUCz"
      },
      "outputs": [],
      "source": [
        "# Configure AWS Session\n",
        "boto3_config = Config(\n",
        "    region_name=aws_region,\n",
        "    signature_version='v4',\n",
        "    retries={\n",
        "        'max_attempts': 3,\n",
        "        'mode': 'standard'\n",
        "    }\n",
        ")\n",
        "\n",
        "# Initialize Bedrock Runtime client\n",
        "try:\n",
        "    bedrock_runtime = boto3.client(\n",
        "        service_name='bedrock-runtime',\n",
        "        aws_access_key_id=aws_access_key,\n",
        "        aws_secret_access_key=aws_secret_key,\n",
        "        config=boto3_config\n",
        "    )\n",
        "    print(\"AWS Bedrock client initialized successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: AWS Bedrock client initialization failed: {e}\")\n",
        "    print(\"Using fallback random embeddings - for demo purposes only\")\n",
        "    bedrock_runtime = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKyQxc8copNF"
      },
      "source": [
        "## Data Model Design\n",
        "Note: This section defines the data models we'll use in our MongoDB collections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXdgpMKEsP7G"
      },
      "source": [
        "We'll create a rich document model for customer profiles that includes:\n",
        "- Personal information\n",
        "- Account details\n",
        "- Behavioral profiles (nested documents)\n",
        "- Risk metrics\n",
        "\n",
        "### Transactions Collection\n",
        "- Transaction details\n",
        "- Location data as GeoJSON\n",
        "- Device information\n",
        "- Risk assessment\n",
        "\n",
        "### Fraud Patterns Collection\n",
        "- Pattern descriptions\n",
        "- Vector embeddings\n",
        "- Severity metrics\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVZn0KwRo6uM"
      },
      "source": [
        "### Customer Profiles Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eszJbDg1ovgH"
      },
      "outputs": [],
      "source": [
        "# Customer Profiles Collection\n",
        "\n",
        "def generate_customer_profiles(num_customers=50):\n",
        "    \"\"\"Generate synthetic customer profiles with behavioral patterns\"\"\"\n",
        "\n",
        "    customers = []\n",
        "\n",
        "    for _ in range(num_customers):\n",
        "        # Generate a customer ID\n",
        "        customer_id = str(ObjectId())\n",
        "\n",
        "        # Common merchant categories\n",
        "        merchant_categories = random.sample([\n",
        "            \"grocery\", \"restaurant\", \"retail\", \"travel\", \"entertainment\",\n",
        "            \"utilities\", \"healthcare\", \"electronics\", \"gas\", \"online\"\n",
        "        ], k=random.randint(3, 6))\n",
        "\n",
        "        # Generate 1-3 devices for this customer\n",
        "        devices = []\n",
        "        num_devices = random.randint(1, 3)\n",
        "\n",
        "        for _ in range(num_devices):\n",
        "            device = {\n",
        "                \"device_id\": str(uuid.uuid4()),\n",
        "                \"type\": random.choice([\"mobile\", \"desktop\", \"tablet\"]),\n",
        "                \"os\": random.choice([\"iOS\", \"Android\", \"Windows\", \"macOS\", \"Linux\"]),\n",
        "                \"browser\": random.choice([\"Chrome\", \"Safari\", \"Firefox\", \"Edge\"]),\n",
        "                \"ip_range\": [fake.ipv4() for _ in range(random.randint(1, 3))],\n",
        "                \"usual_locations\": [\n",
        "                    {\n",
        "                        \"city\": fake.city(),\n",
        "                        \"state\": fake.state(),\n",
        "                        \"country\": fake.country_code(),\n",
        "                        \"location\": {\n",
        "                            \"type\": \"Point\",\n",
        "                            \"coordinates\": [\n",
        "                                float(fake.longitude()),\n",
        "                                float(fake.latitude())\n",
        "                            ]\n",
        "                        },\n",
        "                        \"frequency\": random.uniform(0.1, 0.9)\n",
        "                    } for _ in range(random.randint(1, 3))\n",
        "                ]\n",
        "            }\n",
        "            devices.append(device)\n",
        "\n",
        "        # Generate transaction pattern behavior\n",
        "        transaction_behavior = {\n",
        "            \"avg_transaction_amount\": round(random.uniform(20, 500), 2),\n",
        "            \"std_transaction_amount\": round(random.uniform(10, 100), 2),\n",
        "            \"avg_transactions_per_day\": round(random.uniform(0.5, 5), 1),\n",
        "            \"common_merchant_categories\": merchant_categories,\n",
        "            \"usual_transaction_times\": [\n",
        "                {\n",
        "                    \"day_of_week\": day,\n",
        "                    \"hour_range\": [\n",
        "                        random.randint(8, 12),\n",
        "                        random.randint(13, 22)\n",
        "                    ]\n",
        "                } for day in random.sample(range(7), k=random.randint(3, 7))\n",
        "            ],\n",
        "            \"usual_transaction_locations\": [\n",
        "                {\n",
        "                    \"city\": fake.city(),\n",
        "                    \"state\": fake.state(),\n",
        "                    \"country\": fake.country_code(),\n",
        "                    \"location\": {\n",
        "                        \"type\": \"Point\",\n",
        "                        \"coordinates\": [\n",
        "                            float(fake.longitude()),\n",
        "                            float(fake.latitude())\n",
        "                        ]\n",
        "                    },\n",
        "                    \"frequency\": random.uniform(0.1, 0.9)\n",
        "                } for _ in range(random.randint(1, 3))\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Generate risk metrics\n",
        "        risk_profile = {\n",
        "            \"overall_risk_score\": round(random.uniform(1, 100), 2),\n",
        "            \"last_risk_assessment\": fake.date_time_between(start_date=\"-30d\", end_date=\"now\").isoformat(),\n",
        "            \"risk_factors\": random.sample([\n",
        "                \"irregular_location\", \"unusual_amount\", \"new_merchant_category\",\n",
        "                \"strange_time_pattern\", \"new_device\", \"velocity_alert\"\n",
        "            ], k=random.randint(0, 3)),\n",
        "            \"last_reported_fraud\": fake.date_time_between(start_date=\"-2y\", end_date=\"-1m\").isoformat() if random.random() < 0.1 else None\n",
        "        }\n",
        "\n",
        "        # Create the customer document\n",
        "        customer = {\n",
        "            \"_id\": customer_id,\n",
        "            \"personal_info\": {\n",
        "                \"name\": fake.name(),\n",
        "                \"email\": fake.email(),\n",
        "                \"phone\": fake.phone_number(),\n",
        "                \"address\": {\n",
        "                    \"street\": fake.street_address(),\n",
        "                    \"city\": fake.city(),\n",
        "                    \"state\": fake.state(),\n",
        "                    \"country\": fake.country(),\n",
        "                    \"zip\": fake.zipcode()\n",
        "                },\n",
        "                \"dob\": fake.date_of_birth(minimum_age=18, maximum_age=85).isoformat()\n",
        "            },\n",
        "            \"account_info\": {\n",
        "                \"account_number\": fake.bban(),\n",
        "                \"account_type\": random.choice([\"checking\", \"savings\", \"credit\"]),\n",
        "                \"creation_date\": fake.date_time_between(start_date=\"-10y\", end_date=\"-1m\").isoformat(),\n",
        "                \"status\": random.choice([\"active\", \"inactive\", \"suspended\", \"closed\"]) if random.random() < 0.1 else \"active\",\n",
        "                \"credit_score\": random.randint(300, 850)\n",
        "            },\n",
        "            \"behavioral_profile\": {\n",
        "                \"devices\": devices,\n",
        "                \"transaction_patterns\": transaction_behavior,\n",
        "            },\n",
        "            \"risk_profile\": risk_profile,\n",
        "            \"metadata\": {\n",
        "                \"last_updated\": datetime.now().isoformat(),\n",
        "                \"created_at\": fake.date_time_between(start_date=\"-10y\", end_date=\"-1m\").isoformat()\n",
        "            }\n",
        "        }\n",
        "\n",
        "        customers.append(customer)\n",
        "\n",
        "    return customers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhiE2pL5o9CF"
      },
      "source": [
        "### Transactions Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNWrww6UpCpb"
      },
      "outputs": [],
      "source": [
        "def generate_transactions(customers, num_months=6):\n",
        "    \"\"\"Generate 6 months of synthetic transactions with a mix of normal, suspicious, and fraudulent\"\"\"\n",
        "\n",
        "    transactions = []\n",
        "    end_date = datetime.now()\n",
        "    start_date = end_date - timedelta(days=30 * num_months)\n",
        "\n",
        "    # For each customer\n",
        "    for customer in customers:\n",
        "        customer_id = customer[\"_id\"]\n",
        "\n",
        "        # Calculate expected number of transactions based on customer's profile\n",
        "        avg_txns_per_day = customer[\"behavioral_profile\"][\"transaction_patterns\"][\"avg_transactions_per_day\"]\n",
        "        expected_txns = int(avg_txns_per_day * 30 * num_months)\n",
        "\n",
        "        # Add some randomness to the number of transactions\n",
        "        num_txns = int(expected_txns * random.uniform(0.8, 1.2))\n",
        "\n",
        "        # Get customer's behavioral patterns\n",
        "        avg_amount = customer[\"behavioral_profile\"][\"transaction_patterns\"][\"avg_transaction_amount\"]\n",
        "        std_amount = customer[\"behavioral_profile\"][\"transaction_patterns\"][\"std_transaction_amount\"]\n",
        "        usual_categories = customer[\"behavioral_profile\"][\"transaction_patterns\"][\"common_merchant_categories\"]\n",
        "        usual_locations = customer[\"behavioral_profile\"][\"transaction_patterns\"][\"usual_transaction_locations\"]\n",
        "        devices = customer[\"behavioral_profile\"][\"devices\"]\n",
        "\n",
        "        # Generate transactions for this customer\n",
        "        for _ in range(num_txns):\n",
        "            # Decide if this is a normal, suspicious, or fraudulent transaction\n",
        "            transaction_type = random.choices(\n",
        "                [\"normal\", \"suspicious\", \"fraudulent\"],\n",
        "                weights=[0.60, 0.25, 0.15],\n",
        "                k=1\n",
        "            )[0]\n",
        "\n",
        "            # Generate transaction details based on type\n",
        "            if transaction_type == \"normal\":\n",
        "                # Normal transaction - follows customer's patterns\n",
        "                amount = round(random.normalvariate(avg_amount, std_amount), 2)\n",
        "                if amount < 0:  # Ensure amount is positive\n",
        "                    amount = round(avg_amount * random.uniform(0.5, 0.8), 2)\n",
        "\n",
        "                category = random.choice(usual_categories)\n",
        "\n",
        "                # Select a usual location\n",
        "                location_data = random.choice(usual_locations)\n",
        "                location = location_data[\"location\"]\n",
        "\n",
        "                # Select one of customer's devices\n",
        "                device = random.choice(devices)\n",
        "                device_info = {\n",
        "                    \"device_id\": device[\"device_id\"],\n",
        "                    \"type\": device[\"type\"],\n",
        "                    \"os\": device[\"os\"],\n",
        "                    \"browser\": device[\"browser\"],\n",
        "                    \"ip\": random.choice(device[\"ip_range\"])\n",
        "                }\n",
        "\n",
        "                risk_score = random.uniform(1, 30)\n",
        "\n",
        "            elif transaction_type == \"suspicious\":\n",
        "                # Suspicious transaction - deviates from patterns but may be legitimate\n",
        "                amount = round(avg_amount * random.uniform(1.5, 3), 2)\n",
        "\n",
        "                # Maybe an unusual category\n",
        "                if random.random() < 0.7:\n",
        "                    all_categories = [\n",
        "                        \"grocery\", \"restaurant\", \"retail\", \"travel\", \"entertainment\",\n",
        "                        \"utilities\", \"healthcare\", \"electronics\", \"gas\", \"online\"\n",
        "                    ]\n",
        "                    unusual_categories = [c for c in all_categories if c not in usual_categories]\n",
        "                    if unusual_categories:\n",
        "                        category = random.choice(unusual_categories)\n",
        "                    else:\n",
        "                        category = random.choice(usual_categories)\n",
        "                else:\n",
        "                    category = random.choice(usual_categories)\n",
        "\n",
        "                # Maybe unusual location\n",
        "                if random.random() < 0.7:\n",
        "                    location = {\n",
        "                        \"type\": \"Point\",\n",
        "                        \"coordinates\": [\n",
        "                            float(fake.longitude()),\n",
        "                            float(fake.latitude())\n",
        "                        ]\n",
        "                    }\n",
        "                    location_data = {\n",
        "                        \"city\": fake.city(),\n",
        "                        \"state\": fake.state(),\n",
        "                        \"country\": fake.country_code(),\n",
        "                        \"location\": location\n",
        "                    }\n",
        "                else:\n",
        "                    location_data = random.choice(usual_locations)\n",
        "                    location = location_data[\"location\"]\n",
        "\n",
        "                # Use regular device\n",
        "                device = random.choice(devices)\n",
        "                device_info = {\n",
        "                    \"device_id\": device[\"device_id\"],\n",
        "                    \"type\": device[\"type\"],\n",
        "                    \"os\": device[\"os\"],\n",
        "                    \"browser\": device[\"browser\"],\n",
        "                    \"ip\": random.choice(device[\"ip_range\"])\n",
        "                }\n",
        "\n",
        "                risk_score = random.uniform(30, 70)\n",
        "\n",
        "            else:\n",
        "                # Fraudulent transaction - significant deviations\n",
        "                amount = round(avg_amount * random.uniform(3, 10), 2)\n",
        "\n",
        "                # Unusual category\n",
        "                all_categories = [\n",
        "                    \"grocery\", \"restaurant\", \"retail\", \"travel\", \"entertainment\",\n",
        "                    \"utilities\", \"healthcare\", \"electronics\", \"gas\", \"online\",\n",
        "                    \"gambling\", \"cryptocurrency\", \"jewelry\", \"money_transfer\"\n",
        "                ]\n",
        "                unusual_categories = [c for c in all_categories if c not in usual_categories]\n",
        "                category = random.choice(unusual_categories if unusual_categories else all_categories)\n",
        "\n",
        "                # Unusual location\n",
        "                location = {\n",
        "                    \"type\": \"Point\",\n",
        "                    \"coordinates\": [\n",
        "                        float(fake.longitude()),\n",
        "                        float(fake.latitude())\n",
        "                    ]\n",
        "                }\n",
        "                location_data = {\n",
        "                    \"city\": fake.city(),\n",
        "                    \"state\": fake.state(),\n",
        "                    \"country\": random.choice([\"RU\", \"NG\", \"CN\", \"BR\"]),  # High fraud countries for demo\n",
        "                    \"location\": location\n",
        "                }\n",
        "\n",
        "                # New unknown device\n",
        "                device_info = {\n",
        "                    \"device_id\": str(uuid.uuid4()),  # New unknown device\n",
        "                    \"type\": random.choice([\"mobile\", \"desktop\", \"tablet\"]),\n",
        "                    \"os\": random.choice([\"iOS\", \"Android\", \"Windows\", \"macOS\", \"Linux\"]),\n",
        "                    \"browser\": random.choice([\"Chrome\", \"Safari\", \"Firefox\", \"Edge\"]),\n",
        "                    \"ip\": fake.ipv4()\n",
        "                }\n",
        "\n",
        "                risk_score = random.uniform(70, 100)\n",
        "\n",
        "            # Generate timestamp within the specified date range\n",
        "            txn_date = fake.date_time_between(start_date=start_date, end_date=end_date)\n",
        "\n",
        "            # Create transaction document\n",
        "            transaction = {\n",
        "                \"customer_id\": customer_id,\n",
        "                \"transaction_id\": str(ObjectId()),\n",
        "                \"timestamp\": txn_date.isoformat(),\n",
        "                \"amount\": amount,\n",
        "                \"currency\": \"USD\",  # Simplified for demo\n",
        "                \"merchant\": {\n",
        "                    \"name\": fake.company(),\n",
        "                    \"category\": category,\n",
        "                    \"id\": str(uuid.uuid4())[:8]\n",
        "                },\n",
        "                \"location\": {\n",
        "                    \"city\": location_data[\"city\"],\n",
        "                    \"state\": location_data[\"state\"],\n",
        "                    \"country\": location_data[\"country\"],\n",
        "                    \"coordinates\": location\n",
        "                },\n",
        "                \"device_info\": device_info,\n",
        "                \"transaction_type\": random.choice([\"purchase\", \"refund\", \"payment\", \"transfer\", \"withdrawal\"]),\n",
        "                \"payment_method\": random.choice([\"credit_card\", \"debit_card\", \"bank_transfer\", \"digital_wallet\"]),\n",
        "                \"status\": \"completed\",\n",
        "                \"risk_assessment\": {\n",
        "                    \"score\": risk_score,\n",
        "                    \"level\": \"high\" if risk_score > 70 else \"medium\" if risk_score > 30 else \"low\",\n",
        "                    \"flags\": [],\n",
        "                    \"transaction_type\": transaction_type\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # Add risk flags based on risk score\n",
        "            if risk_score > 30:\n",
        "                possible_flags = [\"unusual_amount\", \"unexpected_location\", \"velocity_alert\",\n",
        "                                 \"new_merchant_category\", \"rare_transaction_time\"]\n",
        "                num_flags = min(int(risk_score / 20), len(possible_flags))\n",
        "                transaction[\"risk_assessment\"][\"flags\"] = random.sample(possible_flags, num_flags)\n",
        "\n",
        "            transactions.append(transaction)\n",
        "\n",
        "    return transactions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omzKuQALpKdi"
      },
      "source": [
        "### Fraud Patterns Collection\n",
        "\n",
        "For this demo, we'll create simple fraud pattern vectors that could be used for similarity matching. In a real-world scenario, these would be derived from actual fraud incidents and would be more complex.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNsV1pZDpNRJ"
      },
      "outputs": [],
      "source": [
        "def generate_bedrock_embedding(text_input):\n",
        "    \"\"\"Generate embeddings using AWS Bedrock Titan Embeddings model\"\"\"\n",
        "\n",
        "    if bedrock_runtime is None:\n",
        "        # Fallback to random embeddings if Bedrock client is not available\n",
        "        return normalize(np.random.rand(1, 1536)).tolist()[0]\n",
        "\n",
        "    try:\n",
        "        # Amazon Titan Embeddings model ID\n",
        "        model_id = \"amazon.titan-embed-text-v1\"\n",
        "\n",
        "        # Prepare request payload\n",
        "        request_body = json.dumps({\n",
        "            \"inputText\": text_input\n",
        "        })\n",
        "\n",
        "        # Invoke the model\n",
        "        response = bedrock_runtime.invoke_model(\n",
        "            modelId=model_id,\n",
        "            contentType=\"application/json\",\n",
        "            accept=\"application/json\",\n",
        "            body=request_body\n",
        "        )\n",
        "\n",
        "        # Parse response\n",
        "        response_body = json.loads(response.get('body').read())\n",
        "        embedding = response_body.get('embedding')\n",
        "\n",
        "        return embedding\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating embedding: {e}\")\n",
        "        # Fallback to random embeddings\n",
        "        return normalize(np.random.rand(1, 1536)).tolist()[0]\n",
        "\n",
        "def create_pattern_text_representation(pattern):\n",
        "    \"\"\"Create a text representation of a fraud pattern for embedding\"\"\"\n",
        "\n",
        "    text = f\"\"\"\n",
        "    Pattern Name: {pattern['pattern_name']}\n",
        "    Description: {pattern['description']}\n",
        "    Severity: {pattern['severity']}\n",
        "    Indicators: {', '.join(pattern['indicators'])}\n",
        "    \"\"\"\n",
        "\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjMOkig2zx7G"
      },
      "outputs": [],
      "source": [
        "def generate_fraud_patterns():\n",
        "    \"\"\"Generate sample fraud patterns with real embeddings via AWS Bedrock\"\"\"\n",
        "\n",
        "    # Define fraud patterns\n",
        "    patterns_data = [\n",
        "        {\n",
        "            \"pattern_name\": \"Account Takeover\",\n",
        "            \"description\": \"New device login followed by unusual transactions and settings changes\",\n",
        "            \"severity\": \"high\",\n",
        "            \"indicators\": [\n",
        "                \"new_device\",\n",
        "                \"unusual_location\",\n",
        "                \"settings_change\",\n",
        "                \"high_value_transaction\"\n",
        "            ],\n",
        "            \"detection_rate\": round(random.uniform(0.7, 0.95), 2),\n",
        "            \"false_positive_rate\": round(random.uniform(0.01, 0.1), 2)\n",
        "        },\n",
        "        {\n",
        "            \"pattern_name\": \"Card Testing\",\n",
        "            \"description\": \"Multiple small transactions in quick succession\",\n",
        "            \"severity\": \"medium\",\n",
        "            \"indicators\": [\n",
        "                \"multiple_small_transactions\",\n",
        "                \"high_velocity\",\n",
        "                \"unusual_merchant_pattern\"\n",
        "            ],\n",
        "            \"detection_rate\": round(random.uniform(0.6, 0.85), 2),\n",
        "            \"false_positive_rate\": round(random.uniform(0.05, 0.15), 2)\n",
        "        },\n",
        "        {\n",
        "            \"pattern_name\": \"Transaction Laundering\",\n",
        "            \"description\": \"Series of transactions that move funds through multiple accounts\",\n",
        "            \"severity\": \"high\",\n",
        "            \"indicators\": [\n",
        "                \"structured_amounts\",\n",
        "                \"circular_transfers\",\n",
        "                \"multiple_accounts\"\n",
        "            ],\n",
        "            \"detection_rate\": round(random.uniform(0.5, 0.8), 2),\n",
        "            \"false_positive_rate\": round(random.uniform(0.05, 0.2), 2)\n",
        "        },\n",
        "        {\n",
        "            \"pattern_name\": \"Geographic Anomaly\",\n",
        "            \"description\": \"Transactions from unusual locations or rapid location changes\",\n",
        "            \"severity\": \"medium\",\n",
        "            \"indicators\": [\n",
        "                \"unusual_location\",\n",
        "                \"impossible_travel\",\n",
        "                \"high_risk_country\"\n",
        "            ],\n",
        "            \"detection_rate\": round(random.uniform(0.6, 0.9), 2),\n",
        "            \"false_positive_rate\": round(random.uniform(0.02, 0.1), 2)\n",
        "        },\n",
        "        {\n",
        "            \"pattern_name\": \"Purchase Anomaly\",\n",
        "            \"description\": \"Purchases that deviate significantly from customer's usual behavior\",\n",
        "            \"severity\": \"low\",\n",
        "            \"indicators\": [\n",
        "                \"unusual_merchant_category\",\n",
        "                \"unusual_amount\",\n",
        "                \"unusual_time\"\n",
        "            ],\n",
        "            \"detection_rate\": round(random.uniform(0.4, 0.7), 2),\n",
        "            \"false_positive_rate\": round(random.uniform(0.1, 0.3), 2)\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Generate embeddings for each pattern\n",
        "    complete_patterns = []\n",
        "    for pattern in patterns_data:\n",
        "        # Create text representation of pattern\n",
        "        pattern_text = create_pattern_text_representation(pattern)\n",
        "\n",
        "        # Generate embedding\n",
        "        print(f\"Generating embedding for pattern: {pattern['pattern_name']}\")\n",
        "        vector_embedding = generate_bedrock_embedding(pattern_text)\n",
        "\n",
        "        # Add embedding to pattern\n",
        "        pattern[\"vector_embedding\"] = vector_embedding\n",
        "        complete_patterns.append(pattern)\n",
        "\n",
        "    return complete_patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClqgaIWYpSZ9"
      },
      "source": [
        "### Generating and Storing Synthetic Data to MongoDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbuU7GijpZPf"
      },
      "outputs": [],
      "source": [
        "# Generate and insert customer profiles\n",
        "print(\"Generating customer profiles...\")\n",
        "customers = generate_customer_profiles(50)\n",
        "if customers_collection.count_documents({}) == 0:\n",
        "    customers_collection.insert_many(customers)\n",
        "    print(f\"Inserted {len(customers)} customer profiles\")\n",
        "else:\n",
        "    print(\"Customer collection already populated, skipping insert\")\n",
        "\n",
        "# Generate and insert transactions\n",
        "print(\"Generating transactions...\")\n",
        "transactions = generate_transactions(customers, 6)\n",
        "if transactions_collection.count_documents({}) == 0:\n",
        "    transactions_collection.insert_many(transactions)\n",
        "    print(f\"Inserted {len(transactions)} transactions\")\n",
        "else:\n",
        "    print(\"Transactions collection already populated, skipping insert\")\n",
        "\n",
        "# Generate and insert fraud patterns\n",
        "print(\"Generating fraud patterns...\")\n",
        "fraud_patterns = generate_fraud_patterns()\n",
        "if fraud_patterns_collection.count_documents({}) == 0:\n",
        "    fraud_patterns_collection.insert_many(fraud_patterns)\n",
        "    print(f\"Inserted {len(fraud_patterns)} fraud patterns\")\n",
        "else:\n",
        "    print(\"Fraud patterns collection already populated, skipping insert\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBIq5gqpy4t4"
      },
      "source": [
        "### Convert Transactions to Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0P90D0n1DlN"
      },
      "outputs": [],
      "source": [
        "#helper function\n",
        "def generate_bedrock_embedding(text_input):\n",
        "    \"\"\"Generate embeddings using AWS Bedrock Titan Embeddings model - no fallbacks\"\"\"\n",
        "\n",
        "    # Check if bedrock_runtime is defined in the global scope\n",
        "    global bedrock_runtime\n",
        "\n",
        "    # Initialize bedrock_runtime if it's not defined\n",
        "    if 'bedrock_runtime' not in globals() or bedrock_runtime is None:\n",
        "        # Load environment variables\n",
        "        load_dotenv()\n",
        "\n",
        "        # Get AWS credentials\n",
        "        aws_access_key = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "        aws_secret_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "        aws_region = os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
        "\n",
        "        if not aws_access_key or not aws_secret_key:\n",
        "            raise ValueError(\"AWS credentials not found. Please set AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables.\")\n",
        "\n",
        "        # Configure AWS\n",
        "        boto3_config = Config(\n",
        "            region_name=aws_region,\n",
        "            signature_version='v4',\n",
        "            retries={\n",
        "                'max_attempts': 3,\n",
        "                'mode': 'standard'\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Initialize Bedrock client\n",
        "        bedrock_runtime = boto3.client(\n",
        "            service_name='bedrock-runtime',\n",
        "            aws_access_key_id=aws_access_key,\n",
        "            aws_secret_access_key=aws_secret_key,\n",
        "            config=boto3_config\n",
        "        )\n",
        "        print(\"AWS Bedrock client initialized successfully\")\n",
        "\n",
        "    # Amazon Titan Embeddings model ID\n",
        "    model_id = \"amazon.titan-embed-text-v1\"\n",
        "\n",
        "    # Prepare request payload\n",
        "    request_body = json.dumps({\n",
        "        \"inputText\": text_input\n",
        "    })\n",
        "\n",
        "    # Invoke the model\n",
        "    response = bedrock_runtime.invoke_model(\n",
        "        modelId=model_id,\n",
        "        contentType=\"application/json\",\n",
        "        accept=\"application/json\",\n",
        "        body=request_body\n",
        "    )\n",
        "\n",
        "    # Parse response\n",
        "    response_body = json.loads(response.get('body').read())\n",
        "    embedding = response_body.get('embedding')\n",
        "\n",
        "    if not embedding:\n",
        "        raise ValueError(\"Failed to generate embedding: Empty response from Bedrock API\")\n",
        "\n",
        "    return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6I-Vy_G80pxc"
      },
      "outputs": [],
      "source": [
        "#helper function\n",
        "def create_transaction_text_representation(transaction):\n",
        "    \"\"\"Create a text representation of a transaction for embedding\"\"\"\n",
        "\n",
        "    # Format transaction details as text\n",
        "    text = f\"\"\"\n",
        "    Transaction ID: {transaction.get('transaction_id', 'N/A')}\n",
        "    Amount: {transaction.get('amount', 0)} {transaction.get('currency', 'USD')}\n",
        "    Merchant: {transaction.get('merchant', {}).get('name', 'N/A')}\n",
        "    Merchant Category: {transaction.get('merchant', {}).get('category', 'N/A')}\n",
        "    Transaction Type: {transaction.get('transaction_type', 'N/A')}\n",
        "    Payment Method: {transaction.get('payment_method', 'N/A')}\n",
        "    Location: {transaction.get('location', {}).get('city', 'N/A')}, {transaction.get('location', {}).get('state', 'N/A')}, {transaction.get('location', {}).get('country', 'N/A')}\n",
        "    Device: {transaction.get('device_info', {}).get('type', 'N/A')}, {transaction.get('device_info', {}).get('os', 'N/A')}, {transaction.get('device_info', {}).get('browser', 'N/A')}\n",
        "    Risk Score: {transaction.get('risk_assessment', {}).get('score', 0)}\n",
        "    Risk Level: {transaction.get('risk_assessment', {}).get('level', 'N/A')}\n",
        "    Risk Flags: {', '.join(transaction.get('risk_assessment', {}).get('flags', [])) if transaction.get('risk_assessment', {}).get('flags', []) else 'None'}\n",
        "    \"\"\"\n",
        "\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFIOZuJSy5XB"
      },
      "outputs": [],
      "source": [
        "#Batch Generate Transaction Embeddings\n",
        "def batch_generate_transaction_embeddings(batch_size=10, max_documents=None):\n",
        "    \"\"\"\n",
        "    Generate embeddings for all transactions in the database and update the documents\n",
        "\n",
        "    Args:\n",
        "        batch_size: Number of transactions to process in each batch\n",
        "        max_documents: Maximum number of documents to process (None for all)\n",
        "\n",
        "    Returns:\n",
        "        dict: Summary of the processing\n",
        "    \"\"\"\n",
        "    # Ensure MongoDB collections are defined\n",
        "    global client, db, transactions_collection\n",
        "\n",
        "    # Check if MongoDB collections are defined, if not, reconnect\n",
        "    if 'transactions_collection' not in globals():\n",
        "        # Load environment variables from .env file (if using)\n",
        "        load_dotenv()\n",
        "\n",
        "        # Get MongoDB connection string from environment variables or set directly\n",
        "        MONGODB_URI = os.getenv(\"MONGODB_URI\", \"your_connection_string_here\")\n",
        "        DB_NAME = \"threatsight360\"\n",
        "\n",
        "        # Connect to MongoDB Atlas\n",
        "        client = pymongo.MongoClient(MONGODB_URI)\n",
        "        db = client[DB_NAME]\n",
        "\n",
        "        # Create collections\n",
        "        transactions_collection = db[\"transactions\"]\n",
        "        print(\"Reconnected to MongoDB and defined collections\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    total_processed = 0\n",
        "    successful = 0\n",
        "    failed = 0\n",
        "\n",
        "    # Get total count for progress tracking\n",
        "    total_docs = transactions_collection.count_documents({})\n",
        "    if max_documents:\n",
        "        total_docs = min(total_docs, max_documents)\n",
        "\n",
        "    print(f\"Starting embedding generation for {total_docs} transactions\")\n",
        "\n",
        "    # Process documents in batches\n",
        "    cursor = transactions_collection.find({})\n",
        "\n",
        "    batch = []\n",
        "    batch_ids = []\n",
        "\n",
        "    for transaction in cursor:\n",
        "        if max_documents and total_processed >= max_documents:\n",
        "            break\n",
        "\n",
        "        # Skip documents that already have embeddings\n",
        "        if \"vector_embedding\" in transaction:\n",
        "            total_processed += 1\n",
        "            successful += 1\n",
        "            continue\n",
        "\n",
        "        # Add transaction to current batch\n",
        "        batch.append(transaction)\n",
        "        batch_ids.append(transaction[\"_id\"])\n",
        "\n",
        "        # When batch is full, process it\n",
        "        if len(batch) >= batch_size:\n",
        "            process_batch_results = process_transaction_batch(batch, batch_ids)\n",
        "            successful += process_batch_results[\"successful\"]\n",
        "            failed += process_batch_results[\"failed\"]\n",
        "\n",
        "            # Clear batch\n",
        "            batch = []\n",
        "            batch_ids = []\n",
        "\n",
        "            # Update progress\n",
        "            total_processed += batch_size\n",
        "            elapsed_time = time.time() - start_time\n",
        "            progress = (total_processed / total_docs) * 100 if total_docs > 0 else 0\n",
        "\n",
        "            print(f\"Progress: {progress:.1f}% ({total_processed}/{total_docs}) - \"\n",
        "                  f\"Success: {successful}, Failed: {failed} - \"\n",
        "                  f\"Elapsed: {elapsed_time:.1f}s\")\n",
        "\n",
        "    # Process any remaining transactions in the final batch\n",
        "    if batch:\n",
        "        process_batch_results = process_transaction_batch(batch, batch_ids)\n",
        "        successful += process_batch_results[\"successful\"]\n",
        "        failed += process_batch_results[\"failed\"]\n",
        "        total_processed += len(batch)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    # Create summary\n",
        "    summary = {\n",
        "        \"total_processed\": total_processed,\n",
        "        \"successful\": successful,\n",
        "        \"failed\": failed,\n",
        "        \"elapsed_time\": elapsed_time,\n",
        "        \"average_time_per_doc\": elapsed_time / total_processed if total_processed > 0 else 0\n",
        "    }\n",
        "\n",
        "    print(f\"Embedding generation complete!\")\n",
        "    print(f\"Processed {total_processed} transactions in {elapsed_time:.1f} seconds\")\n",
        "    print(f\"Success: {successful}, Failed: {failed}\")\n",
        "\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBVEOTvV0QB0"
      },
      "outputs": [],
      "source": [
        "#helper function\n",
        "def process_transaction_batch(batch, batch_ids):\n",
        "    \"\"\"Process a batch of transactions to generate embeddings\"\"\"\n",
        "    successful = 0\n",
        "    failed = 0\n",
        "\n",
        "    for i, transaction in enumerate(batch):\n",
        "        try:\n",
        "            # Create text representation\n",
        "            transaction_text = create_transaction_text_representation(transaction)\n",
        "\n",
        "            # Generate embedding\n",
        "            embedding = generate_bedrock_embedding(transaction_text)\n",
        "\n",
        "            # Update transaction with embedding\n",
        "            result = transactions_collection.update_one(\n",
        "                {\"_id\": batch_ids[i]},\n",
        "                {\"$set\": {\"vector_embedding\": embedding}}\n",
        "            )\n",
        "\n",
        "            if result.modified_count == 1:\n",
        "                successful += 1\n",
        "            else:\n",
        "                failed += 1\n",
        "                print(f\"Warning: Failed to update transaction {transaction['transaction_id']}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            failed += 1\n",
        "            print(f\"Error processing transaction {transaction['transaction_id']}: {e}\")\n",
        "\n",
        "    return {\n",
        "        \"successful\": successful,\n",
        "        \"failed\": failed\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siUq7wlpzqHw"
      },
      "outputs": [],
      "source": [
        "# Process all transactions in batches of 50\n",
        "results = batch_generate_transaction_embeddings(batch_size=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrXE5wCvtFHq"
      },
      "source": [
        "### Create MongoDB Indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_I2DN-qtHdG"
      },
      "outputs": [],
      "source": [
        "# Create standard indexes for better query performance\n",
        "customers_collection.create_index(\"personal_info.email\")\n",
        "customers_collection.create_index(\"risk_profile.overall_risk_score\")\n",
        "transactions_collection.create_index(\"customer_id\")\n",
        "transactions_collection.create_index(\"timestamp\")\n",
        "transactions_collection.create_index(\"risk_assessment.score\")\n",
        "transactions_collection.create_index([(\"location.coordinates\", pymongo.GEOSPHERE)])\n",
        "fraud_patterns_collection.create_index(\"severity\")\n",
        "\n",
        "print(\"Created standard indexes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVJ4IrFjtK6H"
      },
      "outputs": [],
      "source": [
        "# Create a search index for the customers collection\n",
        "search_index = {\n",
        "    \"name\": \"customer_search_index\",\n",
        "    \"definition\": {\n",
        "        \"mappings\": {\n",
        "            \"dynamic\": True,\n",
        "            \"fields\": {\n",
        "                \"personal_info.name\": {\n",
        "                    \"type\": \"string\"\n",
        "                },\n",
        "                \"personal_info.email\": {\n",
        "                    \"type\": \"string\"\n",
        "                },\n",
        "                \"account_info.account_number\": {\n",
        "                    \"type\": \"string\"\n",
        "                },\n",
        "                \"risk_profile.overall_risk_score\": {\n",
        "                    \"type\": \"number\"\n",
        "                },\n",
        "                \"behavioral_profile.transaction_patterns.common_merchant_categories\": {\n",
        "                    \"type\": \"string\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJ08fHfVtTSG"
      },
      "outputs": [],
      "source": [
        "# Create the search index (if it doesn't exist)\n",
        "try:\n",
        "    db.command({\n",
        "        \"createSearchIndexes\": \"customers\",\n",
        "        \"indexes\": [search_index]\n",
        "    })\n",
        "    print(\"Created search index for customers collection\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating search index: {e}\")\n",
        "    print(\"Note: Make sure Atlas Search is enabled on your MongoDB Atlas cluster\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Frz8uhzktZmX"
      },
      "outputs": [],
      "source": [
        "# Create a vector search index for the fraud patterns collection\n",
        "vector_index = {\n",
        "    \"name\": \"fraud_pattern_vector_index\",\n",
        "    \"definition\": {\n",
        "        \"mappings\": {\n",
        "            \"dynamic\": True,\n",
        "            \"fields\": {\n",
        "                \"vector_embedding\": {\n",
        "                    \"type\": \"knnVector\",\n",
        "                    \"dimensions\": 1536,  # Amazon Titan Embeddings dimension\n",
        "                    \"similarity\": \"cosine\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1JmvarZtaZJ"
      },
      "outputs": [],
      "source": [
        "# Create the vector search index (if it doesn't exist)\n",
        "try:\n",
        "    db.command({\n",
        "        \"createSearchIndexes\": \"fraud_patterns\",\n",
        "        \"indexes\": [vector_index]\n",
        "    })\n",
        "    print(\"Created vector search index for fraud patterns collection\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating vector search index: {e}\")\n",
        "    print(\"Note: Vector search requires Atlas Search to be enabled on your MongoDB Atlas cluster\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVAlmwuXzOZ2"
      },
      "outputs": [],
      "source": [
        "# Create a vector search index for transactions collection\n",
        "# Create the vector search index for transactions (if it doesn't exist)\n",
        "try:\n",
        "    # Define the index configuration\n",
        "    transaction_index_config = {\n",
        "        \"name\": \"transaction_vector_index\",\n",
        "        \"definition\": {\n",
        "            \"mappings\": {\n",
        "                \"dynamic\": True,\n",
        "                \"fields\": {\n",
        "                    \"vector_embedding\": {\n",
        "                        \"type\": \"knnVector\",\n",
        "                        \"dimensions\": 1536,  # Amazon Titan Embeddings dimension\n",
        "                        \"similarity\": \"cosine\"\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Create the index\n",
        "    db.command({\n",
        "        \"createSearchIndexes\": \"transactions\",\n",
        "        \"indexes\": [transaction_index_config]\n",
        "    })\n",
        "    print(\"Created vector search index for transactions collection\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating transaction vector search index: {e}\")\n",
        "    print(\"Note: Vector search requires MongoDB Atlas with Search enabled\")\n",
        "    print(\"Alternative approach: You can create this index from the Atlas UI manually\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn5DAnPdpokb"
      },
      "source": [
        "## Example Queries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbRbRzrrtpY7"
      },
      "source": [
        "### Basic Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxMGKwM1thjE"
      },
      "outputs": [],
      "source": [
        "# Find customers with high risk score\n",
        "high_risk_customers = customers_collection.find(\n",
        "    {\"risk_profile.overall_risk_score\": {\"$gt\": 70}},\n",
        "    {\"personal_info.name\": 1, \"risk_profile.overall_risk_score\": 1, \"risk_profile.risk_factors\": 1}\n",
        ")\n",
        "\n",
        "print(\"High-Risk Customers:\")\n",
        "for customer in high_risk_customers:\n",
        "    print(f\"{customer['personal_info']['name']}: Score {customer['risk_profile']['overall_risk_score']}\")\n",
        "    if \"risk_factors\" in customer[\"risk_profile\"] and customer[\"risk_profile\"][\"risk_factors\"]:\n",
        "        print(f\"  Risk factors: {', '.join(customer['risk_profile']['risk_factors'])}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xGbjYL3trnC"
      },
      "source": [
        "### Transaction Summary by Risk Level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmNK2NfetvQm",
        "outputId": "2a9b2faa-5f56-4891-a8cf-a8732e562e60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transaction Analysis by Risk Level:\n",
            "Risk Level: high\n",
            "  Count: 4015\n",
            "  Average Amount: $1824.49\n",
            "  Total Amount: $7325328.92\n",
            "\n",
            "Risk Level: low\n",
            "  Count: 15579\n",
            "  Average Amount: $278.96\n",
            "  Total Amount: $4345984.82\n",
            "\n",
            "Risk Level: medium\n",
            "  Count: 6700\n",
            "  Average Amount: $621.26\n",
            "  Total Amount: $4162445.45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Analyze transactions by risk level\n",
        "risk_pipeline = [\n",
        "    {\n",
        "        \"$group\": {\n",
        "            \"_id\": \"$risk_assessment.level\",\n",
        "            \"count\": {\"$sum\": 1},\n",
        "            \"avg_amount\": {\"$avg\": \"$amount\"},\n",
        "            \"total_amount\": {\"$sum\": \"$amount\"}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$sort\": {\"_id\": 1}\n",
        "    }\n",
        "]\n",
        "\n",
        "risk_results = transactions_collection.aggregate(risk_pipeline)\n",
        "\n",
        "print(\"Transaction Analysis by Risk Level:\")\n",
        "for result in risk_results:\n",
        "    print(f\"Risk Level: {result['_id']}\")\n",
        "    print(f\"  Count: {result['count']}\")\n",
        "    print(f\"  Average Amount: ${result['avg_amount']:.2f}\")\n",
        "    print(f\"  Total Amount: ${result['total_amount']:.2f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xoJZYDft2IM"
      },
      "source": [
        "### Geospatial Query: Find Transactions Near a Location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nD2B7fctmrb",
        "outputId": "53661fde-fcfa-4b1a-e409-7f15bdac592b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transactions within 100km of [-94.144577, 24.8050725]:\n",
            "Transaction 67d2a82b654c7f1b869c4b0c: $225.17\n",
            "  Location: Bradleyburgh, CN\n",
            "  Risk Score: 86.0279076621168\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Find transactions near a specific location\n",
        "# For demo purposes, we'll use the location of the first transaction as our reference point\n",
        "sample_txn = transactions_collection.find_one()\n",
        "reference_location = sample_txn[\"location\"][\"coordinates\"][\"coordinates\"]\n",
        "\n",
        "nearby_txns = transactions_collection.find({\n",
        "    \"location.coordinates\": {\n",
        "        \"$nearSphere\": {\n",
        "            \"$geometry\": {\n",
        "                \"type\": \"Point\",\n",
        "                \"coordinates\": reference_location\n",
        "            },\n",
        "            \"$maxDistance\": 100000  # 100 km in meters\n",
        "        }\n",
        "    }\n",
        "})\n",
        "\n",
        "print(f\"Transactions within 100km of {reference_location}:\")\n",
        "for i, txn in enumerate(nearby_txns):\n",
        "    if i >= 5:  # Limit to 5 results for display\n",
        "        print(\"... and more\")\n",
        "        break\n",
        "    print(f\"Transaction {txn['transaction_id']}: ${txn['amount']:.2f}\")\n",
        "    print(f\"  Location: {txn['location']['city']}, {txn['location']['country']}\")\n",
        "    print(f\"  Risk Score: {txn['risk_assessment']['score']}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf7ADU-Ht9kj"
      },
      "source": [
        "### Vector Similarity Search: Find Similar Fraud Patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThtDkcY-t_ly",
        "outputId": "f4f87709-e776-43dd-ca52-b32630f144e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Patterns similar to 'Account Takeover':\n",
            "Pattern: Account Takeover\n",
            "  Description: New device login followed by unusual transactions and settings changes\n",
            "  Severity: high\n",
            "  Detection Rate: 0.83\n",
            "\n",
            "Pattern: Purchase Anomaly\n",
            "  Description: Purchases that deviate significantly from customer's usual behavior\n",
            "  Severity: low\n",
            "  Detection Rate: 0.64\n",
            "\n",
            "Pattern: Geographic Anomaly\n",
            "  Description: Transactions from unusual locations or rapid location changes\n",
            "  Severity: medium\n",
            "  Detection Rate: 0.68\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Find similar fraud patterns using vector search\n",
        "# For demo, we'll use the first pattern's vector as our query vector\n",
        "sample_pattern = fraud_patterns_collection.find_one()\n",
        "query_vector = sample_pattern[\"vector_embedding\"]\n",
        "\n",
        "vector_search_pipeline = [\n",
        "    {\n",
        "        \"$search\": {\n",
        "            \"index\": \"fraud_pattern_vector_index\",\n",
        "            \"knnBeta\": {\n",
        "                \"vector\": query_vector,\n",
        "                \"path\": \"vector_embedding\",\n",
        "                \"k\": 3,\n",
        "                \"filter\": {\n",
        "                    \"range\": {\n",
        "                        \"path\": \"detection_rate\",\n",
        "                        \"gte\": 0.6\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "try:\n",
        "    similar_patterns = db.fraud_patterns.aggregate(vector_search_pipeline)\n",
        "\n",
        "    print(f\"Patterns similar to '{sample_pattern['pattern_name']}':\")\n",
        "    for pattern in similar_patterns:\n",
        "        print(f\"Pattern: {pattern['pattern_name']}\")\n",
        "        print(f\"  Description: {pattern['description']}\")\n",
        "        print(f\"  Severity: {pattern['severity']}\")\n",
        "        print(f\"  Detection Rate: {pattern['detection_rate']}\")\n",
        "        print()\n",
        "except Exception as e:\n",
        "    print(f\"Error running vector search: {e}\")\n",
        "    print(\"Note: Vector search requires the Atlas Search feature to be enabled on your cluster\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybZPfNMf0SA3"
      },
      "source": [
        "### Transaction Embedding Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-yf700Z0VMh",
        "outputId": "b6ec7ff1-8016-42fb-d78c-9ee277312a47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating embedding for a high-risk transaction...\n",
            "Embedding generated with 1536 dimensions\n",
            "Transaction updated with embedding\n"
          ]
        }
      ],
      "source": [
        "def create_transaction_text_representation(transaction):\n",
        "    \"\"\"Create a text representation of a transaction for embedding\"\"\"\n",
        "\n",
        "    # Format transaction details as text\n",
        "    text = f\"\"\"\n",
        "    Transaction ID: {transaction['transaction_id']}\n",
        "    Amount: {transaction['amount']} {transaction['currency']}\n",
        "    Merchant: {transaction['merchant']['name']}\n",
        "    Merchant Category: {transaction['merchant']['category']}\n",
        "    Transaction Type: {transaction['transaction_type']}\n",
        "    Payment Method: {transaction['payment_method']}\n",
        "    Location: {transaction['location']['city']}, {transaction['location']['state']}, {transaction['location']['country']}\n",
        "    Device: {transaction['device_info']['type']}, {transaction['device_info']['os']}, {transaction['device_info']['browser']}\n",
        "    Risk Score: {transaction['risk_assessment']['score']}\n",
        "    Risk Level: {transaction['risk_assessment']['level']}\n",
        "    Risk Flags: {', '.join(transaction['risk_assessment']['flags']) if transaction['risk_assessment']['flags'] else 'None'}\n",
        "    \"\"\"\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "def generate_transaction_embedding(transaction):\n",
        "    \"\"\"Generate embedding for a transaction using AWS Bedrock\"\"\"\n",
        "\n",
        "    # Create text representation\n",
        "    transaction_text = create_transaction_text_representation(transaction)\n",
        "\n",
        "    # Generate embedding\n",
        "    embedding = generate_bedrock_embedding(transaction_text)\n",
        "\n",
        "    return embedding\n",
        "\n",
        "# Example: Generate embedding for a sample transaction\n",
        "sample_transaction = transactions_collection.find_one({\"risk_assessment.level\": \"high\"})\n",
        "if sample_transaction:\n",
        "    print(\"Generating embedding for a high-risk transaction...\")\n",
        "    sample_embedding = generate_transaction_embedding(sample_transaction)\n",
        "    print(f\"Embedding generated with {len(sample_embedding)} dimensions\")\n",
        "\n",
        "    # Update transaction with embedding (optional)\n",
        "    transactions_collection.update_one(\n",
        "        {\"_id\": sample_transaction[\"_id\"]},\n",
        "        {\"$set\": {\"vector_embedding\": sample_embedding}}\n",
        "    )\n",
        "    print(\"Transaction updated with embedding\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Act1lV9U0YKp"
      },
      "source": [
        "### Finding Similar Suspicious Transactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J10LUolg0V8F"
      },
      "outputs": [],
      "source": [
        "def find_similar_transactions(transaction_id, limit=5):\n",
        "    \"\"\"Find transactions similar to the given transaction using vector search\"\"\"\n",
        "\n",
        "    # Get the transaction\n",
        "    transaction = transactions_collection.find_one({\"transaction_id\": transaction_id})\n",
        "    if not transaction:\n",
        "        return {\"error\": \"Transaction not found\"}\n",
        "\n",
        "    # Check if transaction has embedding, if not generate one\n",
        "    if \"vector_embedding\" not in transaction:\n",
        "        embedding = generate_transaction_embedding(transaction)\n",
        "    else:\n",
        "        embedding = transaction[\"vector_embedding\"]\n",
        "\n",
        "    # Search for similar transactions\n",
        "    try:\n",
        "        pipeline = [\n",
        "            {\n",
        "                \"$search\": {\n",
        "                    \"index\": \"transaction_vector_index\",  # You'll need to create this index\n",
        "                    \"knnBeta\": {\n",
        "                        \"vector\": embedding,\n",
        "                        \"path\": \"vector_embedding\",\n",
        "                        \"k\": limit + 1  # +1 because the query transaction will be included\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"$match\": {\n",
        "                    \"transaction_id\": {\"$ne\": transaction_id}  # Exclude the query transaction\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"$limit\": limit\n",
        "            },\n",
        "            {\n",
        "                \"$project\": {\n",
        "                    \"transaction_id\": 1,\n",
        "                    \"amount\": 1,\n",
        "                    \"merchant\": 1,\n",
        "                    \"timestamp\": 1,\n",
        "                    \"risk_assessment.score\": 1,\n",
        "                    \"risk_assessment.level\": 1,\n",
        "                    \"location.city\": 1,\n",
        "                    \"location.country\": 1\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        similar_transactions = list(transactions_collection.aggregate(pipeline))\n",
        "        return similar_transactions\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error searching for similar transactions: {e}\")\n",
        "        return {\"error\": str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0c8tgs8uH46"
      },
      "source": [
        "### Behavioral Anomaly Detection Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj0eV14duQWi"
      },
      "outputs": [],
      "source": [
        "def detect_anomalies(customer_id):\n",
        "    \"\"\"Detect transaction anomalies for a specific customer based on their profile\"\"\"\n",
        "\n",
        "    # Get customer profile\n",
        "    customer = customers_collection.find_one({\"_id\": customer_id})\n",
        "    if not customer:\n",
        "        return {\"error\": \"Customer not found\"}\n",
        "\n",
        "    # Get customer's behavioral patterns\n",
        "    avg_amount = customer[\"behavioral_profile\"][\"transaction_patterns\"][\"avg_transaction_amount\"]\n",
        "    std_amount = customer[\"behavioral_profile\"][\"transaction_patterns\"][\"std_transaction_amount\"]\n",
        "    usual_categories = customer[\"behavioral_profile\"][\"transaction_patterns\"][\"common_merchant_categories\"]\n",
        "\n",
        "    # Get recent transactions\n",
        "    recent_txns = transactions_collection.find({\n",
        "        \"customer_id\": customer_id,\n",
        "        \"timestamp\": {\"$gte\": (datetime.now() - timedelta(days=30)).isoformat()}\n",
        "    }).sort(\"timestamp\", -1)\n",
        "\n",
        "    # Analyze transactions for anomalies\n",
        "    anomalies = []\n",
        "    for txn in recent_txns:\n",
        "        flags = []\n",
        "\n",
        "        # Check for amount anomaly\n",
        "        if txn[\"amount\"] > avg_amount + (3 * std_amount):\n",
        "            flags.append(\"unusual_amount\")\n",
        "\n",
        "        # Check for category anomaly\n",
        "        if txn[\"merchant\"][\"category\"] not in usual_categories:\n",
        "            flags.append(\"unusual_merchant_category\")\n",
        "\n",
        "        # Check for location anomaly\n",
        "        unusual_location = True\n",
        "        for loc in customer[\"behavioral_profile\"][\"transaction_patterns\"][\"usual_transaction_locations\"]:\n",
        "            # Simple check - in real system would use actual distance calculation\n",
        "            if loc[\"city\"] == txn[\"location\"][\"city\"]:\n",
        "                unusual_location = False\n",
        "                break\n",
        "\n",
        "        if unusual_location:\n",
        "            flags.append(\"unusual_location\")\n",
        "\n",
        "        # If any flags, add to anomalies\n",
        "        if flags:\n",
        "            anomalies.append({\n",
        "                \"transaction_id\": txn[\"transaction_id\"],\n",
        "                \"timestamp\": txn[\"timestamp\"],\n",
        "                \"amount\": txn[\"amount\"],\n",
        "                \"merchant\": txn[\"merchant\"][\"name\"],\n",
        "                \"flags\": flags,\n",
        "                \"risk_score\": txn[\"risk_assessment\"][\"score\"]\n",
        "            })\n",
        "\n",
        "    return {\n",
        "        \"customer_name\": customer[\"personal_info\"][\"name\"],\n",
        "        \"baseline\": {\n",
        "            \"avg_amount\": avg_amount,\n",
        "            \"usual_categories\": usual_categories\n",
        "        },\n",
        "        \"anomalies\": anomalies\n",
        "    }\n",
        "\n",
        "# Test the anomaly detection function with a random customer\n",
        "sample_customer = customers_collection.find_one()\n",
        "anomaly_results = detect_anomalies(sample_customer[\"_id\"])\n",
        "\n",
        "print(\"Behavioral Anomaly Detection Results:\")\n",
        "print(f\"Customer: {anomaly_results['customer_name']}\")\n",
        "print(f\"Baseline - Avg Amount: ${anomaly_results['baseline']['avg_amount']:.2f}\")\n",
        "print(f\"Baseline - Usual Categories: {', '.join(anomaly_results['baseline']['usual_categories'])}\")\n",
        "print(f\"Found {len(anomaly_results['anomalies'])} anomalies in the last 30 days\")\n",
        "\n",
        "for i, anomaly in enumerate(anomaly_results['anomalies']):\n",
        "    if i >= 3:  # Limit display to 3 anomalies\n",
        "        print(\"... and more\")\n",
        "        break\n",
        "    print(f\"\\nAnomaly {i+1}:\")\n",
        "    print(f\"  Transaction: {anomaly['transaction_id']}\")\n",
        "    print(f\"  Date: {anomaly['timestamp']}\")\n",
        "    print(f\"  Amount: ${anomaly['amount']:.2f}\")\n",
        "    print(f\"  Merchant: {anomaly['merchant']}\")\n",
        "    print(f\"  Flags: {', '.join(anomaly['flags'])}\")\n",
        "    print(f\"  Risk Score: {anomaly['risk_score']:.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp9HGE-cAKrj"
      },
      "source": [
        "### Vector Search Anomaly Detection Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGUCvZyGAJpv"
      },
      "outputs": [],
      "source": [
        "#Transaction Fraud Evaluation Using Vector Similarity\n",
        "\n",
        "def evaluate_transaction_fraud(transaction, similarity_threshold=0.85, top_k=5):\n",
        "    \"\"\"\n",
        "    Evaluate a transaction for potential fraud by:\n",
        "    1. Converting it to an embedding\n",
        "    2. Finding similar transactions using vector search\n",
        "    3. Calculating a fraud score based on similarities\n",
        "\n",
        "    Args:\n",
        "        transaction: Transaction document or dict with transaction details\n",
        "        similarity_threshold: Threshold for considering transactions similar (0.0-1.0)\n",
        "        top_k: Number of similar transactions to return\n",
        "\n",
        "    Returns:\n",
        "        dict: Evaluation results including fraud score and similar transactions\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Generate embedding for the transaction\n",
        "        if not transaction.get('vector_embedding'):\n",
        "            print(\"Generating embedding for transaction...\")\n",
        "            transaction_text = create_transaction_text_representation(transaction)\n",
        "            embedding = generate_bedrock_embedding(transaction_text)\n",
        "        else:\n",
        "            embedding = transaction['vector_embedding']\n",
        "\n",
        "        # Find similar transactions using vector search\n",
        "        try:\n",
        "            pipeline = [\n",
        "                {\n",
        "                    \"$search\": {\n",
        "                        \"index\": \"transaction_vector_index\",\n",
        "                        \"knnBeta\": {\n",
        "                            \"vector\": embedding,\n",
        "                            \"path\": \"vector_embedding\",\n",
        "                            \"k\": top_k + 1  # +1 to account for self-match\n",
        "                        }\n",
        "                    }\n",
        "                },\n",
        "                {\n",
        "                    \"$project\": {\n",
        "                        \"transaction_id\": 1,\n",
        "                        \"amount\": 1,\n",
        "                        \"merchant\": 1,\n",
        "                        \"risk_assessment.score\": 1,\n",
        "                        \"risk_assessment.level\": 1,\n",
        "                        \"risk_assessment.transaction_type\": 1,\n",
        "                        \"timestamp\": 1,\n",
        "                        \"location.city\": 1,\n",
        "                        \"location.country\": 1,\n",
        "                        \"score\": {\"$meta\": \"searchScore\"}  # Get the similarity score\n",
        "                    }\n",
        "                }\n",
        "            ]\n",
        "\n",
        "            similar_transactions = list(transactions_collection.aggregate(pipeline))\n",
        "\n",
        "            # Remove self-match if present\n",
        "            if transaction.get('transaction_id'):\n",
        "                similar_transactions = [t for t in similar_transactions\n",
        "                                      if t.get('transaction_id') != transaction.get('transaction_id')]\n",
        "\n",
        "            # Take only top_k transactions\n",
        "            similar_transactions = similar_transactions[:top_k]\n",
        "\n",
        "            # Calculate fraud score based on similar fraudulent transactions\n",
        "            total_score = 0\n",
        "            fraud_weight = 0\n",
        "\n",
        "            for similar_tx in similar_transactions:\n",
        "                # Get similarity score - normalize search score to 0-1 range\n",
        "                similarity = min(similar_tx.get('score', 0) / 1.0, 1.0)\n",
        "\n",
        "                # Skip transactions with similarity below threshold\n",
        "                if similarity < similarity_threshold:\n",
        "                    continue\n",
        "\n",
        "                # Get risk level of similar transaction\n",
        "                tx_type = similar_tx.get('risk_assessment', {}).get('transaction_type', 'normal')\n",
        "                tx_risk_score = similar_tx.get('risk_assessment', {}).get('score', 0)\n",
        "\n",
        "                # Weight by transaction type and similarity\n",
        "                if tx_type == 'fraudulent':\n",
        "                    weight = 1.0\n",
        "                elif tx_type == 'suspicious':\n",
        "                    weight = 0.5\n",
        "                else:\n",
        "                    weight = 0.1\n",
        "\n",
        "                # Add to weighted average\n",
        "                total_score += tx_risk_score * similarity * weight\n",
        "                fraud_weight += similarity * weight\n",
        "\n",
        "            # Calculate final fraud score (0-100)\n",
        "            fraud_score = round(total_score / max(fraud_weight, 0.001), 2)\n",
        "\n",
        "            # Determine risk level\n",
        "            if fraud_score >= 70:\n",
        "                risk_level = \"high\"\n",
        "            elif fraud_score >= 30:\n",
        "                risk_level = \"medium\"\n",
        "            else:\n",
        "                risk_level = \"low\"\n",
        "\n",
        "            return {\n",
        "                \"fraud_score\": fraud_score,\n",
        "                \"risk_level\": risk_level,\n",
        "                \"similar_transactions\": similar_transactions,\n",
        "                \"evaluation_method\": \"vector_similarity\",\n",
        "                \"threshold_used\": similarity_threshold\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error performing vector search: {e}\")\n",
        "            # Fallback to basic evaluation if vector search fails\n",
        "            return {\n",
        "                \"fraud_score\": transaction.get('risk_assessment', {}).get('score', 50),\n",
        "                \"risk_level\": transaction.get('risk_assessment', {}).get('level', 'medium'),\n",
        "                \"similar_transactions\": [],\n",
        "                \"evaluation_method\": \"fallback_basic\",\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating transaction: {e}\")\n",
        "        return {\n",
        "            \"error\": str(e),\n",
        "            \"fraud_score\": 50,  # Default middle score\n",
        "            \"risk_level\": \"medium\",\n",
        "            \"evaluation_method\": \"error_fallback\"\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6jlWpKuAbwo"
      },
      "outputs": [],
      "source": [
        "def test_fraud_evaluation():\n",
        "    \"\"\"\n",
        "    Test the fraud evaluation function on normal and fraudulent transactions\n",
        "    \"\"\"\n",
        "    print(\"Testing fraud evaluation on normal and fraudulent transactions...\")\n",
        "\n",
        "    # Find a few normal transactions\n",
        "    normal_transactions = list(transactions_collection.find(\n",
        "        {\"risk_assessment.transaction_type\": \"normal\"},\n",
        "        {\"transaction_id\": 1, \"amount\": 1, \"merchant\": 1, \"risk_assessment\": 1}\n",
        "    ).limit(3))\n",
        "\n",
        "    # Find a few fraudulent transactions\n",
        "    fraudulent_transactions = list(transactions_collection.find(\n",
        "        {\"risk_assessment.transaction_type\": \"fraudulent\"},\n",
        "        {\"transaction_id\": 1, \"amount\": 1, \"merchant\": 1, \"risk_assessment\": 1}\n",
        "    ).limit(3))\n",
        "\n",
        "    print(f\"Found {len(normal_transactions)} normal and {len(fraudulent_transactions)} fraudulent transactions for testing\")\n",
        "\n",
        "    # Test normal transactions\n",
        "    print(\"\\nEvaluating normal transactions:\")\n",
        "    for idx, tx in enumerate(normal_transactions):\n",
        "        print(f\"\\nNormal Transaction {idx+1}: {tx.get('transaction_id')}\")\n",
        "        print(f\"Original risk score: {tx.get('risk_assessment', {}).get('score', 'N/A')}\")\n",
        "\n",
        "        # Evaluate the transaction\n",
        "        result = evaluate_transaction_fraud(tx)\n",
        "\n",
        "        print(f\"Calculated fraud score: {result.get('fraud_score')}\")\n",
        "        print(f\"Risk level: {result.get('risk_level')}\")\n",
        "        print(f\"Similar transactions found: {len(result.get('similar_transactions', []))}\")\n",
        "\n",
        "    # Test fraudulent transactions\n",
        "    print(\"\\nEvaluating fraudulent transactions:\")\n",
        "    for idx, tx in enumerate(fraudulent_transactions):\n",
        "        print(f\"\\nFraudulent Transaction {idx+1}: {tx.get('transaction_id')}\")\n",
        "        print(f\"Original risk score: {tx.get('risk_assessment', {}).get('score', 'N/A')}\")\n",
        "\n",
        "        # Evaluate the transaction\n",
        "        result = evaluate_transaction_fraud(tx)\n",
        "\n",
        "        print(f\"Calculated fraud score: {result.get('fraud_score')}\")\n",
        "        print(f\"Risk level: {result.get('risk_level')}\")\n",
        "        print(f\"Similar transactions found: {len(result.get('similar_transactions', []))}\")\n",
        "\n",
        "        # Print top similar transaction\n",
        "        if result.get('similar_transactions'):\n",
        "            top_similar = result['similar_transactions'][0]\n",
        "            print(f\"Top similar transaction: {top_similar.get('transaction_id')}\")\n",
        "            print(f\"  Type: {top_similar.get('risk_assessment', {}).get('transaction_type', 'N/A')}\")\n",
        "            print(f\"  Score: {top_similar.get('risk_assessment', {}).get('score', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vissWo5gAjFI"
      },
      "outputs": [],
      "source": [
        "def simulate_transaction_evaluation(\n",
        "    amount=None,\n",
        "    merchant_category=None,\n",
        "    location=None,\n",
        "    customer_id=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Simulate a transaction with the given parameters and evaluate it for fraud\n",
        "\n",
        "    Args:\n",
        "        amount: Transaction amount (float)\n",
        "        merchant_category: Merchant category (string)\n",
        "        location: Dictionary with city, state, country, coordinates\n",
        "        customer_id: Customer ID (to use their profile for defaults)\n",
        "\n",
        "    Returns:\n",
        "        dict: Evaluation results\n",
        "    \"\"\"\n",
        "    # Get default values from a random customer if customer_id is not provided\n",
        "    if not customer_id:\n",
        "        customer = customers_collection.find_one()\n",
        "    else:\n",
        "        customer = customers_collection.find_one({\"_id\": customer_id})\n",
        "\n",
        "    if not customer:\n",
        "        print(\"Customer not found. Using random values.\")\n",
        "        customer_id = None\n",
        "        avg_amount = 100\n",
        "        std_amount = 20\n",
        "        common_categories = [\"retail\", \"restaurant\", \"grocery\"]\n",
        "        common_location = {\n",
        "            \"city\": \"New York\",\n",
        "            \"state\": \"NY\",\n",
        "            \"country\": \"US\",\n",
        "            \"coordinates\": {\n",
        "                \"type\": \"Point\",\n",
        "                \"coordinates\": [-74.0060, 40.7128]\n",
        "            }\n",
        "        }\n",
        "    else:\n",
        "        customer_id = customer.get(\"_id\")\n",
        "        avg_amount = customer.get(\"behavioral_profile\", {}).get(\"transaction_patterns\", {}).get(\"avg_transaction_amount\", 100)\n",
        "        std_amount = customer.get(\"behavioral_profile\", {}).get(\"transaction_patterns\", {}).get(\"std_transaction_amount\", 20)\n",
        "        common_categories = customer.get(\"behavioral_profile\", {}).get(\"transaction_patterns\", {}).get(\"common_merchant_categories\", [\"retail\"])\n",
        "\n",
        "        # Get a common location\n",
        "        location_data = customer.get(\"behavioral_profile\", {}).get(\"transaction_patterns\", {}).get(\"usual_transaction_locations\", [])\n",
        "        common_location = location_data[0] if location_data else {\n",
        "            \"city\": \"New York\",\n",
        "            \"state\": \"NY\",\n",
        "            \"country\": \"US\",\n",
        "            \"location\": {\n",
        "                \"type\": \"Point\",\n",
        "                \"coordinates\": [-74.0060, 40.7128]\n",
        "            }\n",
        "        }\n",
        "\n",
        "    # Use provided values or defaults\n",
        "    if amount is None:\n",
        "        amount = round(random.normalvariate(avg_amount, std_amount), 2)\n",
        "        if amount < 0:\n",
        "            amount = round(avg_amount * 0.5, 2)\n",
        "\n",
        "    if merchant_category is None:\n",
        "        merchant_category = random.choice(common_categories)\n",
        "\n",
        "    if location is None:\n",
        "        location = common_location\n",
        "\n",
        "    # Create a synthetic transaction\n",
        "    transaction = {\n",
        "        \"transaction_id\": str(uuid.uuid4()),\n",
        "        \"customer_id\": customer_id,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"amount\": amount,\n",
        "        \"currency\": \"USD\",\n",
        "        \"merchant\": {\n",
        "            \"name\": fake.company(),\n",
        "            \"category\": merchant_category,\n",
        "            \"id\": str(uuid.uuid4())[:8]\n",
        "        },\n",
        "        \"location\": location,\n",
        "        \"device_info\": {\n",
        "            \"device_id\": str(uuid.uuid4()),\n",
        "            \"type\": random.choice([\"mobile\", \"desktop\", \"tablet\"]),\n",
        "            \"os\": random.choice([\"iOS\", \"Android\", \"Windows\", \"macOS\"]),\n",
        "            \"browser\": random.choice([\"Chrome\", \"Safari\", \"Firefox\", \"Edge\"]),\n",
        "            \"ip\": fake.ipv4()\n",
        "        },\n",
        "        \"transaction_type\": random.choice([\"purchase\", \"payment\"]),\n",
        "        \"payment_method\": random.choice([\"credit_card\", \"debit_card\"]),\n",
        "        \"status\": \"pending\"\n",
        "    }\n",
        "\n",
        "    print(f\"Simulated transaction:\")\n",
        "    print(f\"Amount: ${transaction['amount']:.2f}\")\n",
        "    print(f\"Merchant Category: {transaction['merchant']['category']}\")\n",
        "    print(f\"Location: {transaction['location']['city']}, {transaction['location']['country']}\")\n",
        "\n",
        "    # Generate embedding and evaluate\n",
        "    print(\"\\nEvaluating transaction...\")\n",
        "    result = evaluate_transaction_fraud(transaction)\n",
        "\n",
        "    print(f\"\\nEvaluation Results:\")\n",
        "    print(f\"Fraud Score: {result.get('fraud_score')}\")\n",
        "    print(f\"Risk Level: {result.get('risk_level')}\")\n",
        "    print(f\"Similar Transactions Found: {len(result.get('similar_transactions', []))}\")\n",
        "\n",
        "    # Display similar transactions\n",
        "    if result.get('similar_transactions'):\n",
        "        print(\"\\nTop Similar Transactions:\")\n",
        "        for i, tx in enumerate(result['similar_transactions'][:3]):  # Show top 3\n",
        "            print(f\"{i+1}. Transaction ID: {tx.get('transaction_id')}\")\n",
        "            print(f\"   Amount: ${tx.get('amount', 0):.2f}\")\n",
        "            print(f\"   Risk Level: {tx.get('risk_assessment', {}).get('level', 'unknown')}\")\n",
        "            print(f\"   Type: {tx.get('risk_assessment', {}).get('transaction_type', 'unknown')}\")\n",
        "\n",
        "    return {\n",
        "        \"transaction\": transaction,\n",
        "        \"evaluation\": result\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RKRil63Asan"
      },
      "outputs": [],
      "source": [
        "# Option 1: Run the test evaluation function\n",
        "# This tests existing normal and fraudulent transactions\n",
        "test_fraud_evaluation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f61qrHWAw4J"
      },
      "outputs": [],
      "source": [
        "# Option 2: Simulate a normal transaction\n",
        "print(\"\\n\\n======= SIMULATING NORMAL TRANSACTION =======\")\n",
        "normal_result = simulate_transaction_evaluation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xw-HF0RuA4gR"
      },
      "outputs": [],
      "source": [
        "# Option 3: Simulate a high-amount transaction (potentially suspicious)\n",
        "print(\"\\n\\n======= SIMULATING HIGH-AMOUNT TRANSACTION =======\")\n",
        "high_amount_result = simulate_transaction_evaluation(\n",
        "    amount=3000  # Set a high amount for the transaction\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRTR66mvBC0s"
      },
      "outputs": [],
      "source": [
        "# Option 4: Simulate a transaction from an unusual location\n",
        "print(\"\\n\\n======= SIMULATING UNUSUAL LOCATION TRANSACTION =======\")\n",
        "unusual_location = {\n",
        "    \"city\": \"Lagos\",\n",
        "    \"state\": \"Lagos\",\n",
        "    \"country\": \"NG\",\n",
        "    \"location\": {\n",
        "        \"type\": \"Point\",\n",
        "        \"coordinates\": [3.3792, 6.5244]  # Lagos, Nigeria coordinates\n",
        "    }\n",
        "}\n",
        "unusual_location_result = simulate_transaction_evaluation(location=unusual_location)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLBy1-pCpqVu"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook demonstrates how MongoDB's document model and advanced features enable sophisticated fraud detection capabilities through dynamic behavioral profiling. Key advantages demonstrated include:\n",
        "\n",
        "1. **Flexible Schema**: The document model allows for rich, nested data structures that can capture complex customer behavior patterns.\n",
        "\n",
        "2. **Geospatial Capabilities**: MongoDB's geospatial indexing enables location-based fraud detection.\n",
        "\n",
        "3. **Vector Search**: Similarity-based pattern matching allows the system to identify emerging fraud patterns.\n",
        "\n",
        "4. **Aggregation Framework**: Complex analysis can be performed directly in the database.\n",
        "\n",
        "5. **Performance**: Proper indexing ensures fast queries even with large datasets.\n",
        "\n",
        "For a production system, you would want to add:\n",
        "- Real-time transaction scoring\n",
        "- Machine learning models for pattern recognition\n",
        "- Alert management system\n",
        "- Case management for fraud analysts\n",
        "- Integration with external data sources"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7xoJZYDft2IM"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}