import json
import os
import logging
from typing import Optional, List

from .client import BedrockClient
from botocore.exceptions import ClientError
from dotenv import load_dotenv

load_dotenv()

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class BedrockTitanEmbeddings(BedrockClient):
    """ A class to generate text embeddings using the Amazon Titan Embeddings model for AML/KYC entity search. """

    log: logging.Logger = logging.getLogger("BedrockTitanEmbeddings")

    def __init__(self, aws_access_key: Optional[str] = None, aws_secret_key: Optional[str] = None,
                 region_name: Optional[str] = "us-east-1", model_id: Optional[str] = "amazon.titan-embed-text-v1",
                 use_default_credentials: Optional[bool] = False) -> None:
        super().__init__(aws_access_key=aws_access_key, aws_secret_key=aws_secret_key,
                        region_name=region_name, use_default_credentials=use_default_credentials)
        """
        Initialize the BedrockTitanEmbeddings class for AML/KYC entity search.
        
        Args:
            aws_access_key (str): The AWS access key.
            aws_secret_key (str): The AWS secret key.
            region_name (str): The AWS region name.
            model_id (str): The model ID to use. Default is Amazon Titan Embeddings model.
        """
        self.model_id = model_id
        self.bedrock_client = self._get_bedrock_client()

    def generate_text_embeddings(self, body: str):
        """
        Generate text embedding by using the Titan Embed model.
        Args:
            body (str): The request body to use.
        Returns:
            dict: The response from the model.
        """
        accept = '*/*'
        content_type = 'application/json'

        response = self.bedrock_client.invoke_model(
            body=body,
            modelId=self.model_id,
            accept=accept,
            contentType=content_type
        )

        return response

    def predict(self, text: str) -> List[float]:
        """ Predict text embeddings based on the input text for entity similarity search.

        Args:
            text (str): The input text to generate embeddings for (e.g., search queries, entity descriptions).

        Returns:
            list: The text embeddings generated by the model (1536 dimensions for compatibility with entity profiles).
        """
        try:
            # Titan model format - optimized for entity and risk profile search queries
            body = json.dumps({
                "inputText": text
            })
            response = self.generate_text_embeddings(body=body)
            
            # Extract the response embeddings
            response_body = json.loads(response.get('body').read())
            embedding = response_body.get("embedding")
            
            if not embedding:
                self.log.error("No embedding found in response: %s", response_body)
                raise ValueError("No embedding found in response")
                
            return embedding
        except ClientError as err:
            message = err.response["Error"]["Message"]
            self.log.error("A client error occurred: %s", message)
            raise


# Singleton instance for reuse across API calls
_embedding_model = None


def get_embedding_model():
    """
    Get or create a singleton instance of the BedrockTitanEmbeddings class.
    This helps avoid creating new clients for each API call.

    Returns:
        BedrockTitanEmbeddings: The embedding model instance.
    """
    global _embedding_model

    if _embedding_model is None:
        # Check if we should use default credentials (SSO, IAM roles, etc.)
        use_sso = os.getenv("AWS_USE_SSO", "false").lower() in ("true", "1", "yes")
        region_name = os.getenv("AWS_REGION", "us-east-1")

        if use_sso:
            # Use default credential chain - don't pass explicit credentials
            _embedding_model = BedrockTitanEmbeddings(
                model_id="arn:aws:bedrock:us-east-1:275662791714:application-inference-profile/78hc25ft38p2",
                region_name=region_name,
                use_default_credentials=True
            )
        else:
            # Fall back to explicit credentials for backward compatibility
            aws_access_key = os.getenv("AWS_ACCESS_KEY_ID")
            aws_secret_key = os.getenv("AWS_SECRET_ACCESS_KEY")

            _embedding_model = BedrockTitanEmbeddings(
                model_id="arn:aws:bedrock:us-east-1:275662791714:application-inference-profile/78hc25ft38p2",
                region_name=region_name,
                aws_access_key=aws_access_key,
                aws_secret_key=aws_secret_key
            )

    return _embedding_model


async def get_embedding(text: str) -> List[float]:
    """
    Generate embeddings for the given text using Amazon Bedrock Titan model.
    Optimized for AML/KYC entity search queries and descriptions.
    
    Args:
        text (str): The text to generate embeddings for (e.g., "high-risk individuals with offshore accounts").
        
    Returns:
        List[float]: The embeddings vector (1536 dimensions).
        
    Raises:
        Exception: If there's an error generating the embeddings.
    """
    try:
        model = get_embedding_model()
        embeddings = model.predict(text)
        logger.info(f"Generated embeddings for text: '{text[:50]}...' (length: {len(embeddings)})")
        return embeddings
    except Exception as e:
        logger.error(f"Error generating embeddings with Titan model: {str(e)}")
        raise


async def get_batch_embeddings(texts: List[str]) -> List[List[float]]:
    """
    Generate embeddings for a batch of texts.
    
    Args:
        texts (List[str]): List of texts to generate embeddings for.
        
    Returns:
        List[List[float]]: List of embedding vectors.
    """
    results = []
    for text in texts:
        embedding = await get_embedding(text)
        results.append(embedding)
    return results


if __name__ == '__main__':
    import asyncio

    # Example usage for AML/KYC entity search
    use_sso = os.getenv("AWS_USE_SSO", "false").lower() in ("true", "1", "yes")
    region_name = os.getenv("AWS_REGION", "us-east-1")

    # Direct usage of the class
    if use_sso:
        embeddings_client = BedrockTitanEmbeddings(
            region_name=region_name,
            use_default_credentials=True
        )
    else:
        aws_access_key = os.getenv("AWS_ACCESS_KEY_ID")
        aws_secret_key = os.getenv("AWS_SECRET_ACCESS_KEY")

        embeddings_client = BedrockTitanEmbeddings(
            region_name=region_name,
            aws_access_key=aws_access_key,
            aws_secret_key=aws_secret_key
        )

    # Test direct prediction with AML/KYC relevant text
    sample_text = "High-risk individual with offshore banking activities and shell company connections."
    result = embeddings_client.predict(sample_text)
    print(f"Direct embedding result (first 5 values): {result[:5]}... (total length: {len(result)})")
    
    # Test the async wrapper function
    async def test_get_embedding():
        result = await get_embedding("Entities involved in money laundering through cryptocurrency exchanges.")
        print(f"Async embedding result (first 5 values): {result[:5]}... (total length: {len(result)})")
        
        batch_results = await get_batch_embeddings([
            "Corporate entities with beneficial ownership in offshore jurisdictions", 
            "Individuals with politically exposed person (PEP) status and sanctions risk"
        ])
        print(f"Batch embedding results: {len(batch_results)} embeddings generated")
    
    # Run the async test
    asyncio.run(test_get_embedding())